{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. test하려는 논문 csv파일과 QA CSV파일이 주어졌을때"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 논문 text file을 csv file로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**사용법**\\\n",
    "! python paper_text_to_csv.py \\\n",
    "--input_Paper_path=[논문 텍스트파일이 든 폴더 경로]\\\n",
    "--input_QA_path=[질의응답 csv 파일 경로]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QnA 데이터의 논문 개수 : 60\n",
      "Complete Creating paper.csv\n"
     ]
    }
   ],
   "source": [
    "! python paper_text_to_csv.py \\\n",
    "--input_Paper_path=Paper_text_dataset\\\n",
    "--input_QA_path=QnA_evaluate_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 논문 csv파일과 QA csv파일로 json 파일 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**사용법**\\\n",
    "!python make_json.py \\\n",
    "--input_QA_path QA경로입력 \\\n",
    "--input_Paper_path PAPER경로입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 논문제어번호  난이도(1:하 2:중 3:상)  ... 응답의 시작 index 응답의 종료 index\n",
      "0   JAKO201411560021354                 2  ...          191          242\n",
      "1   JAKO201425560113083                 1  ...           26           56\n",
      "2   JAKO201425560113083                 2  ...           24           53\n",
      "3   JAKO201514039404613                 3  ...           81          184\n",
      "4   JAKO201506959397686                 2  ...           55          125\n",
      "..                  ...               ...  ...          ...          ...\n",
      "94  JAKO201420947476221                 3  ...          223          305\n",
      "95  JAKO201432441779238                 2  ...            9           40\n",
      "96  JAKO201514039404613                 2  ...           21           81\n",
      "97  JAKO201408439035619                 1  ...            5           47\n",
      "98  JAKO201534853187876                 2  ...          114          221\n",
      "\n",
      "[99 rows x 11 columns]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "!python make_json.py \\\n",
    "--input_QA_path QnA_evaluate_dataset.csv \\\n",
    "--input_Paper_path paper_evaluate.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> 현재 폴더에서 **./QA_test.json** 파일 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CUDA_VISIBLE_DEVICES=1 ==> 사용할 GPU번호 설정(FREE GPU 설정 부탁드립니다)\n",
    "2. predict_file ==> 1번에서 나온 QA_test.json파일 경로 입력(경로 안바꼈으면 그대로 사용 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /scratch/kedu21/workspace/Final_Folder/make_bert_model/optimization.py:84: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From make_bert_model/run_squad.py:1187: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From make_bert_model/run_squad.py:1033: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W1125 11:12:36.153786 47903194205696 module_wrapper.py:139] From make_bert_model/run_squad.py:1033: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From make_bert_model/run_squad.py:1033: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W1125 11:12:36.154013 47903194205696 module_wrapper.py:139] From make_bert_model/run_squad.py:1033: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /scratch/kedu21/workspace/Final_Folder/make_bert_model/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1125 11:12:36.154170 47903194205696 module_wrapper.py:139] From /scratch/kedu21/workspace/Final_Folder/make_bert_model/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From make_bert_model/run_squad.py:1039: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W1125 11:12:36.155684 47903194205696 module_wrapper.py:139] From make_bert_model/run_squad.py:1039: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1125 11:12:36.295856 47903194205696 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x2b91eeb25560>) includes params argument, but params are not passed to Estimator.\n",
      "W1125 11:12:38.325692 47903194205696 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x2b91eeb25560>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './QA_models', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b91eeb91050>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "I1125 11:12:38.326447 47903194205696 estimator.py:212] Using config: {'_model_dir': './QA_models', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b91eeb91050>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "I1125 11:12:38.326766 47903194205696 tpu_context.py:220] _TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "W1125 11:12:38.326956 47903194205696 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.\n",
      "WARNING:tensorflow:From make_bert_model/run_squad.py:212: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1125 11:12:38.327094 47903194205696 module_wrapper.py:139] From make_bert_model/run_squad.py:212: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "could not find answer:  0\n",
      "len(examples): 99\n",
      "WARNING:tensorflow:From make_bert_model/run_squad.py:978: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W1125 11:12:38.351366 47903194205696 module_wrapper.py:139] From make_bert_model/run_squad.py:978: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From make_bert_model/run_squad.py:399: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W1125 11:12:38.355556 47903194205696 module_wrapper.py:139] From make_bert_model/run_squad.py:399: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.355676 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000000\n",
      "I1125 11:12:38.355740 47903194205696 run_squad.py:400] unique_id: 1000000000\n",
      "INFO:tensorflow:example_index: 0\n",
      "I1125 11:12:38.355790 47903194205696 run_squad.py:401] example_index: 0\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.355843 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 유 ##채 ##대의 운 ##송 ##, 취 ##급 및 보 ##관 ##에 어려 ##움을 해결 ##하는 방법 ##은 ##? [SEP] 유 ##채 ##대는 유 ##채 ##씨 ##를 수 ##확 ##한 후 부 ##산 ##물 ##로 발생하는 줄 ##기 ##와 잎 ##으로 확보 가능한 양 ##은 유 ##채 ##씨 ##의 수 ##확 ##량 ##과 거의 동일 ##하며, 따라서 상 ##당한 양 ##의 유 ##채 ##대 확보 ##가 산 ##술 ##적으로 가능 ##하다. 그러나 유 ##채 ##대 ##와 같은 짚 ##은 목 ##재 ##나 석 ##탄 ##과 같이 열 ##원으로 주로 사용 ##되고 있는 원 ##료 ##와 비교 ##하여 낮은 밀 ##도로 인 ##하여 운 ##송 ##, 취 ##급 및 보 ##관 ##에 어려 ##움을 가지고 있는데 ##, 이러한 문제 ##점 ##은 유 ##채 재 ##배 ##지 근 ##처 ##에서 펠 ##릿 ##을 생산 ##하거나 ##, 이동 ##식 펠 ##릿 성 ##형 ##기를 이용 ##함으로써 해결 ##이 가능 ##할 것으로 생각 ##한다. 또한 유 ##채 ##대는 대부분의 농 ##업 ##부 ##산 ##물 ##과 마 ##찬 ##가지 ##로 낮은 밀 ##도로 단위 ##부 ##피 ##당 순 ##에너지 ##량이 낮은 ##데, 이러한 문제 ##점 ##은 압 ##밀 ##화를 통하여 어느 정도 해결 ##이 가능 ##할 것으로 판단된다. 마지막 ##으로 많은 농 ##업 ##부 ##산 ##물을 펠 ##릿 ##의 원 ##료 ##로 사용 ##할 경우 발생 ##하게 되는 가장 큰 문제 ##점 ##으로 유 ##채 ##대는 목 ##분에 비 ##하여 많은 질 ##소 ##, 황 ##, 염 ##소 그리고 회 ##분을 함 ##유 ##하고 있으며, 이 회 ##분 ##의 용 ##해 ##온 ##도가 낮 ##아 연 ##소 시 ##에 보 ##일 ##러 내 ##에 클 ##링 ##커 ( ##clin ##ker ##) 현 ##상 및 부 ##식을 초 ##래 ##하고, 아 ##울 ##러 연 ##소 후에 많은 양 ##의 대 ##기 ##오 ##염 물 ##질 ##이 발생 ##되어 가정 ##용 보 ##일 ##러 원 ##료 ##로 사용 ##이 불 ##가 ##한 단 ##점을 가지고 있다( ##B ##oman et al., 2006 ##). 이와 같은 문제 ##는 목 ##재 ##와 같이 회 ##분 함 ##량이 낮은 원 ##료 ##와 혼합 ##하여 펠 ##릿 ##을 제조 ##하거나 ##, 야 ##지 폭 ##로 ##를 통하여 유 ##채 ##대 내 ##에 함 ##유 ##되어 있는 일정 ##량의 회 ##분을 근 ##본 ##적으로 감소 ##시켜 펠 ##릿 ##의 원 ##료 ##로 사용 ##하거나 ##, 또는 회 ##분 제거 ##를 위하여 적절 ##한 장 ##치를 보 ##유 ##한 보 ##일 ##러 ##를 사용 ##함으로써 해결 ##이 가능한 것으로 보고 ##되었다 ##( ##O ##bern ##berger and The ##k ##, 2004 ##). 국내 ##의 경우, Han et al. ( ##2012) ##은 보 ##리 ##짚 ##의 야 ##지 폭 ##로 ##를 통하여 회 ##분 ##량이 크게 감소 ##한다고 보고 ##하였다. [SEP]\n",
      "I1125 11:12:38.356009 47903194205696 run_squad.py:404] tokens: [CLS] 유 ##채 ##대의 운 ##송 ##, 취 ##급 및 보 ##관 ##에 어려 ##움을 해결 ##하는 방법 ##은 ##? [SEP] 유 ##채 ##대는 유 ##채 ##씨 ##를 수 ##확 ##한 후 부 ##산 ##물 ##로 발생하는 줄 ##기 ##와 잎 ##으로 확보 가능한 양 ##은 유 ##채 ##씨 ##의 수 ##확 ##량 ##과 거의 동일 ##하며, 따라서 상 ##당한 양 ##의 유 ##채 ##대 확보 ##가 산 ##술 ##적으로 가능 ##하다. 그러나 유 ##채 ##대 ##와 같은 짚 ##은 목 ##재 ##나 석 ##탄 ##과 같이 열 ##원으로 주로 사용 ##되고 있는 원 ##료 ##와 비교 ##하여 낮은 밀 ##도로 인 ##하여 운 ##송 ##, 취 ##급 및 보 ##관 ##에 어려 ##움을 가지고 있는데 ##, 이러한 문제 ##점 ##은 유 ##채 재 ##배 ##지 근 ##처 ##에서 펠 ##릿 ##을 생산 ##하거나 ##, 이동 ##식 펠 ##릿 성 ##형 ##기를 이용 ##함으로써 해결 ##이 가능 ##할 것으로 생각 ##한다. 또한 유 ##채 ##대는 대부분의 농 ##업 ##부 ##산 ##물 ##과 마 ##찬 ##가지 ##로 낮은 밀 ##도로 단위 ##부 ##피 ##당 순 ##에너지 ##량이 낮은 ##데, 이러한 문제 ##점 ##은 압 ##밀 ##화를 통하여 어느 정도 해결 ##이 가능 ##할 것으로 판단된다. 마지막 ##으로 많은 농 ##업 ##부 ##산 ##물을 펠 ##릿 ##의 원 ##료 ##로 사용 ##할 경우 발생 ##하게 되는 가장 큰 문제 ##점 ##으로 유 ##채 ##대는 목 ##분에 비 ##하여 많은 질 ##소 ##, 황 ##, 염 ##소 그리고 회 ##분을 함 ##유 ##하고 있으며, 이 회 ##분 ##의 용 ##해 ##온 ##도가 낮 ##아 연 ##소 시 ##에 보 ##일 ##러 내 ##에 클 ##링 ##커 ( ##clin ##ker ##) 현 ##상 및 부 ##식을 초 ##래 ##하고, 아 ##울 ##러 연 ##소 후에 많은 양 ##의 대 ##기 ##오 ##염 물 ##질 ##이 발생 ##되어 가정 ##용 보 ##일 ##러 원 ##료 ##로 사용 ##이 불 ##가 ##한 단 ##점을 가지고 있다( ##B ##oman et al., 2006 ##). 이와 같은 문제 ##는 목 ##재 ##와 같이 회 ##분 함 ##량이 낮은 원 ##료 ##와 혼합 ##하여 펠 ##릿 ##을 제조 ##하거나 ##, 야 ##지 폭 ##로 ##를 통하여 유 ##채 ##대 내 ##에 함 ##유 ##되어 있는 일정 ##량의 회 ##분을 근 ##본 ##적으로 감소 ##시켜 펠 ##릿 ##의 원 ##료 ##로 사용 ##하거나 ##, 또는 회 ##분 제거 ##를 위하여 적절 ##한 장 ##치를 보 ##유 ##한 보 ##일 ##러 ##를 사용 ##함으로써 해결 ##이 가능한 것으로 보고 ##되었다 ##( ##O ##bern ##berger and The ##k ##, 2004 ##). 국내 ##의 경우, Han et al. ( ##2012) ##은 보 ##리 ##짚 ##의 야 ##지 폭 ##로 ##를 통하여 회 ##분 ##량이 크게 감소 ##한다고 보고 ##하였다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 21:0 22:0 23:0 24:1 25:1 26:1 27:1 28:2 29:2 30:2 31:3 32:4 33:4 34:4 35:4 36:5 37:6 38:6 39:6 40:7 41:7 42:8 43:9 44:10 45:10 46:11 47:11 48:11 49:11 50:12 51:12 52:12 53:12 54:13 55:14 56:14 57:15 58:16 59:16 60:17 61:17 62:18 63:18 64:18 65:19 66:19 67:20 68:20 69:20 70:21 71:21 72:22 73:23 74:23 75:23 76:23 77:24 78:25 79:25 80:26 81:26 82:26 83:27 84:27 85:27 86:28 87:29 88:29 89:30 90:31 91:31 92:32 93:33 94:33 95:33 96:34 97:34 98:35 99:36 100:36 101:37 102:37 103:38 104:38 105:38 106:39 107:39 108:40 109:41 110:41 111:41 112:42 113:42 114:43 115:44 116:44 117:45 118:46 119:46 120:46 121:47 122:47 123:48 124:48 125:48 126:49 127:49 128:49 129:50 130:50 131:50 132:51 133:51 134:51 135:52 136:52 137:53 138:53 139:54 140:54 141:54 142:55 143:55 144:56 145:56 146:57 147:57 148:58 149:59 150:59 151:60 152:61 153:61 154:61 155:62 156:63 157:63 158:63 159:63 160:63 161:63 162:64 163:64 164:64 165:64 166:65 167:66 168:66 169:67 170:67 171:67 172:67 173:68 174:68 175:68 176:69 177:69 178:70 179:71 180:71 181:71 182:72 183:72 184:72 185:73 186:74 187:75 188:76 189:76 190:77 191:77 192:78 193:79 194:80 195:80 196:81 197:82 198:82 199:82 200:82 201:82 202:83 203:83 204:83 205:84 206:84 207:84 208:85 209:85 210:86 211:87 212:87 213:88 214:89 215:90 216:91 217:91 218:91 219:92 220:92 221:92 222:93 223:93 224:94 225:94 226:95 227:96 228:96 229:96 230:97 231:97 232:98 233:98 234:99 235:100 236:100 237:101 238:101 239:101 240:102 241:103 242:104 243:104 244:104 245:105 246:105 247:105 248:105 249:106 250:106 251:107 252:107 253:108 254:108 255:109 256:109 257:109 258:110 259:110 260:111 261:111 262:111 263:112 264:112 265:112 266:112 267:113 268:113 269:114 270:115 271:115 272:116 273:116 274:116 275:117 276:117 277:117 278:118 279:118 280:119 281:120 282:121 283:121 284:122 285:122 286:122 287:122 288:123 289:123 290:123 291:124 292:124 293:125 294:125 295:126 296:126 297:126 298:127 299:127 300:127 301:128 302:128 303:129 304:129 305:129 306:130 307:130 308:131 309:132 310:132 311:132 312:133 313:134 314:135 315:135 316:136 317:137 318:138 319:138 320:139 321:139 322:139 323:140 324:141 325:141 326:142 327:142 328:143 329:144 330:144 331:144 332:145 333:145 334:146 335:146 336:146 337:147 338:147 339:147 340:148 341:148 342:149 343:149 344:149 345:150 346:151 347:151 348:151 349:152 350:152 351:153 352:153 353:153 354:154 355:155 356:155 357:156 358:156 359:157 360:157 361:157 362:158 363:158 364:159 365:159 366:159 367:160 368:160 369:160 370:161 371:161 372:161 373:162 374:163 375:163 376:164 377:164 378:165 379:166 380:166 381:167 382:167 383:168 384:168 385:168 386:169 387:169 388:169 389:169 390:170 391:170 392:171 393:171 394:172 395:173 396:174 397:174 398:174 399:174 400:174 401:174 402:175 403:176 404:176 405:176 406:177 407:177 408:178 409:178 410:179 411:180 412:181 413:182 414:183 415:183 416:183 417:184 418:184 419:184 420:184 421:185 422:185 423:186 424:186 425:186 426:187 427:188 428:188 429:188 430:189 431:190 432:190 433:191 434:191\n",
      "I1125 11:12:38.356213 47903194205696 run_squad.py:406] token_to_orig_map: 21:0 22:0 23:0 24:1 25:1 26:1 27:1 28:2 29:2 30:2 31:3 32:4 33:4 34:4 35:4 36:5 37:6 38:6 39:6 40:7 41:7 42:8 43:9 44:10 45:10 46:11 47:11 48:11 49:11 50:12 51:12 52:12 53:12 54:13 55:14 56:14 57:15 58:16 59:16 60:17 61:17 62:18 63:18 64:18 65:19 66:19 67:20 68:20 69:20 70:21 71:21 72:22 73:23 74:23 75:23 76:23 77:24 78:25 79:25 80:26 81:26 82:26 83:27 84:27 85:27 86:28 87:29 88:29 89:30 90:31 91:31 92:32 93:33 94:33 95:33 96:34 97:34 98:35 99:36 100:36 101:37 102:37 103:38 104:38 105:38 106:39 107:39 108:40 109:41 110:41 111:41 112:42 113:42 114:43 115:44 116:44 117:45 118:46 119:46 120:46 121:47 122:47 123:48 124:48 125:48 126:49 127:49 128:49 129:50 130:50 131:50 132:51 133:51 134:51 135:52 136:52 137:53 138:53 139:54 140:54 141:54 142:55 143:55 144:56 145:56 146:57 147:57 148:58 149:59 150:59 151:60 152:61 153:61 154:61 155:62 156:63 157:63 158:63 159:63 160:63 161:63 162:64 163:64 164:64 165:64 166:65 167:66 168:66 169:67 170:67 171:67 172:67 173:68 174:68 175:68 176:69 177:69 178:70 179:71 180:71 181:71 182:72 183:72 184:72 185:73 186:74 187:75 188:76 189:76 190:77 191:77 192:78 193:79 194:80 195:80 196:81 197:82 198:82 199:82 200:82 201:82 202:83 203:83 204:83 205:84 206:84 207:84 208:85 209:85 210:86 211:87 212:87 213:88 214:89 215:90 216:91 217:91 218:91 219:92 220:92 221:92 222:93 223:93 224:94 225:94 226:95 227:96 228:96 229:96 230:97 231:97 232:98 233:98 234:99 235:100 236:100 237:101 238:101 239:101 240:102 241:103 242:104 243:104 244:104 245:105 246:105 247:105 248:105 249:106 250:106 251:107 252:107 253:108 254:108 255:109 256:109 257:109 258:110 259:110 260:111 261:111 262:111 263:112 264:112 265:112 266:112 267:113 268:113 269:114 270:115 271:115 272:116 273:116 274:116 275:117 276:117 277:117 278:118 279:118 280:119 281:120 282:121 283:121 284:122 285:122 286:122 287:122 288:123 289:123 290:123 291:124 292:124 293:125 294:125 295:126 296:126 297:126 298:127 299:127 300:127 301:128 302:128 303:129 304:129 305:129 306:130 307:130 308:131 309:132 310:132 311:132 312:133 313:134 314:135 315:135 316:136 317:137 318:138 319:138 320:139 321:139 322:139 323:140 324:141 325:141 326:142 327:142 328:143 329:144 330:144 331:144 332:145 333:145 334:146 335:146 336:146 337:147 338:147 339:147 340:148 341:148 342:149 343:149 344:149 345:150 346:151 347:151 348:151 349:152 350:152 351:153 352:153 353:153 354:154 355:155 356:155 357:156 358:156 359:157 360:157 361:157 362:158 363:158 364:159 365:159 366:159 367:160 368:160 369:160 370:161 371:161 372:161 373:162 374:163 375:163 376:164 377:164 378:165 379:166 380:166 381:167 382:167 383:168 384:168 385:168 386:169 387:169 388:169 389:169 390:170 391:170 392:171 393:171 394:172 395:173 396:174 397:174 398:174 399:174 400:174 401:174 402:175 403:176 404:176 405:176 406:177 407:177 408:178 409:178 410:179 411:180 412:181 413:182 414:183 415:183 416:183 417:184 418:184 419:184 420:184 421:185 422:185 423:186 424:186 425:186 426:187 427:188 428:188 429:188 430:189 431:190 432:190 433:191 434:191\n",
      "INFO:tensorflow:token_is_max_context: 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True\n",
      "I1125 11:12:38.356394 47903194205696 run_squad.py:408] token_is_max_context: 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True\n",
      "INFO:tensorflow:input_ids: 101 9625 119253 69725 9606 119057 110862 9773 37568 9316 9356 20595 10530 119838 90373 119927 12178 119567 10892 110871 102 9625 119253 97997 9625 119253 49212 11513 9460 119445 11102 10003 9365 21386 29364 11261 120027 9692 12310 12638 9650 11467 119921 120015 9543 10892 9625 119253 49212 10459 9460 119445 44321 11882 55067 120112 119780 52579 9414 103088 9543 10459 9625 119253 14423 119921 11287 9407 51945 17022 119609 119793 21890 9625 119253 14423 12638 18589 121303 10892 9284 36210 16439 9426 66554 11882 38401 9569 78686 41195 119550 29208 13767 9612 38688 12638 119572 13374 119758 9313 54448 9640 13374 9606 119057 110862 9773 37568 9316 9356 20595 10530 119838 90373 44270 60030 110862 34079 119581 34907 10892 9625 119253 9659 76036 12508 8926 60469 11489 9921 118906 10622 119707 120054 110862 119831 21155 9921 118906 9434 27506 29669 119580 119866 119927 10739 119609 14843 23925 119735 119554 19789 9625 119253 97997 85146 9027 26784 14646 21386 29364 11882 9246 119249 69023 11261 119758 9313 54448 120057 14646 97146 21928 9462 120200 119722 119758 119953 34079 119581 34907 10892 9527 118958 56999 119834 82564 107657 119927 10739 119609 14843 23925 119975 67313 11467 25685 9027 26784 14646 21386 69047 9921 118906 10459 9612 38688 11261 119550 14843 28467 119568 17594 54780 22224 9835 119581 34907 11467 9625 119253 97997 9284 110355 9379 13374 25685 9709 22333 110862 9997 110862 9570 22333 23289 9998 97005 9956 42815 12453 119661 9638 9998 37712 10459 9603 14523 37093 68516 8992 16985 9568 22333 9485 10530 9356 18392 30873 8996 10530 9836 80174 106826 113 86257 11880 110859 9978 14871 9316 9365 48132 9757 37388 119604 9519 78123 30873 9568 22333 56528 25685 9543 10459 9069 12310 28188 119144 9299 48599 10739 119568 16855 119853 24974 9356 18392 30873 9612 38688 11261 119550 10739 9368 11287 11102 9059 67477 44270 119798 11274 70228 10131 119680 10214 119558 104342 18589 119581 11018 9284 36210 12638 38401 9998 37712 9956 119722 119758 9612 38688 12638 120016 13374 9921 118906 10622 119847 120054 110862 9538 12508 9929 11261 11513 119834 9625 119253 14423 8996 10530 9956 42815 16855 13767 120018 119900 9998 97005 8926 40419 17022 119598 119942 9921 118906 10459 9612 38688 11261 119550 120054 110862 20625 9998 37712 119976 11513 68010 120048 11102 9657 62672 9356 42815 11102 9356 18392 30873 11513 119550 119866 119927 10739 120015 23925 98199 13628 110858 11403 74158 32482 10111 10117 10174 110862 10264 119558 119687 10459 119913 10818 10131 120007 113 120394 10892 9356 12692 121041 10459 9538 12508 9929 11261 11513 119834 9998 37712 119722 62548 119598 120177 98199 119548 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.358399 47903194205696 run_squad.py:410] input_ids: 101 9625 119253 69725 9606 119057 110862 9773 37568 9316 9356 20595 10530 119838 90373 119927 12178 119567 10892 110871 102 9625 119253 97997 9625 119253 49212 11513 9460 119445 11102 10003 9365 21386 29364 11261 120027 9692 12310 12638 9650 11467 119921 120015 9543 10892 9625 119253 49212 10459 9460 119445 44321 11882 55067 120112 119780 52579 9414 103088 9543 10459 9625 119253 14423 119921 11287 9407 51945 17022 119609 119793 21890 9625 119253 14423 12638 18589 121303 10892 9284 36210 16439 9426 66554 11882 38401 9569 78686 41195 119550 29208 13767 9612 38688 12638 119572 13374 119758 9313 54448 9640 13374 9606 119057 110862 9773 37568 9316 9356 20595 10530 119838 90373 44270 60030 110862 34079 119581 34907 10892 9625 119253 9659 76036 12508 8926 60469 11489 9921 118906 10622 119707 120054 110862 119831 21155 9921 118906 9434 27506 29669 119580 119866 119927 10739 119609 14843 23925 119735 119554 19789 9625 119253 97997 85146 9027 26784 14646 21386 29364 11882 9246 119249 69023 11261 119758 9313 54448 120057 14646 97146 21928 9462 120200 119722 119758 119953 34079 119581 34907 10892 9527 118958 56999 119834 82564 107657 119927 10739 119609 14843 23925 119975 67313 11467 25685 9027 26784 14646 21386 69047 9921 118906 10459 9612 38688 11261 119550 14843 28467 119568 17594 54780 22224 9835 119581 34907 11467 9625 119253 97997 9284 110355 9379 13374 25685 9709 22333 110862 9997 110862 9570 22333 23289 9998 97005 9956 42815 12453 119661 9638 9998 37712 10459 9603 14523 37093 68516 8992 16985 9568 22333 9485 10530 9356 18392 30873 8996 10530 9836 80174 106826 113 86257 11880 110859 9978 14871 9316 9365 48132 9757 37388 119604 9519 78123 30873 9568 22333 56528 25685 9543 10459 9069 12310 28188 119144 9299 48599 10739 119568 16855 119853 24974 9356 18392 30873 9612 38688 11261 119550 10739 9368 11287 11102 9059 67477 44270 119798 11274 70228 10131 119680 10214 119558 104342 18589 119581 11018 9284 36210 12638 38401 9998 37712 9956 119722 119758 9612 38688 12638 120016 13374 9921 118906 10622 119847 120054 110862 9538 12508 9929 11261 11513 119834 9625 119253 14423 8996 10530 9956 42815 16855 13767 120018 119900 9998 97005 8926 40419 17022 119598 119942 9921 118906 10459 9612 38688 11261 119550 120054 110862 20625 9998 37712 119976 11513 68010 120048 11102 9657 62672 9356 42815 11102 9356 18392 30873 11513 119550 119866 119927 10739 120015 23925 98199 13628 110858 11403 74158 32482 10111 10117 10174 110862 10264 119558 119687 10459 119913 10818 10131 120007 113 120394 10892 9356 12692 121041 10459 9538 12508 9929 11261 11513 119834 9998 37712 119722 62548 119598 120177 98199 119548 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.358562 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.358710 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.362221 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000001\n",
      "I1125 11:12:38.362347 47903194205696 run_squad.py:400] unique_id: 1000000001\n",
      "INFO:tensorflow:example_index: 1\n",
      "I1125 11:12:38.362405 47903194205696 run_squad.py:401] example_index: 1\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.362454 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 고 ##체 바 ##이 ##오 ##연 ##료 ##는 무 ##엇 ##인 ##가 ##? [SEP] 천 ##연 ##가 ##스 ##, 석 ##유 ##, 석 ##탄 ##과 같은 화 ##석 ##연 ##료 ##는 전 세계 모든 나 ##라 ##에서 소비 ##하는 에너지 ##의 80 ##％ 이상 ##을 제공 ##하고 있는 주요 연 ##료 ##원으로 국내 ##에서도 2007년 기준 에너지 수 ##요 ##의 95 ##％ 이상 ##을 차 ##지 ##하고 있다( ##이 등 ##, 2009 ##). 최근 에너지 소비 ##의 급 ##증 ##과 자동 ##차 ##의 급 ##격 ##한 보 ##급 ##으로 화 ##석 ##연 ##료 ##의 사용 ##량이 크게 증가 ##함 ##에 따라 화 ##석 ##연 ##료 ##의 대부분 ##을 수 ##입 ##에 의 ##존 ##하는 우리나라 ##에서 이에 대한 대 ##응 ##책 ##이 필요 ##하며, 또한 화 ##석 ##연 ##료 사용 ##의 증가 ##에 따른 이 ##산화 ##탄 ##소 ##의 과 ##도 ##한 배 ##출 ##로 인 ##하여 제 ##정 ##된 기 ##후 ##변화 협 ##약 ##의 규 ##제 ##에 대한 대 ##응 ##책 ##으로 새로운 에너지원 ##의 개발 ##이 시 ##급 ##한 상황 ##이다. 따라서 여러 선 ##진 ##국 ##에서 많은 초기 투 ##자 ##비용 ##에도 불구하고 태 ##양 ##열 ##, 풍 ##력 ##, 조 ##력 ##, 바 ##이 ##오 ##매 ##스 등과 같은 신 ##재 ##생 ##에너지 개발 ##에 여러 연구 및 과 ##감 ##한 투 ##자를 추 ##진 ##하고 있다. 이 가운데 바 ##이 ##오 ##매 ##스 ##에 열 ##과 압 ##력을 가 ##하여 제조 ##한 펠 ##릿 ##, 브 ##리 ##켓 ##과 같은 고 ##체 바 ##이 ##오 ##연 ##료 ##를 이용하여 열 또는 전기를 공급 ##하는 시장 ##이 유럽 ##을 중심으로 1990년 ##대 후 ##반 ##부터 성장 ##하기 시작 ##하였으며, 향 ##후 그 시장 ##이 더욱 확 ##대 ##될 것으로 예 ##상 ##되고 있다( ##Y ##ang et al., 2011 ##a ##). 현재 ##까지 주로 사용 ##되고 있는 고 ##체 ##바 ##이 ##오 연 ##료 형태 ##는 펠 ##릿 ##으로 제 ##재 ##소 및 목 ##재 ##가 ##공 공 ##장 등에서 부 ##산 ##물 ##로 발생 ##되는 톱 ##밥 ##을 원 ##료 ##로 제조 ##되고 있으나 ##, 지 ##금 ##과 같은 추 ##세 ##로 목 ##재 ##펠 ##릿 시장 ##이 계속 성장 ##할 경우 조 ##만 ##간 원 ##료 부족 및 원 ##가 상 ##승 ##을 초 ##래 ##할 가능 ##성이 매우 높은 것으로 예 ##견 ##되고 있다( ##H ##an et al., 2009 ##). 따라서 펠 ##릿 ##의 원 ##료 ##로 목 ##재 ##를 대 ##체 ##할 수 있는 새로운 바 ##이 ##오 ##매 ##스를 찾 ##는 것이 필요한 상황 ##에서 기존 ##에 사용 ##되고 있는 펠 ##릿 ##의 원 ##료 ##가 아니 ##며, 부 ##산 ##물 ##로 ##써 식 ##품 또는 다른 목적 ##의 원 ##료 ##로 사용 ##되지 않 ##음 ##으로써 확보 ##가 용 ##이하고, 결과 ##적으로 가 ##격 ##이 저 ##렴 ##한 원 ##료 ##의 사용 ##이 필요 ##할 것으로 판단된다. [SEP]\n",
      "I1125 11:12:38.362617 47903194205696 run_squad.py:404] tokens: [CLS] 고 ##체 바 ##이 ##오 ##연 ##료 ##는 무 ##엇 ##인 ##가 ##? [SEP] 천 ##연 ##가 ##스 ##, 석 ##유 ##, 석 ##탄 ##과 같은 화 ##석 ##연 ##료 ##는 전 세계 모든 나 ##라 ##에서 소비 ##하는 에너지 ##의 80 ##％ 이상 ##을 제공 ##하고 있는 주요 연 ##료 ##원으로 국내 ##에서도 2007년 기준 에너지 수 ##요 ##의 95 ##％ 이상 ##을 차 ##지 ##하고 있다( ##이 등 ##, 2009 ##). 최근 에너지 소비 ##의 급 ##증 ##과 자동 ##차 ##의 급 ##격 ##한 보 ##급 ##으로 화 ##석 ##연 ##료 ##의 사용 ##량이 크게 증가 ##함 ##에 따라 화 ##석 ##연 ##료 ##의 대부분 ##을 수 ##입 ##에 의 ##존 ##하는 우리나라 ##에서 이에 대한 대 ##응 ##책 ##이 필요 ##하며, 또한 화 ##석 ##연 ##료 사용 ##의 증가 ##에 따른 이 ##산화 ##탄 ##소 ##의 과 ##도 ##한 배 ##출 ##로 인 ##하여 제 ##정 ##된 기 ##후 ##변화 협 ##약 ##의 규 ##제 ##에 대한 대 ##응 ##책 ##으로 새로운 에너지원 ##의 개발 ##이 시 ##급 ##한 상황 ##이다. 따라서 여러 선 ##진 ##국 ##에서 많은 초기 투 ##자 ##비용 ##에도 불구하고 태 ##양 ##열 ##, 풍 ##력 ##, 조 ##력 ##, 바 ##이 ##오 ##매 ##스 등과 같은 신 ##재 ##생 ##에너지 개발 ##에 여러 연구 및 과 ##감 ##한 투 ##자를 추 ##진 ##하고 있다. 이 가운데 바 ##이 ##오 ##매 ##스 ##에 열 ##과 압 ##력을 가 ##하여 제조 ##한 펠 ##릿 ##, 브 ##리 ##켓 ##과 같은 고 ##체 바 ##이 ##오 ##연 ##료 ##를 이용하여 열 또는 전기를 공급 ##하는 시장 ##이 유럽 ##을 중심으로 1990년 ##대 후 ##반 ##부터 성장 ##하기 시작 ##하였으며, 향 ##후 그 시장 ##이 더욱 확 ##대 ##될 것으로 예 ##상 ##되고 있다( ##Y ##ang et al., 2011 ##a ##). 현재 ##까지 주로 사용 ##되고 있는 고 ##체 ##바 ##이 ##오 연 ##료 형태 ##는 펠 ##릿 ##으로 제 ##재 ##소 및 목 ##재 ##가 ##공 공 ##장 등에서 부 ##산 ##물 ##로 발생 ##되는 톱 ##밥 ##을 원 ##료 ##로 제조 ##되고 있으나 ##, 지 ##금 ##과 같은 추 ##세 ##로 목 ##재 ##펠 ##릿 시장 ##이 계속 성장 ##할 경우 조 ##만 ##간 원 ##료 부족 및 원 ##가 상 ##승 ##을 초 ##래 ##할 가능 ##성이 매우 높은 것으로 예 ##견 ##되고 있다( ##H ##an et al., 2009 ##). 따라서 펠 ##릿 ##의 원 ##료 ##로 목 ##재 ##를 대 ##체 ##할 수 있는 새로운 바 ##이 ##오 ##매 ##스를 찾 ##는 것이 필요한 상황 ##에서 기존 ##에 사용 ##되고 있는 펠 ##릿 ##의 원 ##료 ##가 아니 ##며, 부 ##산 ##물 ##로 ##써 식 ##품 또는 다른 목적 ##의 원 ##료 ##로 사용 ##되지 않 ##음 ##으로써 확보 ##가 용 ##이하고, 결과 ##적으로 가 ##격 ##이 저 ##렴 ##한 원 ##료 ##의 사용 ##이 필요 ##할 것으로 판단된다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 15:0 16:0 17:0 18:0 19:0 20:1 21:1 22:1 23:2 24:2 25:2 26:3 27:4 28:4 29:4 30:4 31:4 32:5 33:6 34:7 35:8 36:8 37:8 38:9 39:9 40:10 41:10 42:11 43:11 44:12 45:12 46:13 47:13 48:14 49:15 50:16 51:16 52:16 53:17 54:17 55:18 56:19 57:20 58:21 59:21 60:21 61:22 62:22 63:23 64:23 65:24 66:24 67:24 68:25 69:25 70:26 71:26 72:27 73:27 74:28 75:29 76:30 77:30 78:31 79:31 80:31 81:32 82:32 83:32 84:33 85:33 86:33 87:34 88:34 89:34 90:35 91:35 92:35 93:35 94:35 95:36 96:36 97:37 98:38 99:38 100:38 101:39 102:40 103:40 104:40 105:40 106:40 107:41 108:41 109:42 110:42 111:42 112:43 113:43 114:43 115:44 116:44 117:45 118:46 119:47 120:47 121:47 122:47 123:48 124:48 125:49 126:50 127:50 128:50 129:50 130:51 131:51 132:52 133:52 134:53 135:54 136:54 137:54 138:54 139:54 140:55 141:55 142:55 143:56 144:56 145:56 146:57 147:57 148:58 149:58 150:58 151:59 152:59 153:59 154:60 155:60 156:60 157:61 158:61 159:61 160:62 161:63 162:63 163:63 164:63 165:64 166:65 167:65 168:66 169:66 170:67 171:67 172:67 173:68 174:68 175:69 176:70 177:71 178:71 179:71 180:71 181:72 182:73 183:74 184:74 185:74 186:74 187:75 188:76 189:76 190:76 191:76 192:77 193:77 194:77 195:78 196:78 197:78 198:79 199:79 200:79 201:79 202:79 203:80 204:81 205:82 206:82 207:82 208:82 209:83 210:83 211:84 212:85 213:86 214:87 215:87 216:87 217:88 218:88 219:89 220:89 221:89 222:90 223:91 224:92 225:93 226:93 227:93 228:93 229:93 230:93 231:94 232:94 233:95 234:95 235:96 236:96 237:97 238:97 239:98 240:98 241:98 242:99 243:99 244:99 245:99 246:100 247:101 248:101 249:102 250:102 251:102 252:102 253:102 254:102 255:103 256:104 257:105 258:106 259:107 260:107 261:108 262:108 263:109 264:109 265:110 266:111 267:111 268:112 269:112 270:112 271:113 272:113 273:114 274:114 275:115 276:115 277:116 278:117 279:117 280:118 281:119 282:119 283:119 284:120 285:121 286:121 287:121 288:122 289:122 290:122 291:123 292:124 293:125 294:125 295:125 296:126 297:126 298:127 299:128 300:128 301:129 302:130 303:130 304:130 305:130 306:130 307:131 308:131 309:132 310:132 311:133 312:133 313:133 314:134 315:134 316:134 317:135 318:136 319:136 320:136 321:136 322:137 323:137 324:138 325:139 326:139 327:139 328:139 329:140 330:140 331:141 332:141 333:141 334:142 335:142 336:142 337:143 338:143 339:144 340:144 341:145 342:145 343:145 344:146 345:147 346:147 347:147 348:148 349:148 350:148 351:148 352:149 353:149 354:150 355:151 356:151 357:152 358:153 359:153 360:153 361:154 362:154 363:155 364:156 365:157 366:157 367:158 368:158 369:158 370:159 371:159 372:159 373:160 374:160 375:161 376:162 377:163 378:164 379:164 380:164 381:165 382:165 383:165 384:166 385:167 386:168 387:168 388:169 389:170 390:170 391:170 392:171 393:171 394:171 395:172 396:172 397:172 398:173 399:173 400:173 401:174 402:175 403:176 404:177 405:177 406:177 407:177 408:177 409:178 410:178 411:179 412:180 413:181 414:181 415:182 416:182 417:183 418:183 419:184 420:185 421:185 422:185 423:186 424:186 425:186 426:187 427:187 428:188 429:188 430:188 431:188 432:188 433:189 434:189 435:190 436:191 437:192 438:192 439:193 440:193 441:193 442:194 443:194 444:195 445:195 446:195 447:196 448:196 449:197 450:197 451:198 452:198 453:199 454:199 455:199 456:200 457:200 458:200 459:201 460:201 461:201 462:202 463:202 464:203 465:203 466:204 467:205\n",
      "I1125 11:12:38.362849 47903194205696 run_squad.py:406] token_to_orig_map: 15:0 16:0 17:0 18:0 19:0 20:1 21:1 22:1 23:2 24:2 25:2 26:3 27:4 28:4 29:4 30:4 31:4 32:5 33:6 34:7 35:8 36:8 37:8 38:9 39:9 40:10 41:10 42:11 43:11 44:12 45:12 46:13 47:13 48:14 49:15 50:16 51:16 52:16 53:17 54:17 55:18 56:19 57:20 58:21 59:21 60:21 61:22 62:22 63:23 64:23 65:24 66:24 67:24 68:25 69:25 70:26 71:26 72:27 73:27 74:28 75:29 76:30 77:30 78:31 79:31 80:31 81:32 82:32 83:32 84:33 85:33 86:33 87:34 88:34 89:34 90:35 91:35 92:35 93:35 94:35 95:36 96:36 97:37 98:38 99:38 100:38 101:39 102:40 103:40 104:40 105:40 106:40 107:41 108:41 109:42 110:42 111:42 112:43 113:43 114:43 115:44 116:44 117:45 118:46 119:47 120:47 121:47 122:47 123:48 124:48 125:49 126:50 127:50 128:50 129:50 130:51 131:51 132:52 133:52 134:53 135:54 136:54 137:54 138:54 139:54 140:55 141:55 142:55 143:56 144:56 145:56 146:57 147:57 148:58 149:58 150:58 151:59 152:59 153:59 154:60 155:60 156:60 157:61 158:61 159:61 160:62 161:63 162:63 163:63 164:63 165:64 166:65 167:65 168:66 169:66 170:67 171:67 172:67 173:68 174:68 175:69 176:70 177:71 178:71 179:71 180:71 181:72 182:73 183:74 184:74 185:74 186:74 187:75 188:76 189:76 190:76 191:76 192:77 193:77 194:77 195:78 196:78 197:78 198:79 199:79 200:79 201:79 202:79 203:80 204:81 205:82 206:82 207:82 208:82 209:83 210:83 211:84 212:85 213:86 214:87 215:87 216:87 217:88 218:88 219:89 220:89 221:89 222:90 223:91 224:92 225:93 226:93 227:93 228:93 229:93 230:93 231:94 232:94 233:95 234:95 235:96 236:96 237:97 238:97 239:98 240:98 241:98 242:99 243:99 244:99 245:99 246:100 247:101 248:101 249:102 250:102 251:102 252:102 253:102 254:102 255:103 256:104 257:105 258:106 259:107 260:107 261:108 262:108 263:109 264:109 265:110 266:111 267:111 268:112 269:112 270:112 271:113 272:113 273:114 274:114 275:115 276:115 277:116 278:117 279:117 280:118 281:119 282:119 283:119 284:120 285:121 286:121 287:121 288:122 289:122 290:122 291:123 292:124 293:125 294:125 295:125 296:126 297:126 298:127 299:128 300:128 301:129 302:130 303:130 304:130 305:130 306:130 307:131 308:131 309:132 310:132 311:133 312:133 313:133 314:134 315:134 316:134 317:135 318:136 319:136 320:136 321:136 322:137 323:137 324:138 325:139 326:139 327:139 328:139 329:140 330:140 331:141 332:141 333:141 334:142 335:142 336:142 337:143 338:143 339:144 340:144 341:145 342:145 343:145 344:146 345:147 346:147 347:147 348:148 349:148 350:148 351:148 352:149 353:149 354:150 355:151 356:151 357:152 358:153 359:153 360:153 361:154 362:154 363:155 364:156 365:157 366:157 367:158 368:158 369:158 370:159 371:159 372:159 373:160 374:160 375:161 376:162 377:163 378:164 379:164 380:164 381:165 382:165 383:165 384:166 385:167 386:168 387:168 388:169 389:170 390:170 391:170 392:171 393:171 394:171 395:172 396:172 397:172 398:173 399:173 400:173 401:174 402:175 403:176 404:177 405:177 406:177 407:177 408:177 409:178 410:178 411:179 412:180 413:181 414:181 415:182 416:182 417:183 418:183 419:184 420:185 421:185 422:185 423:186 424:186 425:186 426:187 427:187 428:188 429:188 430:188 431:188 432:188 433:189 434:189 435:190 436:191 437:192 438:192 439:193 440:193 441:193 442:194 443:194 444:195 445:195 446:195 447:196 448:196 449:197 450:197 451:198 452:198 453:199 454:199 455:199 456:200 457:200 458:200 459:201 460:201 461:201 462:202 463:202 464:203 465:203 466:204 467:205\n",
      "INFO:tensorflow:token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True 461:True 462:True 463:True 464:True 465:True 466:True 467:True\n",
      "I1125 11:12:38.363035 47903194205696 run_squad.py:408] token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True 461:True 462:True 463:True 464:True 465:True 466:True 467:True\n",
      "INFO:tensorflow:input_ids: 101 8888 29683 9318 10739 28188 25486 38688 11018 9294 119137 12030 11287 110871 102 9746 25486 11287 12605 110862 9426 42815 110862 9426 66554 11882 18589 9993 40958 25486 38688 11018 9665 32613 25701 8982 17342 11489 119708 12178 119862 10459 10832 119501 66982 10622 119611 12453 13767 55368 9568 38688 78686 119687 119829 22522 63185 119862 9460 48549 10459 11978 119501 66982 10622 9730 12508 12453 119798 10739 9121 110862 10195 119558 119852 119862 119708 10459 8929 119230 11882 120033 23466 10459 8929 45465 11102 9356 37568 11467 9993 40958 25486 38688 10459 119550 119722 62548 119561 48533 10530 22799 9993 40958 25486 38688 10459 107153 10622 9460 58303 10530 9637 79718 12178 119999 11489 41099 18154 9069 119187 119254 10739 119629 119780 19789 9993 40958 25486 38688 119550 10459 119561 10530 110463 9638 119979 66554 22333 10459 8898 12092 11102 9330 52363 11261 9640 13374 9672 16605 13441 8932 31531 120121 9981 47289 10459 8922 17730 10530 18154 9069 119187 119254 11467 39773 120805 10459 110176 10739 9485 37568 11102 119742 119555 52579 30085 9428 18623 20479 11489 25685 106280 9881 13764 120147 35979 103279 9854 37114 79604 110862 9940 28143 110862 9678 28143 110862 9318 10739 28188 100372 12605 105464 18589 9487 36210 24017 120200 110176 10530 30085 91785 9316 8898 105197 11102 9881 48959 9765 18623 12453 119547 9638 58844 9318 10739 28188 100372 12605 10530 9569 11882 9527 33975 8843 13374 119847 11102 9921 118906 110862 9376 12692 119304 11882 18589 8888 29683 9318 10739 28188 25486 38688 11513 119593 9569 20625 121028 119998 12178 120008 10739 68495 10622 75109 71767 14423 10003 30134 17655 120005 22440 119889 119654 9967 31531 8924 120008 10739 99958 9994 14423 59330 23925 9576 14871 29208 119798 14703 11889 10131 119680 10158 10113 119558 26565 18382 41195 119550 29208 13767 8888 29683 42144 10739 28188 9568 38688 119652 11018 9921 118906 11467 9672 36210 22333 9316 9284 36210 11287 28000 8896 13890 120355 9365 21386 29364 11261 119568 24683 9878 118969 10622 9612 38688 11261 119847 29208 108543 110862 9706 40032 11882 18589 9765 24982 11261 9284 36210 119394 118906 120008 10739 77039 120005 14843 28467 9678 19105 18784 9612 38688 120093 9316 9612 11287 9414 48210 10622 9757 37388 14843 119609 53371 42608 55600 23925 9576 118634 29208 119798 12396 10206 10131 119680 10195 119558 52579 9921 118906 10459 9612 38688 11261 9284 36210 11513 9069 29683 14843 9460 13767 39773 9318 10739 28188 100372 98500 9737 11018 27487 119873 119742 11489 119790 10530 119550 29208 13767 9921 118906 10459 9612 38688 11287 120145 119635 9365 21386 29364 11261 73131 9486 52951 20625 19709 119861 10459 9612 38688 11261 119550 59902 9523 32158 120116 119921 11287 9603 121549 85533 17022 8843 45465 10739 9663 118878 11102 9612 38688 10459 119550 10739 119629 14843 23925 119975 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.364417 47903194205696 run_squad.py:410] input_ids: 101 8888 29683 9318 10739 28188 25486 38688 11018 9294 119137 12030 11287 110871 102 9746 25486 11287 12605 110862 9426 42815 110862 9426 66554 11882 18589 9993 40958 25486 38688 11018 9665 32613 25701 8982 17342 11489 119708 12178 119862 10459 10832 119501 66982 10622 119611 12453 13767 55368 9568 38688 78686 119687 119829 22522 63185 119862 9460 48549 10459 11978 119501 66982 10622 9730 12508 12453 119798 10739 9121 110862 10195 119558 119852 119862 119708 10459 8929 119230 11882 120033 23466 10459 8929 45465 11102 9356 37568 11467 9993 40958 25486 38688 10459 119550 119722 62548 119561 48533 10530 22799 9993 40958 25486 38688 10459 107153 10622 9460 58303 10530 9637 79718 12178 119999 11489 41099 18154 9069 119187 119254 10739 119629 119780 19789 9993 40958 25486 38688 119550 10459 119561 10530 110463 9638 119979 66554 22333 10459 8898 12092 11102 9330 52363 11261 9640 13374 9672 16605 13441 8932 31531 120121 9981 47289 10459 8922 17730 10530 18154 9069 119187 119254 11467 39773 120805 10459 110176 10739 9485 37568 11102 119742 119555 52579 30085 9428 18623 20479 11489 25685 106280 9881 13764 120147 35979 103279 9854 37114 79604 110862 9940 28143 110862 9678 28143 110862 9318 10739 28188 100372 12605 105464 18589 9487 36210 24017 120200 110176 10530 30085 91785 9316 8898 105197 11102 9881 48959 9765 18623 12453 119547 9638 58844 9318 10739 28188 100372 12605 10530 9569 11882 9527 33975 8843 13374 119847 11102 9921 118906 110862 9376 12692 119304 11882 18589 8888 29683 9318 10739 28188 25486 38688 11513 119593 9569 20625 121028 119998 12178 120008 10739 68495 10622 75109 71767 14423 10003 30134 17655 120005 22440 119889 119654 9967 31531 8924 120008 10739 99958 9994 14423 59330 23925 9576 14871 29208 119798 14703 11889 10131 119680 10158 10113 119558 26565 18382 41195 119550 29208 13767 8888 29683 42144 10739 28188 9568 38688 119652 11018 9921 118906 11467 9672 36210 22333 9316 9284 36210 11287 28000 8896 13890 120355 9365 21386 29364 11261 119568 24683 9878 118969 10622 9612 38688 11261 119847 29208 108543 110862 9706 40032 11882 18589 9765 24982 11261 9284 36210 119394 118906 120008 10739 77039 120005 14843 28467 9678 19105 18784 9612 38688 120093 9316 9612 11287 9414 48210 10622 9757 37388 14843 119609 53371 42608 55600 23925 9576 118634 29208 119798 12396 10206 10131 119680 10195 119558 52579 9921 118906 10459 9612 38688 11261 9284 36210 11513 9069 29683 14843 9460 13767 39773 9318 10739 28188 100372 98500 9737 11018 27487 119873 119742 11489 119790 10530 119550 29208 13767 9921 118906 10459 9612 38688 11287 120145 119635 9365 21386 29364 11261 73131 9486 52951 20625 19709 119861 10459 9612 38688 11261 119550 59902 9523 32158 120116 119921 11287 9603 121549 85533 17022 8843 45465 10739 9663 118878 11102 9612 38688 10459 119550 10739 119629 14843 23925 119975 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.364580 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.364726 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.366178 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000002\n",
      "I1125 11:12:38.366271 47903194205696 run_squad.py:400] unique_id: 1000000002\n",
      "INFO:tensorflow:example_index: 2\n",
      "I1125 11:12:38.366331 47903194205696 run_squad.py:401] example_index: 2\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.366386 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 폐 ##경 ##( ##meno ##pa ##use ##)은 무 ##엇 ##인 ##가 ##? [SEP] 폐 ##경 ##( ##meno ##pa ##use ##)은 생 ##물 ##학적 개념 ##으로 [UNK] 기능 ##의 소 ##실 ##로 인해 일 ##어나 ##는 월 ##경 ##의 영 ##구 ##적인 [UNK] 의미 ##하며, 폐 ##경 전 ##후 일정 ##한 기 ##간을 포함 ##하는 생 ##물 ##학적 ##, 사회 ⋅ 문화 ##적 개념 ##을 갱 ##년 ##기 ##(C ##lima ##cter ##ic ##) ##라 한다. 갱 ##년 ##기의 호 ##르 ##몬 변화 ##와 그 ##로 인한 다양한 증 ##상 ##은 주로 40 ##대 중 ##후 ##반 ##에 발생 ##하며 그 시 ##점 ##은 일 ##률 ##적 ##이지 않고 증 ##상의 경 ##과 또한 다양 ##하다 ##1). 이를 갱 ##년 ##기 증 ##후 ##군 ##(C ##lima ##cter ##ic Syndrome ##)이라 한다. [SEP]\n",
      "I1125 11:12:38.366472 47903194205696 run_squad.py:404] tokens: [CLS] 폐 ##경 ##( ##meno ##pa ##use ##)은 무 ##엇 ##인 ##가 ##? [SEP] 폐 ##경 ##( ##meno ##pa ##use ##)은 생 ##물 ##학적 개념 ##으로 [UNK] 기능 ##의 소 ##실 ##로 인해 일 ##어나 ##는 월 ##경 ##의 영 ##구 ##적인 [UNK] 의미 ##하며, 폐 ##경 전 ##후 일정 ##한 기 ##간을 포함 ##하는 생 ##물 ##학적 ##, 사회 ⋅ 문화 ##적 개념 ##을 갱 ##년 ##기 ##(C ##lima ##cter ##ic ##) ##라 한다. 갱 ##년 ##기의 호 ##르 ##몬 변화 ##와 그 ##로 인한 다양한 증 ##상 ##은 주로 40 ##대 중 ##후 ##반 ##에 발생 ##하며 그 시 ##점 ##은 일 ##률 ##적 ##이지 않고 증 ##상의 경 ##과 또한 다양 ##하다 ##1). 이를 갱 ##년 ##기 증 ##후 ##군 ##(C ##lima ##cter ##ic Syndrome ##)이라 한다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 14:0 15:0 16:0 17:0 18:0 19:0 20:0 21:1 22:1 23:1 24:2 25:2 26:3 27:4 28:4 29:5 30:5 31:5 32:6 33:7 34:7 35:7 36:8 37:8 38:8 39:9 40:9 41:9 42:10 43:11 44:11 45:12 46:12 47:13 48:13 49:14 50:14 51:15 52:15 53:16 54:16 55:17 56:17 57:17 58:17 59:18 60:19 61:20 62:20 63:21 64:21 65:22 66:22 67:22 68:22 69:22 70:22 71:22 72:22 73:22 74:23 75:24 76:24 77:24 78:25 79:25 80:25 81:26 82:26 83:27 84:27 85:28 86:29 87:30 88:30 89:30 90:31 91:32 92:32 93:33 94:33 95:33 96:33 97:34 98:34 99:35 100:36 101:36 102:36 103:37 104:37 105:37 106:37 107:38 108:39 109:39 110:40 111:40 112:41 113:42 114:42 115:42 116:43 117:44 118:44 119:44 120:45 121:45 122:45 123:45 124:45 125:45 126:45 127:46 128:46 129:47\n",
      "I1125 11:12:38.366567 47903194205696 run_squad.py:406] token_to_orig_map: 14:0 15:0 16:0 17:0 18:0 19:0 20:0 21:1 22:1 23:1 24:2 25:2 26:3 27:4 28:4 29:5 30:5 31:5 32:6 33:7 34:7 35:7 36:8 37:8 38:8 39:9 40:9 41:9 42:10 43:11 44:11 45:12 46:12 47:13 48:13 49:14 50:14 51:15 52:15 53:16 54:16 55:17 56:17 57:17 58:17 59:18 60:19 61:20 62:20 63:21 64:21 65:22 66:22 67:22 68:22 69:22 70:22 71:22 72:22 73:22 74:23 75:24 76:24 77:24 78:25 79:25 80:25 81:26 82:26 83:27 84:27 85:28 86:29 87:30 88:30 89:30 90:31 91:32 92:32 93:33 94:33 95:33 96:33 97:34 98:34 99:35 100:36 101:36 102:36 103:37 104:37 105:37 106:37 107:38 108:39 109:39 110:40 111:40 112:41 113:42 114:42 115:42 116:43 117:44 118:44 119:44 120:45 121:45 122:45 123:45 124:45 125:45 126:45 127:46 128:46 129:47\n",
      "INFO:tensorflow:token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True\n",
      "I1125 11:12:38.366662 47903194205696 run_squad.py:408] token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True\n",
      "INFO:tensorflow:input_ids: 101 9927 31720 110858 55762 11359 12730 119748 9294 119137 12030 11287 110871 102 9927 31720 110858 55762 11359 12730 119748 9420 29364 87503 119739 11467 100 119646 10459 9448 31503 11261 39629 9641 120098 11018 9613 31720 10459 9574 17196 15387 100 119614 119780 9927 31720 9665 31531 120018 11102 8932 90295 119623 12178 9420 29364 87503 110862 119701 1827 119968 14801 119739 10622 8861 10954 12310 119936 43584 64334 11130 110859 17342 119575 8861 10954 46874 9985 31401 118936 119586 12638 8924 11261 119984 53645 9705 14871 10892 41195 10533 14423 9694 31531 30134 10530 119568 22766 8924 9485 34907 10892 9641 88350 14801 44359 45593 9705 70969 8885 11882 19789 120122 32679 120179 35756 8861 10954 12310 9705 31531 17360 119936 43584 64334 11130 108257 120458 119575 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.366819 47903194205696 run_squad.py:410] input_ids: 101 9927 31720 110858 55762 11359 12730 119748 9294 119137 12030 11287 110871 102 9927 31720 110858 55762 11359 12730 119748 9420 29364 87503 119739 11467 100 119646 10459 9448 31503 11261 39629 9641 120098 11018 9613 31720 10459 9574 17196 15387 100 119614 119780 9927 31720 9665 31531 120018 11102 8932 90295 119623 12178 9420 29364 87503 110862 119701 1827 119968 14801 119739 10622 8861 10954 12310 119936 43584 64334 11130 110859 17342 119575 8861 10954 46874 9985 31401 118936 119586 12638 8924 11261 119984 53645 9705 14871 10892 41195 10533 14423 9694 31531 30134 10530 119568 22766 8924 9485 34907 10892 9641 88350 14801 44359 45593 9705 70969 8885 11882 19789 120122 32679 120179 35756 8861 10954 12310 9705 31531 17360 119936 43584 64334 11130 108257 120458 119575 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.366965 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.367114 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.368921 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000003\n",
      "I1125 11:12:38.369008 47903194205696 run_squad.py:400] unique_id: 1000000003\n",
      "INFO:tensorflow:example_index: 3\n",
      "I1125 11:12:38.369072 47903194205696 run_squad.py:401] example_index: 3\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.369124 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 갱 ##년 ##기 증 ##후 ##군의 증 ##상으로 ##는 무 ##엇 ##이 있는 ##가 ##? [SEP] 갱 ##년 ##기 증 ##후 ##군 ##에서 가장 흔 ##히 나타나 ##는 증 ##상 ##은 안 ##면 홍 ##조 ##, 상 ##기 ##감 ##, 수 ##족 냉 ##증 등의 혈 ##관 ##운동 ##성 증 ##상이 ##다 ##2). 현대 ##의 ##학적으로 폐 ##경 ##기 여성 ##의 혈 ##관 ##운동 ##성 증 ##상 ##은 여성 호 ##르 ##몬 ##의 감소 ##로 인해 발생 ##한다. 여성 호 ##르 ##몬 ##이 감소 ##하면 혈 ##관 ##의 탄 ##성이 감소 ##되고 혈 ##중 저 ##밀 ##도 콜 ##레스 ##테 ##롤 ##의 농 ##도가 높아 ##지 ##며, 이는 곧 고 ##지 ##혈 ##증 ##, 동 ##맥 ##경 ##화 등의 심 ##혈 ##관계 ##질 ##환 뿐 아니라 안 ##면 ##홍 ##조 ##, 수 ##족 냉 ##증 ##과 같은 말 ##초 ##혈 ##관 순 ##환 장 ##애 ##를 초 ##래 ##한다 ##3). 그 외 자 ##율 ##신 ##경 ##계 ##의 기능 부 ##조 ##화 또한 말 ##초 ##혈 ##관 ##의 잦 ##은 확 ##장 ##과 수 ##축 ##을 유 ##발 ##한다. 이러한 경우 심 ##계 ##항 ##진 ##, 숨 ##참 등 심 ##장 ##박 ##동 ##의 이상 증 ##상이 동 ##반 ##되 ##기도 한다 ##4). 이에 폐 ##경 ##기 여성 ##의 안 ##면 홍 ##조 증 ##상이 혈 ##관 ##의 노 ##화 ##와 연 ##관 ##되어 있음을 확인 ##하고자 한 연구가 국내 ##외 ##로 진행 ##되어 왔 ##다 ##5 ##, ##6 ##). [SEP]\n",
      "I1125 11:12:38.369237 47903194205696 run_squad.py:404] tokens: [CLS] 갱 ##년 ##기 증 ##후 ##군의 증 ##상으로 ##는 무 ##엇 ##이 있는 ##가 ##? [SEP] 갱 ##년 ##기 증 ##후 ##군 ##에서 가장 흔 ##히 나타나 ##는 증 ##상 ##은 안 ##면 홍 ##조 ##, 상 ##기 ##감 ##, 수 ##족 냉 ##증 등의 혈 ##관 ##운동 ##성 증 ##상이 ##다 ##2). 현대 ##의 ##학적으로 폐 ##경 ##기 여성 ##의 혈 ##관 ##운동 ##성 증 ##상 ##은 여성 호 ##르 ##몬 ##의 감소 ##로 인해 발생 ##한다. 여성 호 ##르 ##몬 ##이 감소 ##하면 혈 ##관 ##의 탄 ##성이 감소 ##되고 혈 ##중 저 ##밀 ##도 콜 ##레스 ##테 ##롤 ##의 농 ##도가 높아 ##지 ##며, 이는 곧 고 ##지 ##혈 ##증 ##, 동 ##맥 ##경 ##화 등의 심 ##혈 ##관계 ##질 ##환 뿐 아니라 안 ##면 ##홍 ##조 ##, 수 ##족 냉 ##증 ##과 같은 말 ##초 ##혈 ##관 순 ##환 장 ##애 ##를 초 ##래 ##한다 ##3). 그 외 자 ##율 ##신 ##경 ##계 ##의 기능 부 ##조 ##화 또한 말 ##초 ##혈 ##관 ##의 잦 ##은 확 ##장 ##과 수 ##축 ##을 유 ##발 ##한다. 이러한 경우 심 ##계 ##항 ##진 ##, 숨 ##참 등 심 ##장 ##박 ##동 ##의 이상 증 ##상이 동 ##반 ##되 ##기도 한다 ##4). 이에 폐 ##경 ##기 여성 ##의 안 ##면 홍 ##조 증 ##상이 혈 ##관 ##의 노 ##화 ##와 연 ##관 ##되어 있음을 확인 ##하고자 한 연구가 국내 ##외 ##로 진행 ##되어 왔 ##다 ##5 ##, ##6 ##). [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 17:0 18:0 19:0 20:1 21:1 22:1 23:1 24:2 25:3 26:3 27:4 28:4 29:5 30:5 31:5 32:6 33:6 34:7 35:7 36:7 37:8 38:8 39:8 40:8 41:9 42:9 43:10 44:10 45:11 46:12 47:12 48:12 49:12 50:13 51:13 52:13 53:13 54:14 55:14 56:14 57:15 58:15 59:15 60:16 61:16 62:17 63:17 64:17 65:17 66:18 67:18 68:18 69:19 70:20 71:20 72:20 73:20 74:21 75:21 76:22 77:23 78:23 79:24 80:25 81:25 82:25 83:25 84:26 85:26 86:27 87:27 88:27 89:28 90:28 91:29 92:29 93:30 94:30 95:31 96:31 97:31 98:32 99:32 100:32 101:32 102:32 103:33 104:33 105:34 106:34 107:34 108:35 109:36 110:37 111:37 112:37 113:37 114:37 115:38 116:38 117:38 118:38 119:39 120:40 121:40 122:40 123:40 124:40 125:41 126:42 127:43 128:43 129:43 130:43 131:43 132:44 133:44 134:45 135:45 136:45 137:46 138:47 139:47 140:47 141:47 142:48 143:48 144:49 145:49 146:49 147:50 148:50 149:50 150:50 151:51 152:52 153:53 154:53 155:53 156:53 157:53 158:53 159:54 160:55 161:55 162:55 163:56 164:57 165:57 166:57 167:57 168:57 169:58 170:58 171:59 172:59 173:59 174:60 175:60 176:60 177:61 178:61 179:61 180:62 181:63 182:64 183:64 184:64 185:64 186:64 187:65 188:65 189:66 190:67 191:67 192:67 193:67 194:67 195:68 196:69 197:69 198:70 199:70 200:70 201:70 202:71 203:71 204:72 205:73 206:73 207:73 208:74 209:74 210:75 211:75 212:76 213:76 214:77 215:77 216:78 217:78 218:78 219:79 220:79 221:79 222:80 223:80 224:80 225:81 226:82 227:82 228:83 229:84 230:85 231:85 232:85 233:86 234:86 235:87 236:87 237:87 238:87 239:87 240:87\n",
      "I1125 11:12:38.369370 47903194205696 run_squad.py:406] token_to_orig_map: 17:0 18:0 19:0 20:1 21:1 22:1 23:1 24:2 25:3 26:3 27:4 28:4 29:5 30:5 31:5 32:6 33:6 34:7 35:7 36:7 37:8 38:8 39:8 40:8 41:9 42:9 43:10 44:10 45:11 46:12 47:12 48:12 49:12 50:13 51:13 52:13 53:13 54:14 55:14 56:14 57:15 58:15 59:15 60:16 61:16 62:17 63:17 64:17 65:17 66:18 67:18 68:18 69:19 70:20 71:20 72:20 73:20 74:21 75:21 76:22 77:23 78:23 79:24 80:25 81:25 82:25 83:25 84:26 85:26 86:27 87:27 88:27 89:28 90:28 91:29 92:29 93:30 94:30 95:31 96:31 97:31 98:32 99:32 100:32 101:32 102:32 103:33 104:33 105:34 106:34 107:34 108:35 109:36 110:37 111:37 112:37 113:37 114:37 115:38 116:38 117:38 118:38 119:39 120:40 121:40 122:40 123:40 124:40 125:41 126:42 127:43 128:43 129:43 130:43 131:43 132:44 133:44 134:45 135:45 136:45 137:46 138:47 139:47 140:47 141:47 142:48 143:48 144:49 145:49 146:49 147:50 148:50 149:50 150:50 151:51 152:52 153:53 154:53 155:53 156:53 157:53 158:53 159:54 160:55 161:55 162:55 163:56 164:57 165:57 166:57 167:57 168:57 169:58 170:58 171:59 172:59 173:59 174:60 175:60 176:60 177:61 178:61 179:61 180:62 181:63 182:64 183:64 184:64 185:64 186:64 187:65 188:65 189:66 190:67 191:67 192:67 193:67 194:67 195:68 196:69 197:69 198:70 199:70 200:70 201:70 202:71 203:71 204:72 205:73 206:73 207:73 208:74 209:74 210:75 211:75 212:76 213:76 214:77 215:77 216:78 217:78 218:78 219:79 220:79 221:79 222:80 223:80 224:80 225:81 226:82 227:82 228:83 229:84 230:85 231:85 232:85 233:86 234:86 235:87 236:87 237:87 238:87 239:87 240:87\n",
      "INFO:tensorflow:token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True\n",
      "I1125 11:12:38.369492 47903194205696 run_squad.py:408] token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True\n",
      "INFO:tensorflow:input_ids: 101 8861 10954 12310 9705 31531 46741 9705 82214 11018 9294 119137 10739 13767 11287 110871 102 8861 10954 12310 9705 31531 17360 11489 22224 10017 18108 119653 11018 9705 14871 10892 9521 14867 9992 20626 110862 9414 12310 105197 110862 9460 52560 9001 119230 28697 9979 20595 120203 17138 9705 83902 11903 120259 104518 10459 120380 9927 31720 12310 100006 10459 9979 20595 120203 17138 9705 14871 10892 100006 9985 31401 118936 10459 119598 11261 39629 119568 119554 100006 9985 31401 118936 10739 119598 38378 9979 20595 10459 9847 53371 119598 29208 9979 41693 9663 118958 12092 9815 100929 119351 118882 10459 9027 68516 120035 12508 119635 33904 8891 8888 12508 119433 119230 110862 9095 118915 31720 18227 28697 9491 119433 119995 48599 51745 9400 45021 9521 14867 119444 20626 110862 9460 52560 9001 119230 11882 18589 9251 57030 119433 20595 9462 51745 9657 119121 11513 9757 37388 14102 120252 8924 9597 9651 119183 25387 31720 21611 10459 119646 9365 20626 18227 19789 9251 57030 119433 20595 10459 9658 10892 9994 13890 11882 9460 70122 10622 9625 51431 119554 34079 28467 9491 21611 50632 18623 110862 9464 119251 9121 9491 13890 118963 18778 10459 66982 9705 83902 9095 30134 118800 27792 16139 120258 41099 9927 31720 12310 100006 10459 9521 14867 9992 20626 9705 83902 9979 20595 10459 9022 18227 12638 9568 20595 16855 119907 84300 119713 9954 119778 119687 78705 11261 119625 16855 9594 11903 11166 110862 11211 119558 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.369668 47903194205696 run_squad.py:410] input_ids: 101 8861 10954 12310 9705 31531 46741 9705 82214 11018 9294 119137 10739 13767 11287 110871 102 8861 10954 12310 9705 31531 17360 11489 22224 10017 18108 119653 11018 9705 14871 10892 9521 14867 9992 20626 110862 9414 12310 105197 110862 9460 52560 9001 119230 28697 9979 20595 120203 17138 9705 83902 11903 120259 104518 10459 120380 9927 31720 12310 100006 10459 9979 20595 120203 17138 9705 14871 10892 100006 9985 31401 118936 10459 119598 11261 39629 119568 119554 100006 9985 31401 118936 10739 119598 38378 9979 20595 10459 9847 53371 119598 29208 9979 41693 9663 118958 12092 9815 100929 119351 118882 10459 9027 68516 120035 12508 119635 33904 8891 8888 12508 119433 119230 110862 9095 118915 31720 18227 28697 9491 119433 119995 48599 51745 9400 45021 9521 14867 119444 20626 110862 9460 52560 9001 119230 11882 18589 9251 57030 119433 20595 9462 51745 9657 119121 11513 9757 37388 14102 120252 8924 9597 9651 119183 25387 31720 21611 10459 119646 9365 20626 18227 19789 9251 57030 119433 20595 10459 9658 10892 9994 13890 11882 9460 70122 10622 9625 51431 119554 34079 28467 9491 21611 50632 18623 110862 9464 119251 9121 9491 13890 118963 18778 10459 66982 9705 83902 9095 30134 118800 27792 16139 120258 41099 9927 31720 12310 100006 10459 9521 14867 9992 20626 9705 83902 9979 20595 10459 9022 18227 12638 9568 20595 16855 119907 84300 119713 9954 119778 119687 78705 11261 119625 16855 9594 11903 11166 110862 11211 119558 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.369825 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.369968 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.371602 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000004\n",
      "I1125 11:12:38.371698 47903194205696 run_squad.py:400] unique_id: 1000000004\n",
      "INFO:tensorflow:example_index: 4\n",
      "I1125 11:12:38.371754 47903194205696 run_squad.py:401] example_index: 4\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.371814 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] D ##T ##LS ##는 타 ##이 ##머 ##의 단 ##점을 보 ##완 ##한 기법 ##은 무 ##엇 ##인 ##가 ##? [SEP] 기존의 UDP ##에서 보 ##안 ##기능 ##을 지원 ##하는 프로 ##토 ##콜 ##인 D ##T ##LS ##는 타 ##이 ##머 ##( ##T ##imer ##)를 이용한 부분 ##적인 에 ##러 제어 기능 ##만 ##을 지원 ##하는 단 ##점이 있다 ##[ ##13 ##] ##. RL ##P ##는 이런 단 ##점을 보 ##완 ##하기 위해 AR ##Q ##( ##A ##utom ##atic Rep ##eat Re ##quest ##) 기법 중 정 ##지 ##대 ##기 ##방식 ##(Sto ##p and Wait ##, I ##dle AR ##Q ##) ##[ ##14 ##] ##을 이용하여 에 ##러 ##를 제어 ##하도록 하였다. IS ##P ##와 D ##TP ##에서 송 ##신 ##한 데이터 ##는 하 ##위 계 ##층 ##인 RL ##P ##에서 UDP ##의 MT ##U ##에 맞 ##게 단 ##편 ##화 ##하여 송 ##신 ##되고, 이 ##렇게 나 ##누 ##어진 데이터를 수 ##신 ##측 RL ##P ##에서 재 ##조 ##립 ##하여 수 ##신 ##측 IS ##P ##와 D ##TP ##로 전송 ##하게 된다. [SEP]\n",
      "I1125 11:12:38.371912 47903194205696 run_squad.py:404] tokens: [CLS] D ##T ##LS ##는 타 ##이 ##머 ##의 단 ##점을 보 ##완 ##한 기법 ##은 무 ##엇 ##인 ##가 ##? [SEP] 기존의 UDP ##에서 보 ##안 ##기능 ##을 지원 ##하는 프로 ##토 ##콜 ##인 D ##T ##LS ##는 타 ##이 ##머 ##( ##T ##imer ##)를 이용한 부분 ##적인 에 ##러 제어 기능 ##만 ##을 지원 ##하는 단 ##점이 있다 ##[ ##13 ##] ##. RL ##P ##는 이런 단 ##점을 보 ##완 ##하기 위해 AR ##Q ##( ##A ##utom ##atic Rep ##eat Re ##quest ##) 기법 중 정 ##지 ##대 ##기 ##방식 ##(Sto ##p and Wait ##, I ##dle AR ##Q ##) ##[ ##14 ##] ##을 이용하여 에 ##러 ##를 제어 ##하도록 하였다. IS ##P ##와 D ##TP ##에서 송 ##신 ##한 데이터 ##는 하 ##위 계 ##층 ##인 RL ##P ##에서 UDP ##의 MT ##U ##에 맞 ##게 단 ##편 ##화 ##하여 송 ##신 ##되고, 이 ##렇게 나 ##누 ##어진 데이터를 수 ##신 ##측 RL ##P ##에서 재 ##조 ##립 ##하여 수 ##신 ##측 IS ##P ##와 D ##TP ##로 전송 ##하게 된다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 22:0 23:1 24:1 25:2 26:2 27:2 28:2 29:3 30:3 31:4 32:4 33:4 34:4 35:5 36:5 37:5 38:5 39:6 40:6 41:6 42:6 43:6 44:6 45:6 46:7 47:8 48:8 49:9 50:9 51:10 52:11 53:11 54:11 55:12 56:12 57:13 58:13 59:14 60:14 61:14 62:14 63:14 64:15 65:15 66:15 67:16 68:17 69:17 70:18 71:18 72:18 73:19 74:20 75:20 76:20 77:20 78:20 79:20 80:21 81:21 82:22 83:22 84:22 85:23 86:24 87:25 88:25 89:25 90:25 91:25 92:25 93:25 94:26 95:27 96:27 97:28 98:28 99:29 100:29 101:29 102:29 103:29 104:29 105:29 106:30 107:31 108:31 109:31 110:32 111:32 112:33 113:34 114:34 115:34 116:35 117:35 118:35 119:36 120:36 121:36 122:37 123:37 124:38 125:38 126:39 127:39 128:39 129:40 130:40 131:40 132:41 133:41 134:42 135:42 136:42 137:43 138:43 139:44 140:44 141:44 142:44 143:45 144:45 145:45 146:46 147:46 148:47 149:47 150:47 151:48 152:49 153:49 154:49 155:50 156:50 157:50 158:51 159:51 160:51 161:51 162:52 163:52 164:52 165:53 166:53 167:53 168:54 169:54 170:54 171:55 172:55 173:56\n",
      "I1125 11:12:38.372019 47903194205696 run_squad.py:406] token_to_orig_map: 22:0 23:1 24:1 25:2 26:2 27:2 28:2 29:3 30:3 31:4 32:4 33:4 34:4 35:5 36:5 37:5 38:5 39:6 40:6 41:6 42:6 43:6 44:6 45:6 46:7 47:8 48:8 49:9 50:9 51:10 52:11 53:11 54:11 55:12 56:12 57:13 58:13 59:14 60:14 61:14 62:14 63:14 64:15 65:15 66:15 67:16 68:17 69:17 70:18 71:18 72:18 73:19 74:20 75:20 76:20 77:20 78:20 79:20 80:21 81:21 82:22 83:22 84:22 85:23 86:24 87:25 88:25 89:25 90:25 91:25 92:25 93:25 94:26 95:27 96:27 97:28 98:28 99:29 100:29 101:29 102:29 103:29 104:29 105:29 106:30 107:31 108:31 109:31 110:32 111:32 112:33 113:34 114:34 115:34 116:35 117:35 118:35 119:36 120:36 121:36 122:37 123:37 124:38 125:38 126:39 127:39 128:39 129:40 130:40 131:40 132:41 133:41 134:42 135:42 136:42 137:43 138:43 139:44 140:44 141:44 142:44 143:45 144:45 145:45 146:46 147:46 148:47 149:47 150:47 151:48 152:49 153:49 154:49 155:50 156:50 157:50 158:51 159:51 160:51 161:51 162:52 163:52 164:52 165:53 166:53 167:53 168:54 169:54 170:54 171:55 172:55 173:56\n",
      "INFO:tensorflow:token_is_max_context: 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True\n",
      "I1125 11:12:38.372114 47903194205696 run_squad.py:408] token_is_max_context: 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True\n",
      "INFO:tensorflow:input_ids: 101 141 11090 66934 11018 9845 10739 118920 10459 9059 67477 9356 119160 11102 119878 10892 9294 119137 12030 11287 110871 102 119977 94929 11489 9356 34951 120123 10622 119752 12178 102574 26444 119308 12030 141 11090 66934 11018 9845 10739 118920 110858 11090 121192 119638 119728 119725 15387 9559 30873 119808 119646 19105 10622 119752 12178 9059 119928 11506 110873 45389 110875 110864 109478 11127 11018 80956 9059 67477 9356 119160 22440 19905 50884 19282 110858 10738 74777 69252 72337 52064 20304 93877 110859 119878 9694 9670 12508 14423 12310 120117 122080 10410 10111 87519 110862 146 27477 50884 19282 110859 110873 39900 110875 10622 119593 9559 30873 11513 119808 119916 119626 40214 11127 12638 141 36966 11489 9454 25387 11102 119633 11018 9952 19855 8887 70450 12030 109478 11127 11489 94929 10459 74649 12022 10530 9256 14153 9059 50450 18227 13374 9454 25387 120262 9638 82838 8982 118751 46572 120105 9460 25387 119281 109478 11127 11489 9659 20626 35115 13374 9460 25387 119281 40214 11127 12638 141 36966 11261 120038 17594 119684 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.372284 47903194205696 run_squad.py:410] input_ids: 101 141 11090 66934 11018 9845 10739 118920 10459 9059 67477 9356 119160 11102 119878 10892 9294 119137 12030 11287 110871 102 119977 94929 11489 9356 34951 120123 10622 119752 12178 102574 26444 119308 12030 141 11090 66934 11018 9845 10739 118920 110858 11090 121192 119638 119728 119725 15387 9559 30873 119808 119646 19105 10622 119752 12178 9059 119928 11506 110873 45389 110875 110864 109478 11127 11018 80956 9059 67477 9356 119160 22440 19905 50884 19282 110858 10738 74777 69252 72337 52064 20304 93877 110859 119878 9694 9670 12508 14423 12310 120117 122080 10410 10111 87519 110862 146 27477 50884 19282 110859 110873 39900 110875 10622 119593 9559 30873 11513 119808 119916 119626 40214 11127 12638 141 36966 11489 9454 25387 11102 119633 11018 9952 19855 8887 70450 12030 109478 11127 11489 94929 10459 74649 12022 10530 9256 14153 9059 50450 18227 13374 9454 25387 120262 9638 82838 8982 118751 46572 120105 9460 25387 119281 109478 11127 11489 9659 20626 35115 13374 9460 25387 119281 40214 11127 12638 141 36966 11261 120038 17594 119684 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.372433 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.372580 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.374008 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000005\n",
      "I1125 11:12:38.374097 47903194205696 run_squad.py:400] unique_id: 1000000005\n",
      "INFO:tensorflow:example_index: 5\n",
      "I1125 11:12:38.374156 47903194205696 run_squad.py:401] example_index: 5\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.374212 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 무 ##선 ##통 ##신 기술 활용 ##이 증가 ##함 ##에 야 ##기 ##되는 문제 ##점 ##은 무 ##엇 ##인 ##가 ##? [SEP] 하지만 무 ##선 ##통 ##신 기술 활용 ##이 증가 ##하면서 MIT ##M ##( ##M ##an ##- ##in ##- ##the ##- ##M ##idd ##le ##) 공 ##격 ##, 재 ##전송 공 ##격 ##과 같은 공 ##격 ##들 ##도 증가 ##하여 보 ##안 ##상의 위험 ##이 야 ##기 ##되었다 ##[ ##4 ##] ##. 예를 들어 차 ##량 추 ##돌 사고 ##를 알 ##리는 데이터 ##가 노 ##출 ##되어 제 ##3 ##자 ##에 의해 변 ##조 ##되었 ##을 때 ##, 1 ##차 충 ##돌 ##로 끝 ##날 수 있는 사고 ##가 더 큰 사고 ##로 이어 ##질 수 있다. 이러한 이유로 본 논문 ##에서는 W ##AV ##E 통 ##신 시스템 ##에서 안전 ##하게 통 ##신 ##하기 위한 보 ##안 ##통 ##신 프로 ##토 ##콜 ##을 제안 ##하였다. [SEP]\n",
      "I1125 11:12:38.374304 47903194205696 run_squad.py:404] tokens: [CLS] 무 ##선 ##통 ##신 기술 활용 ##이 증가 ##함 ##에 야 ##기 ##되는 문제 ##점 ##은 무 ##엇 ##인 ##가 ##? [SEP] 하지만 무 ##선 ##통 ##신 기술 활용 ##이 증가 ##하면서 MIT ##M ##( ##M ##an ##- ##in ##- ##the ##- ##M ##idd ##le ##) 공 ##격 ##, 재 ##전송 공 ##격 ##과 같은 공 ##격 ##들 ##도 증가 ##하여 보 ##안 ##상의 위험 ##이 야 ##기 ##되었다 ##[ ##4 ##] ##. 예를 들어 차 ##량 추 ##돌 사고 ##를 알 ##리는 데이터 ##가 노 ##출 ##되어 제 ##3 ##자 ##에 의해 변 ##조 ##되었 ##을 때 ##, 1 ##차 충 ##돌 ##로 끝 ##날 수 있는 사고 ##가 더 큰 사고 ##로 이어 ##질 수 있다. 이러한 이유로 본 논문 ##에서는 W ##AV ##E 통 ##신 시스템 ##에서 안전 ##하게 통 ##신 ##하기 위한 보 ##안 ##통 ##신 프로 ##토 ##콜 ##을 제안 ##하였다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 23:0 24:1 25:1 26:1 27:1 28:2 29:3 30:3 31:4 32:4 33:5 34:5 35:5 36:5 37:5 38:5 39:5 40:5 41:5 42:5 43:5 44:5 45:5 46:5 47:6 48:6 49:6 50:7 51:7 52:8 53:8 54:8 55:9 56:10 57:10 58:10 59:10 60:11 61:11 62:12 63:12 64:12 65:13 66:13 67:14 68:14 69:14 70:14 71:14 72:14 73:14 74:15 75:16 76:17 77:17 78:18 79:18 80:19 81:19 82:20 83:20 84:21 85:21 86:22 87:22 88:22 89:23 90:23 91:23 92:23 93:24 94:25 95:25 96:25 97:25 98:26 99:26 100:27 101:27 102:28 103:28 104:28 105:29 106:29 107:30 108:31 109:32 110:32 111:33 112:34 113:35 114:35 115:36 116:36 117:37 118:38 119:39 120:40 121:41 122:42 123:42 124:43 125:43 126:43 127:44 128:44 129:45 130:45 131:46 132:46 133:47 134:47 135:47 136:48 137:49 138:49 139:49 140:49 141:50 142:50 143:50 144:50 145:51 146:51\n",
      "I1125 11:12:38.374402 47903194205696 run_squad.py:406] token_to_orig_map: 23:0 24:1 25:1 26:1 27:1 28:2 29:3 30:3 31:4 32:4 33:5 34:5 35:5 36:5 37:5 38:5 39:5 40:5 41:5 42:5 43:5 44:5 45:5 46:5 47:6 48:6 49:6 50:7 51:7 52:8 53:8 54:8 55:9 56:10 57:10 58:10 59:10 60:11 61:11 62:12 63:12 64:12 65:13 66:13 67:14 68:14 69:14 70:14 71:14 72:14 73:14 74:15 75:16 76:17 77:17 78:18 79:18 80:19 81:19 82:20 83:20 84:21 85:21 86:22 87:22 88:22 89:23 90:23 91:23 92:23 93:24 94:25 95:25 96:25 97:25 98:26 99:26 100:27 101:27 102:28 103:28 104:28 105:29 106:29 107:30 108:31 109:32 110:32 111:33 112:34 113:35 114:35 115:36 116:36 117:37 118:38 119:39 120:40 121:41 122:42 123:42 124:43 125:43 126:43 127:44 128:44 129:45 130:45 131:46 132:46 133:47 134:47 135:47 136:48 137:49 138:49 139:49 140:49 141:50 142:50 143:50 144:50 145:51 146:51\n",
      "INFO:tensorflow:token_is_max_context: 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True\n",
      "I1125 11:12:38.374495 47903194205696 run_squad.py:408] token_is_max_context: 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True\n",
      "INFO:tensorflow:input_ids: 101 9294 18471 43022 25387 119578 119577 10739 119561 48533 10530 9538 12310 24683 119581 34907 10892 9294 119137 12030 11287 110871 102 32775 9294 18471 43022 25387 119578 119577 10739 119561 37341 31472 11517 110858 11517 10206 110863 10245 110863 26900 110863 11517 45591 10284 110859 8896 45465 110862 9659 120605 8896 45465 11882 18589 8896 45465 27023 12092 119561 13374 9356 34951 70969 119827 10739 9538 12310 13628 110873 11011 110875 110864 85379 71568 9730 44321 9765 118794 119954 11513 9524 26344 119633 11287 9022 52363 16855 9672 10884 13764 10530 23610 9352 20626 119587 10622 9137 110862 122 23466 9770 118794 11261 8977 41919 9460 13767 119954 11287 9074 9835 119954 11261 64749 48599 9460 119547 34079 89184 9358 119691 23635 160 99903 11259 9879 25387 119597 11489 119741 17594 9879 25387 22440 28195 9356 34951 43022 25387 102574 26444 119308 10622 119670 119548 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.374660 47903194205696 run_squad.py:410] input_ids: 101 9294 18471 43022 25387 119578 119577 10739 119561 48533 10530 9538 12310 24683 119581 34907 10892 9294 119137 12030 11287 110871 102 32775 9294 18471 43022 25387 119578 119577 10739 119561 37341 31472 11517 110858 11517 10206 110863 10245 110863 26900 110863 11517 45591 10284 110859 8896 45465 110862 9659 120605 8896 45465 11882 18589 8896 45465 27023 12092 119561 13374 9356 34951 70969 119827 10739 9538 12310 13628 110873 11011 110875 110864 85379 71568 9730 44321 9765 118794 119954 11513 9524 26344 119633 11287 9022 52363 16855 9672 10884 13764 10530 23610 9352 20626 119587 10622 9137 110862 122 23466 9770 118794 11261 8977 41919 9460 13767 119954 11287 9074 9835 119954 11261 64749 48599 9460 119547 34079 89184 9358 119691 23635 160 99903 11259 9879 25387 119597 11489 119741 17594 9879 25387 22440 28195 9356 34951 43022 25387 102574 26444 119308 10622 119670 119548 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.374816 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.374960 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.376148 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000006\n",
      "I1125 11:12:38.376238 47903194205696 run_squad.py:400] unique_id: 1000000006\n",
      "INFO:tensorflow:example_index: 6\n",
      "I1125 11:12:38.376298 47903194205696 run_squad.py:401] example_index: 6\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.376346 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 음 ##향 ##방 ##사 ##효율 ##은 어떤 지 ##표 ##로 ##써 사용 ##되는 ##가 ##? [SEP] 수 ##중 운동 ##체의 수 ##중 ##방 ##사 ##소 ##음 ##은 소 ##나 ##를 이용한 운동 ##체의 탐 ##지 및 식 ##별 ##에 중요한 영향을 미치는 인 ##자 ##이다. 운동 ##체의 기 ##계 ##적 진 ##동 특성 ##에 따라 수 ##중 ##방 ##사 ##소 ##음을 예측 ##하고 소 ##음 ##원의 소 ##음 특성을 잘 표현 ##할 수 있는 지 ##표 ##로 ##써 음 ##향 ##방 ##사 ##효율 ##이 사용 ##된다. 음 ##향 ##방 ##사 ##효율 ##은 구조 ##물 표면 ##의 진 ##동 ##에너지 수준 ##에 대한 총 음 ##향 ##방 ##사 에너지 ##의 비 ##로 ##써 정의 ##된다. [SEP]\n",
      "I1125 11:12:38.376425 47903194205696 run_squad.py:404] tokens: [CLS] 음 ##향 ##방 ##사 ##효율 ##은 어떤 지 ##표 ##로 ##써 사용 ##되는 ##가 ##? [SEP] 수 ##중 운동 ##체의 수 ##중 ##방 ##사 ##소 ##음 ##은 소 ##나 ##를 이용한 운동 ##체의 탐 ##지 및 식 ##별 ##에 중요한 영향을 미치는 인 ##자 ##이다. 운동 ##체의 기 ##계 ##적 진 ##동 특성 ##에 따라 수 ##중 ##방 ##사 ##소 ##음을 예측 ##하고 소 ##음 ##원의 소 ##음 특성을 잘 표현 ##할 수 있는 지 ##표 ##로 ##써 음 ##향 ##방 ##사 ##효율 ##이 사용 ##된다. 음 ##향 ##방 ##사 ##효율 ##은 구조 ##물 표면 ##의 진 ##동 ##에너지 수준 ##에 대한 총 음 ##향 ##방 ##사 에너지 ##의 비 ##로 ##써 정의 ##된다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 17:0 18:0 19:1 20:1 21:2 22:2 23:2 24:2 25:2 26:2 27:2 28:3 29:3 30:3 31:4 32:5 33:5 34:6 35:6 36:7 37:8 38:8 39:8 40:9 41:10 42:11 43:12 44:12 45:12 46:13 47:13 48:14 49:14 50:14 51:15 52:15 53:16 54:16 55:17 56:18 57:18 58:18 59:18 60:18 61:18 62:19 63:19 64:20 65:20 66:20 67:21 68:21 69:22 70:23 71:24 72:24 73:25 74:26 75:27 76:27 77:27 78:27 79:28 80:28 81:28 82:28 83:28 84:28 85:29 86:29 87:30 88:30 89:30 90:30 91:30 92:30 93:31 94:31 95:32 96:32 97:33 98:33 99:33 100:34 101:34 102:35 103:36 104:37 105:37 106:37 107:37 108:38 109:38 110:39 111:39 112:39 113:40 114:40\n",
      "I1125 11:12:38.376520 47903194205696 run_squad.py:406] token_to_orig_map: 17:0 18:0 19:1 20:1 21:2 22:2 23:2 24:2 25:2 26:2 27:2 28:3 29:3 30:3 31:4 32:5 33:5 34:6 35:6 36:7 37:8 38:8 39:8 40:9 41:10 42:11 43:12 44:12 45:12 46:13 47:13 48:14 49:14 50:14 51:15 52:15 53:16 54:16 55:17 56:18 57:18 58:18 59:18 60:18 61:18 62:19 63:19 64:20 65:20 66:20 67:21 68:21 69:22 70:23 71:24 72:24 73:25 74:26 75:27 76:27 77:27 78:27 79:28 80:28 81:28 82:28 83:28 84:28 85:29 86:29 87:30 88:30 89:30 90:30 91:30 92:30 93:31 94:31 95:32 96:32 97:33 98:33 99:33 100:34 101:34 102:35 103:36 104:37 105:37 106:37 107:37 108:38 109:38 110:39 111:39 112:39 113:40 114:40\n",
      "INFO:tensorflow:token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True\n",
      "I1125 11:12:38.376606 47903194205696 run_squad.py:408] token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True\n",
      "INFO:tensorflow:input_ids: 101 9634 79544 42337 12945 120152 10892 55910 9706 37824 11261 73131 119550 24683 11287 110871 102 9460 41693 119899 79025 9460 41693 42337 12945 22333 32158 10892 9448 16439 11513 119728 119899 79025 9849 12508 9316 9486 61844 10530 63552 58088 119610 9640 13764 119555 119899 79025 8932 21611 14801 9708 18778 119601 10530 22799 9460 41693 42337 12945 22333 59724 119759 12453 9448 32158 74125 9448 32158 119772 9654 119750 14843 9460 13767 9706 37824 11261 73131 9634 79544 42337 12945 120152 10739 119550 119574 9634 79544 42337 12945 120152 10892 119605 29364 119867 10459 9708 18778 120200 119636 10530 18154 9761 9634 79544 42337 12945 119862 10459 9379 11261 73131 119765 119574 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.376767 47903194205696 run_squad.py:410] input_ids: 101 9634 79544 42337 12945 120152 10892 55910 9706 37824 11261 73131 119550 24683 11287 110871 102 9460 41693 119899 79025 9460 41693 42337 12945 22333 32158 10892 9448 16439 11513 119728 119899 79025 9849 12508 9316 9486 61844 10530 63552 58088 119610 9640 13764 119555 119899 79025 8932 21611 14801 9708 18778 119601 10530 22799 9460 41693 42337 12945 22333 59724 119759 12453 9448 32158 74125 9448 32158 119772 9654 119750 14843 9460 13767 9706 37824 11261 73131 9634 79544 42337 12945 120152 10739 119550 119574 9634 79544 42337 12945 120152 10892 119605 29364 119867 10459 9708 18778 120200 119636 10530 18154 9761 9634 79544 42337 12945 119862 10459 9379 11261 73131 119765 119574 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.376919 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.377060 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.378447 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000007\n",
      "I1125 11:12:38.378536 47903194205696 run_squad.py:400] unique_id: 1000000007\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1125 11:12:38.378590 47903194205696 run_squad.py:401] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.378638 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 소 ##나 음 ##원의 경우에는 벽 ##면 반 ##사 ##파 ##가 도 ##달 ##하기 전에 방 ##사 ##된 음 ##파 ##를 계 ##측 ##하는 방법 ##( ##gate ##d pu ##lse method ##)을 사용하는 ##데 어떤 경우 ##에 사용 ##이 가능한 ##가 ##? [SEP] 일반적으로 소 ##나 ##( ##sona ##r ##) 음 ##원의 경우에는 벽 ##면 반 ##사 ##파 ##가 도 ##달 ##하기 전에 방 ##사 ##된 음 ##파 ##를 계 ##측 ##하는 방법 ##( ##gate ##d pu ##lse method ##)을 사용한다 ##. 이 방법 ##은 음 ##원의 출 ##력이 정 ##상 ##상태 ##( ##ste ##ady state ##) ##까지 매우 급 ##격 ##하게 증가 ##하는 경우 ##에 사용 ##할 수 있다. 그러나 수 ##중 ##무 ##기 ##체 ##계 ##와 같이 내부 ##의 기 ##계 ##류 진 ##동 ##에 의한 소 ##음 ##원은 이러한 빠 ##른 응답 ##을 보 ##일 수 없 ##으므로 적용 불 ##가능 ##하다. [SEP]\n",
      "I1125 11:12:38.378741 47903194205696 run_squad.py:404] tokens: [CLS] 소 ##나 음 ##원의 경우에는 벽 ##면 반 ##사 ##파 ##가 도 ##달 ##하기 전에 방 ##사 ##된 음 ##파 ##를 계 ##측 ##하는 방법 ##( ##gate ##d pu ##lse method ##)을 사용하는 ##데 어떤 경우 ##에 사용 ##이 가능한 ##가 ##? [SEP] 일반적으로 소 ##나 ##( ##sona ##r ##) 음 ##원의 경우에는 벽 ##면 반 ##사 ##파 ##가 도 ##달 ##하기 전에 방 ##사 ##된 음 ##파 ##를 계 ##측 ##하는 방법 ##( ##gate ##d pu ##lse method ##)을 사용한다 ##. 이 방법 ##은 음 ##원의 출 ##력이 정 ##상 ##상태 ##( ##ste ##ady state ##) ##까지 매우 급 ##격 ##하게 증가 ##하는 경우 ##에 사용 ##할 수 있다. 그러나 수 ##중 ##무 ##기 ##체 ##계 ##와 같이 내부 ##의 기 ##계 ##류 진 ##동 ##에 의한 소 ##음 ##원은 이러한 빠 ##른 응답 ##을 보 ##일 수 없 ##으므로 적용 불 ##가능 ##하다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 44:0 45:1 46:1 47:1 48:1 49:1 50:1 51:2 52:2 53:3 54:4 55:4 56:5 57:5 58:5 59:5 60:6 61:6 62:6 63:7 64:8 65:8 66:8 67:9 68:9 69:9 70:10 71:10 72:10 73:11 74:11 75:11 76:11 77:12 78:12 79:13 80:13 81:14 82:14 83:15 84:16 85:16 86:17 87:17 88:18 89:18 90:19 91:19 92:19 93:19 94:19 95:19 96:20 97:20 98:20 99:21 100:22 101:22 102:22 103:23 104:23 105:24 106:24 107:25 108:25 109:26 110:27 111:28 112:29 113:29 114:29 115:29 116:29 117:29 118:29 119:30 120:31 121:31 122:32 123:32 124:32 125:33 126:33 127:33 128:34 129:35 130:35 131:35 132:36 133:37 134:37 135:38 136:38 137:39 138:39 139:40 140:41 141:41 142:42 143:43 144:43 145:43\n",
      "I1125 11:12:38.378836 47903194205696 run_squad.py:406] token_to_orig_map: 44:0 45:1 46:1 47:1 48:1 49:1 50:1 51:2 52:2 53:3 54:4 55:4 56:5 57:5 58:5 59:5 60:6 61:6 62:6 63:7 64:8 65:8 66:8 67:9 68:9 69:9 70:10 71:10 72:10 73:11 74:11 75:11 76:11 77:12 78:12 79:13 80:13 81:14 82:14 83:15 84:16 85:16 86:17 87:17 88:18 89:18 90:19 91:19 92:19 93:19 94:19 95:19 96:20 97:20 98:20 99:21 100:22 101:22 102:22 103:23 104:23 105:24 106:24 107:25 108:25 109:26 110:27 111:28 112:29 113:29 114:29 115:29 116:29 117:29 118:29 119:30 120:31 121:31 122:32 123:32 124:32 125:33 126:33 127:33 128:34 129:35 130:35 131:35 132:36 133:37 134:37 135:38 136:38 137:39 138:39 139:40 140:41 141:41 142:42 143:43 144:43 145:43\n",
      "INFO:tensorflow:token_is_max_context: 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True\n",
      "I1125 11:12:38.378918 47903194205696 run_squad.py:408] token_is_max_context: 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True\n",
      "INFO:tensorflow:input_ids: 101 9448 16439 9634 74125 120056 9351 14867 9321 12945 46150 11287 9087 89851 22440 91069 9328 12945 13441 9634 46150 11513 8887 119281 12178 119567 110858 21305 10162 34597 14433 22414 119643 94794 28911 55910 28467 10530 119550 10739 120015 11287 110871 102 79055 9448 16439 110858 79825 10129 110859 9634 74125 120056 9351 14867 9321 12945 46150 11287 9087 89851 22440 91069 9328 12945 13441 9634 46150 11513 8887 119281 12178 119567 110858 21305 10162 34597 14433 22414 119643 110475 110864 9638 119567 10892 9634 74125 9768 61964 9670 14871 119946 110858 11157 51210 11388 110859 18382 42608 8929 45465 17594 119561 12178 28467 10530 119550 14843 9460 119547 21890 9460 41693 32537 12310 29683 21611 12638 38401 119856 10459 8932 21611 46520 9708 18778 10530 60804 9448 32158 84467 34079 9388 37819 119796 10622 9356 18392 9460 9555 120059 119564 9368 120143 119793 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.379075 47903194205696 run_squad.py:410] input_ids: 101 9448 16439 9634 74125 120056 9351 14867 9321 12945 46150 11287 9087 89851 22440 91069 9328 12945 13441 9634 46150 11513 8887 119281 12178 119567 110858 21305 10162 34597 14433 22414 119643 94794 28911 55910 28467 10530 119550 10739 120015 11287 110871 102 79055 9448 16439 110858 79825 10129 110859 9634 74125 120056 9351 14867 9321 12945 46150 11287 9087 89851 22440 91069 9328 12945 13441 9634 46150 11513 8887 119281 12178 119567 110858 21305 10162 34597 14433 22414 119643 110475 110864 9638 119567 10892 9634 74125 9768 61964 9670 14871 119946 110858 11157 51210 11388 110859 18382 42608 8929 45465 17594 119561 12178 28467 10530 119550 14843 9460 119547 21890 9460 41693 32537 12310 29683 21611 12638 38401 119856 10459 8932 21611 46520 9708 18778 10530 60804 9448 32158 84467 34079 9388 37819 119796 10622 9356 18392 9460 9555 120059 119564 9368 120143 119793 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.379227 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.379369 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.382489 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000008\n",
      "I1125 11:12:38.382579 47903194205696 run_squad.py:400] unique_id: 1000000008\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1125 11:12:38.382643 47903194205696 run_squad.py:401] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.382699 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 미국 ##은 구조 ##물의 내 ##진 ##성능 강 ##화를 위해 어떤 철 ##근 ##을 적용 ##하였 ##는 ##가 ##? [SEP] 미국의 경우 1994년 노 ##스 ##리 ##지 ##( ##N ##orth ##ridge ##) 지 ##진 ##의 경험 ##으로 구조 ##물의 내 ##진 ##성능 ##을 강 ##화 ##하기 위하여 AS ##TM A ##99 ##2 형 과 AS ##TM A7 ##0 ##6 ##M 철 ##근 ##을 적용 ##하도록 하였다. 다 ##수의 철 ##강 ##회 ##사에 ##서 내 ##진 ##성능 ##을 강 ##화 ##한 강 ##재 ##를 생산 ##하고 있으며, 내 ##진 ##용 철 ##근 ##으로서 ##, 소 ##성 변 ##형 능 ##력 향상을 위한 항 ##복 ##강 ##도 상 ##한 및 하 ##한 규 ##정 ##, 항 ##복 ##비 상 ##한 규 ##정 ##, 용 ##접 ##성능 향상을 위한 탄 ##소 ##당 ##량 상 ##한 규 ##정 ##, 충 ##격 흡 ##수 능 ##력 향상을 위한 샤 ##르 ##피 흡 ##수 ##에너지 하 ##한 규 ##정 ##과 같은 요구조건 ##이 충 ##족 ##되는 철 ##근 ##을 생산 ##하고 있다. 일본 ##은 신 ##일 ##본 ##제 ##철 ##에서 개발 ##한 SD ##6 ##85 ##급 ##을 시 ##범 ##적으로 신 ##축 공 ##사 현장 ##에 적용 ##한 바 있으며, 1995년 고 ##베 지 ##진 ##을 겪 ##으면 ##서 각 ##종 설계 ##기준 ##에 구조 ##물의 내 ##진 ##성능 ##을 강 ##화 ##하면서 내 ##진 ##성능 ##이 우 ##수 ##한 강 ##종 ##을 도입 ##하였다. J ##IS G 313 ##6 등 내 ##진 ##성능 ##강 ##화 ##강 종 ##(S ##N ##강 ##종 ##) 표준 ##을 제 ##정 ##하여 사용 ##하고 있다. 신 ##일 ##본 ##제 ##철 ##에서는 내 ##진 ##성능 ##을 강 ##화 ##한 570 ##MP ##a 수준 ##의 SN ##57 ##0 ##강 ##재 ##를 개발 ##하 여 H ##형 ##강 및 후 ##판 ##에 적용 ##하여 상 ##용 ##화 ##하였다. 스 ##웨 ##덴 ##은 SD ##60 ##0 ##과 SD ##70 ##0 ##의 봉 ##강 ##개발 ##에 성 ##공 ##하였고, 프랑스 ##와 독일 ##도, 압 ##연 형 ##강 ##재 생산 ##을 통하여 고 ##속 전 ##철 ##의 경 ##량 ##화를 이 ##룰 수 있는 첨 ##단 기술 ##을 확보 ##함으로써 ##, 에너지 절 ##감 및 성능 향상 ##, 가 ##공 ##의 용 ##이 ##성, 재 ##활용 ##성 등 다양한 이 ##점을 얻 ##고 있다. 우리나라 ##는 관련 제 ##도의 개 ##정 이전 ##에는 주로 토 ##목 ##분야 ##에서는 SD ##400 철 ##근 ##을 많이 사용 ##하였으며, 건 ##축 ##분야 ##에서는 SD ##500 ##의 사용 ##이 빈 ##번 ##하였다( ##L ##ee, 2010 ##). 그러나 2012년 콘 ##크리 ##트 ##구조 ##설계 ##기준 개 ##정 이후 ##에는 항 ##복 ##강 ##도가 600 MP ##a ##인 SD ##60 ##0 철 ##근 ##의 사용 ##이 늘 ##어 ##났 ##으며, 현대 ##제 ##철 등에서 SD ##60 ##0 이상의 철 ##근 ##을 생산 ##하여 공급 ##하고 있다. [SEP]\n",
      "I1125 11:12:38.382860 47903194205696 run_squad.py:404] tokens: [CLS] 미국 ##은 구조 ##물의 내 ##진 ##성능 강 ##화를 위해 어떤 철 ##근 ##을 적용 ##하였 ##는 ##가 ##? [SEP] 미국의 경우 1994년 노 ##스 ##리 ##지 ##( ##N ##orth ##ridge ##) 지 ##진 ##의 경험 ##으로 구조 ##물의 내 ##진 ##성능 ##을 강 ##화 ##하기 위하여 AS ##TM A ##99 ##2 형 과 AS ##TM A7 ##0 ##6 ##M 철 ##근 ##을 적용 ##하도록 하였다. 다 ##수의 철 ##강 ##회 ##사에 ##서 내 ##진 ##성능 ##을 강 ##화 ##한 강 ##재 ##를 생산 ##하고 있으며, 내 ##진 ##용 철 ##근 ##으로서 ##, 소 ##성 변 ##형 능 ##력 향상을 위한 항 ##복 ##강 ##도 상 ##한 및 하 ##한 규 ##정 ##, 항 ##복 ##비 상 ##한 규 ##정 ##, 용 ##접 ##성능 향상을 위한 탄 ##소 ##당 ##량 상 ##한 규 ##정 ##, 충 ##격 흡 ##수 능 ##력 향상을 위한 샤 ##르 ##피 흡 ##수 ##에너지 하 ##한 규 ##정 ##과 같은 요구조건 ##이 충 ##족 ##되는 철 ##근 ##을 생산 ##하고 있다. 일본 ##은 신 ##일 ##본 ##제 ##철 ##에서 개발 ##한 SD ##6 ##85 ##급 ##을 시 ##범 ##적으로 신 ##축 공 ##사 현장 ##에 적용 ##한 바 있으며, 1995년 고 ##베 지 ##진 ##을 겪 ##으면 ##서 각 ##종 설계 ##기준 ##에 구조 ##물의 내 ##진 ##성능 ##을 강 ##화 ##하면서 내 ##진 ##성능 ##이 우 ##수 ##한 강 ##종 ##을 도입 ##하였다. J ##IS G 313 ##6 등 내 ##진 ##성능 ##강 ##화 ##강 종 ##(S ##N ##강 ##종 ##) 표준 ##을 제 ##정 ##하여 사용 ##하고 있다. 신 ##일 ##본 ##제 ##철 ##에서는 내 ##진 ##성능 ##을 강 ##화 ##한 570 ##MP ##a 수준 ##의 SN ##57 ##0 ##강 ##재 ##를 개발 ##하 여 H ##형 ##강 및 후 ##판 ##에 적용 ##하여 상 ##용 ##화 ##하였다. 스 ##웨 ##덴 ##은 SD ##60 ##0 ##과 SD ##70 ##0 ##의 봉 ##강 ##개발 ##에 성 ##공 ##하였고, 프랑스 ##와 독일 ##도, 압 ##연 형 ##강 ##재 생산 ##을 통하여 고 ##속 전 ##철 ##의 경 ##량 ##화를 이 ##룰 수 있는 첨 ##단 기술 ##을 확보 ##함으로써 ##, 에너지 절 ##감 및 성능 향상 ##, 가 ##공 ##의 용 ##이 ##성, 재 ##활용 ##성 등 다양한 이 ##점을 얻 ##고 있다. 우리나라 ##는 관련 제 ##도의 개 ##정 이전 ##에는 주로 토 ##목 ##분야 ##에서는 SD ##400 철 ##근 ##을 많이 사용 ##하였으며, 건 ##축 ##분야 ##에서는 SD ##500 ##의 사용 ##이 빈 ##번 ##하였다( ##L ##ee, 2010 ##). 그러나 2012년 콘 ##크리 ##트 ##구조 ##설계 ##기준 개 ##정 이후 ##에는 항 ##복 ##강 ##도가 600 MP ##a ##인 SD ##60 ##0 철 ##근 ##의 사용 ##이 늘 ##어 ##났 ##으며, 현대 ##제 ##철 등에서 SD ##60 ##0 이상의 철 ##근 ##을 생산 ##하여 공급 ##하고 있다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 21:0 22:1 23:2 24:3 25:3 26:3 27:3 28:3 29:3 30:3 31:3 32:3 33:4 34:4 35:4 36:5 37:5 38:6 39:6 40:7 41:7 42:7 43:7 44:8 45:8 46:8 47:9 48:10 49:10 50:11 51:11 52:11 53:12 54:12 55:13 56:13 57:14 58:14 59:14 60:14 61:15 62:15 63:15 64:16 65:16 66:17 67:18 68:18 69:19 70:19 71:19 72:19 73:19 74:20 75:20 76:20 77:20 78:21 79:21 80:21 81:22 82:22 83:22 84:23 85:23 86:24 87:25 88:25 89:25 90:26 91:26 92:26 93:26 94:27 95:27 96:28 97:28 98:29 99:29 100:30 101:31 102:32 103:32 104:32 105:32 106:33 107:33 108:34 109:35 110:35 111:36 112:36 113:36 114:37 115:37 116:37 117:38 118:38 119:39 120:39 121:39 122:40 123:40 124:40 125:41 126:42 127:43 128:43 129:43 130:43 131:44 132:44 133:45 134:45 135:45 136:46 137:46 138:47 139:47 140:48 141:48 142:49 143:50 144:51 145:51 146:51 147:52 148:52 149:52 150:53 151:53 152:54 153:54 154:54 155:55 156:56 157:56 158:57 159:57 160:57 161:58 162:58 163:58 164:59 165:59 166:60 167:61 168:61 169:62 170:62 171:62 172:62 173:62 174:62 175:63 176:63 177:64 178:64 179:64 180:64 181:64 182:65 183:65 184:65 185:66 186:66 187:67 188:67 189:68 190:68 191:69 192:69 193:70 194:71 195:72 196:73 197:73 198:74 199:74 200:74 201:75 202:75 203:75 204:76 205:76 206:77 207:77 208:77 209:78 210:78 211:79 212:79 213:79 214:79 215:80 216:80 217:80 218:81 219:81 220:81 221:81 222:82 223:82 224:82 225:83 226:83 227:83 228:84 229:84 230:85 231:85 232:86 233:87 234:87 235:88 236:89 237:89 238:89 239:89 240:89 241:89 242:90 243:90 244:90 245:90 246:90 247:90 248:91 249:91 250:92 251:92 252:92 253:93 254:93 255:94 256:95 257:95 258:95 259:95 260:95 261:95 262:96 263:96 264:96 265:96 266:97 267:97 268:97 269:98 270:98 271:98 272:99 273:99 274:100 275:100 276:100 277:100 278:100 279:100 280:101 281:101 282:102 283:103 284:103 285:103 286:104 287:105 288:105 289:105 290:106 291:106 292:107 293:107 294:107 295:107 296:108 297:108 298:108 299:108 300:109 301:109 302:109 303:109 304:110 305:110 306:110 307:110 308:111 309:111 310:111 311:111 312:112 313:112 314:112 315:113 316:113 317:114 318:114 319:115 320:115 321:116 322:116 323:116 324:117 325:117 326:118 327:119 328:119 329:120 330:120 331:120 332:121 333:121 334:121 335:122 336:122 337:123 338:124 339:125 340:125 341:126 342:126 343:127 344:127 345:127 346:128 347:129 348:129 349:130 350:131 351:132 352:132 353:133 354:133 355:133 356:134 357:134 358:134 359:135 360:135 361:135 362:136 363:137 364:138 365:138 366:139 367:139 368:140 369:141 370:141 371:142 372:143 373:143 374:144 375:144 376:145 377:145 378:146 379:147 380:147 381:147 382:147 383:148 384:148 385:149 386:149 387:149 388:150 389:151 390:151 391:152 392:152 393:152 394:152 395:153 396:153 397:153 398:154 399:154 400:155 401:155 402:155 403:155 404:155 405:156 406:156 407:157 408:158 409:159 410:159 411:159 412:159 413:159 414:159 415:160 416:160 417:161 418:161 419:162 420:162 421:162 422:162 423:163 424:164 425:164 426:164 427:165 428:165 429:165 430:166 431:166 432:166 433:167 434:167 435:168 436:168 437:168 438:168 439:169 440:169 441:169 442:170 443:171 444:171 445:171 446:172 447:173 448:173 449:173 450:174 451:174 452:175 453:175 454:176\n",
      "I1125 11:12:38.383076 47903194205696 run_squad.py:406] token_to_orig_map: 21:0 22:1 23:2 24:3 25:3 26:3 27:3 28:3 29:3 30:3 31:3 32:3 33:4 34:4 35:4 36:5 37:5 38:6 39:6 40:7 41:7 42:7 43:7 44:8 45:8 46:8 47:9 48:10 49:10 50:11 51:11 52:11 53:12 54:12 55:13 56:13 57:14 58:14 59:14 60:14 61:15 62:15 63:15 64:16 65:16 66:17 67:18 68:18 69:19 70:19 71:19 72:19 73:19 74:20 75:20 76:20 77:20 78:21 79:21 80:21 81:22 82:22 83:22 84:23 85:23 86:24 87:25 88:25 89:25 90:26 91:26 92:26 93:26 94:27 95:27 96:28 97:28 98:29 99:29 100:30 101:31 102:32 103:32 104:32 105:32 106:33 107:33 108:34 109:35 110:35 111:36 112:36 113:36 114:37 115:37 116:37 117:38 118:38 119:39 120:39 121:39 122:40 123:40 124:40 125:41 126:42 127:43 128:43 129:43 130:43 131:44 132:44 133:45 134:45 135:45 136:46 137:46 138:47 139:47 140:48 141:48 142:49 143:50 144:51 145:51 146:51 147:52 148:52 149:52 150:53 151:53 152:54 153:54 154:54 155:55 156:56 157:56 158:57 159:57 160:57 161:58 162:58 163:58 164:59 165:59 166:60 167:61 168:61 169:62 170:62 171:62 172:62 173:62 174:62 175:63 176:63 177:64 178:64 179:64 180:64 181:64 182:65 183:65 184:65 185:66 186:66 187:67 188:67 189:68 190:68 191:69 192:69 193:70 194:71 195:72 196:73 197:73 198:74 199:74 200:74 201:75 202:75 203:75 204:76 205:76 206:77 207:77 208:77 209:78 210:78 211:79 212:79 213:79 214:79 215:80 216:80 217:80 218:81 219:81 220:81 221:81 222:82 223:82 224:82 225:83 226:83 227:83 228:84 229:84 230:85 231:85 232:86 233:87 234:87 235:88 236:89 237:89 238:89 239:89 240:89 241:89 242:90 243:90 244:90 245:90 246:90 247:90 248:91 249:91 250:92 251:92 252:92 253:93 254:93 255:94 256:95 257:95 258:95 259:95 260:95 261:95 262:96 263:96 264:96 265:96 266:97 267:97 268:97 269:98 270:98 271:98 272:99 273:99 274:100 275:100 276:100 277:100 278:100 279:100 280:101 281:101 282:102 283:103 284:103 285:103 286:104 287:105 288:105 289:105 290:106 291:106 292:107 293:107 294:107 295:107 296:108 297:108 298:108 299:108 300:109 301:109 302:109 303:109 304:110 305:110 306:110 307:110 308:111 309:111 310:111 311:111 312:112 313:112 314:112 315:113 316:113 317:114 318:114 319:115 320:115 321:116 322:116 323:116 324:117 325:117 326:118 327:119 328:119 329:120 330:120 331:120 332:121 333:121 334:121 335:122 336:122 337:123 338:124 339:125 340:125 341:126 342:126 343:127 344:127 345:127 346:128 347:129 348:129 349:130 350:131 351:132 352:132 353:133 354:133 355:133 356:134 357:134 358:134 359:135 360:135 361:135 362:136 363:137 364:138 365:138 366:139 367:139 368:140 369:141 370:141 371:142 372:143 373:143 374:144 375:144 376:145 377:145 378:146 379:147 380:147 381:147 382:147 383:148 384:148 385:149 386:149 387:149 388:150 389:151 390:151 391:152 392:152 393:152 394:152 395:153 396:153 397:153 398:154 399:154 400:155 401:155 402:155 403:155 404:155 405:156 406:156 407:157 408:158 409:159 410:159 411:159 412:159 413:159 414:159 415:160 416:160 417:161 418:161 419:162 420:162 421:162 422:162 423:163 424:164 425:164 426:164 427:165 428:165 429:165 430:166 431:166 432:166 433:167 434:167 435:168 436:168 437:168 438:168 439:169 440:169 441:169 442:170 443:171 444:171 445:171 446:172 447:173 448:173 449:173 450:174 451:174 452:175 453:175 454:176\n",
      "INFO:tensorflow:token_is_max_context: 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True\n",
      "I1125 11:12:38.383262 47903194205696 run_squad.py:408] token_is_max_context: 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True\n",
      "INFO:tensorflow:input_ids: 101 23545 10892 119605 85759 8996 18623 120184 8853 56999 19905 55910 9747 50248 10622 119564 119585 11018 11287 110871 102 37650 28467 60762 9022 12605 12692 12508 110858 11537 120609 40788 110859 9706 18623 10459 119698 11467 119605 85759 8996 18623 120184 10622 8853 18227 22440 68010 17421 55032 138 88657 10729 9983 8898 17421 55032 80505 10929 11211 11517 9747 50248 10622 119564 119916 119626 9056 57138 9747 47181 14863 86580 12424 8996 18623 120184 10622 8853 18227 11102 8853 36210 11513 119707 12453 119661 8996 18623 24974 9747 50248 120024 110862 9448 17138 9352 27506 9046 28143 120285 28195 9959 70915 47181 12092 9414 11102 9316 9952 11102 8922 16605 110862 9959 70915 29455 9414 11102 8922 16605 110862 9603 119205 120184 120285 28195 9847 22333 21928 44321 9414 11102 8922 16605 110862 9770 45465 10020 15891 9046 28143 120285 28195 9421 31401 97146 10020 15891 120200 9952 11102 8922 16605 11882 18589 120928 10739 9770 52560 24683 9747 50248 10622 119707 12453 119547 23130 10892 9487 18392 40419 17730 47465 11489 110176 11102 27589 11211 69975 37568 10622 9485 108056 17022 9487 70122 8896 12945 120030 10530 119564 11102 9318 119661 54735 8888 92688 9706 18623 10622 8879 80046 12424 8844 22200 119628 119992 10530 119605 85759 8996 18623 120184 10622 8853 18227 37341 8996 18623 120184 10739 9604 15891 11102 8853 22200 10622 120044 119548 147 19088 144 25940 11211 9121 8996 18623 120184 47181 18227 47181 9684 119941 11537 47181 22200 110859 119727 10622 9672 16605 13374 119550 12453 119547 9487 18392 40419 17730 47465 23635 8996 18623 120184 10622 8853 18227 11102 31545 79936 10113 119636 10459 62342 89156 10929 47181 36210 11513 110176 35506 9565 145 27506 47181 9316 10003 33323 10530 119564 13374 9414 24974 18227 119548 9477 119173 118790 10892 27589 50924 10929 11882 27589 48205 10929 10459 9362 47181 120043 10530 9434 28000 119773 47364 12638 51175 119768 9527 25486 9983 47181 36210 119707 10622 119834 8888 43962 9665 47465 10459 8885 44321 56999 9638 118891 9460 13767 9748 24989 119578 10622 119921 119866 110862 119862 9666 105197 9316 119745 119776 110862 8843 28000 10459 9603 10739 119794 9659 120300 17138 9121 53645 9638 67477 9550 11664 119547 119999 11018 86080 9672 54469 8857 16605 84253 15303 41195 9873 68055 120165 23635 27589 108122 9747 50248 10622 47058 119550 119654 8865 70122 120165 23635 27589 120372 10459 119550 10739 9381 35465 120097 11369 120280 10175 119558 21890 18851 9814 120068 15184 119915 120153 119992 8857 16605 18347 15303 9959 70915 47181 68516 11796 27211 10113 12030 27589 50924 10929 9747 50248 10459 119550 10739 9044 12965 118718 119579 104518 17730 47465 120355 27589 50924 10929 80607 9747 50248 10622 119707 13374 119998 12453 119547 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.384445 47903194205696 run_squad.py:410] input_ids: 101 23545 10892 119605 85759 8996 18623 120184 8853 56999 19905 55910 9747 50248 10622 119564 119585 11018 11287 110871 102 37650 28467 60762 9022 12605 12692 12508 110858 11537 120609 40788 110859 9706 18623 10459 119698 11467 119605 85759 8996 18623 120184 10622 8853 18227 22440 68010 17421 55032 138 88657 10729 9983 8898 17421 55032 80505 10929 11211 11517 9747 50248 10622 119564 119916 119626 9056 57138 9747 47181 14863 86580 12424 8996 18623 120184 10622 8853 18227 11102 8853 36210 11513 119707 12453 119661 8996 18623 24974 9747 50248 120024 110862 9448 17138 9352 27506 9046 28143 120285 28195 9959 70915 47181 12092 9414 11102 9316 9952 11102 8922 16605 110862 9959 70915 29455 9414 11102 8922 16605 110862 9603 119205 120184 120285 28195 9847 22333 21928 44321 9414 11102 8922 16605 110862 9770 45465 10020 15891 9046 28143 120285 28195 9421 31401 97146 10020 15891 120200 9952 11102 8922 16605 11882 18589 120928 10739 9770 52560 24683 9747 50248 10622 119707 12453 119547 23130 10892 9487 18392 40419 17730 47465 11489 110176 11102 27589 11211 69975 37568 10622 9485 108056 17022 9487 70122 8896 12945 120030 10530 119564 11102 9318 119661 54735 8888 92688 9706 18623 10622 8879 80046 12424 8844 22200 119628 119992 10530 119605 85759 8996 18623 120184 10622 8853 18227 37341 8996 18623 120184 10739 9604 15891 11102 8853 22200 10622 120044 119548 147 19088 144 25940 11211 9121 8996 18623 120184 47181 18227 47181 9684 119941 11537 47181 22200 110859 119727 10622 9672 16605 13374 119550 12453 119547 9487 18392 40419 17730 47465 23635 8996 18623 120184 10622 8853 18227 11102 31545 79936 10113 119636 10459 62342 89156 10929 47181 36210 11513 110176 35506 9565 145 27506 47181 9316 10003 33323 10530 119564 13374 9414 24974 18227 119548 9477 119173 118790 10892 27589 50924 10929 11882 27589 48205 10929 10459 9362 47181 120043 10530 9434 28000 119773 47364 12638 51175 119768 9527 25486 9983 47181 36210 119707 10622 119834 8888 43962 9665 47465 10459 8885 44321 56999 9638 118891 9460 13767 9748 24989 119578 10622 119921 119866 110862 119862 9666 105197 9316 119745 119776 110862 8843 28000 10459 9603 10739 119794 9659 120300 17138 9121 53645 9638 67477 9550 11664 119547 119999 11018 86080 9672 54469 8857 16605 84253 15303 41195 9873 68055 120165 23635 27589 108122 9747 50248 10622 47058 119550 119654 8865 70122 120165 23635 27589 120372 10459 119550 10739 9381 35465 120097 11369 120280 10175 119558 21890 18851 9814 120068 15184 119915 120153 119992 8857 16605 18347 15303 9959 70915 47181 68516 11796 27211 10113 12030 27589 50924 10929 9747 50248 10459 119550 10739 9044 12965 118718 119579 104518 17730 47465 120355 27589 50924 10929 80607 9747 50248 10622 119707 13374 119998 12453 119547 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.384615 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.384764 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.387864 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000009\n",
      "I1125 11:12:38.387959 47903194205696 run_squad.py:400] unique_id: 1000000009\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1125 11:12:38.388020 47903194205696 run_squad.py:401] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.388069 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 공간 주파 ##수의 정의 ##는 무 ##엇 ##인 ##가 ##? [SEP] 위 ##성 ##영상 ##에서 주파 ##수 ##란 일반적으로 공간 주파 ##수를 의미 ##하며 공간 주파 ##수 ##란 단위 ##거 ##리에 대하여 변화 ##하는 화 ##소 ##값 ##으로 정의 ##할 수 있다. 주 ##어진 지역 ##에서 반 ##사 ##값 ##이 거의 변 ##하지 않는 경우 저 ##주파 ##지역 ##이라 할 수 있으며, 짧 ##은 거 ##리에 ##서 많은 변화 ##가 있다 ##면 고 ##주파 지역 ##이라 ##고 할 수 있다( ##J ##ense ##n ##, 1995 ##). 고 ##주파 필 ##터 ##링 ##은 저 ##주파 성 ##분을 제거 ##하고 지역 ##적인 변화 ##인 고 ##주파 성 ##분을 강 ##조 ##함으로써 물 ##체의 윤 ##곽 ##이나 경 ##계 ##선 부분 ##을 강 ##조 ##하거나 에 ##지를 검 ##출 ##하는데 이용 ##된다. 따라서 고 ##주파 필 ##터 ##링 ##은 영상을 선 ##명 ##하게 하는 효과 ##가 있다. 일반적으로 윈 ##도 ##우 기반 ##의 커 ##널 ##( ##kern ##el ##) 구조 ##를 이용하여 필 ##터 ##링 ##이 수행 ##되는 ##데 고 ##주파 필 ##터 ##링 ##의 경우 중 ##앙 ##에 높은 값 ##의 가 ##중 ##치를 지 ##니 ##며 주 ##변 ##부에 ##는 음 ##( ##nega ##tive ##)의 가 ##중 ##치를 갖는 커 ##널 ##을 이용한 ##다 ( ##H ##ara ##lick et al., 1987 ##). 본 연구에서는 3 ##× ##3 크 ##기 커 ##널 ##을 이용하여 영상 ##의 각 밴 ##드 ##별 고 ##주파 필 ##터 ##링 ##을 수행 ##하였다. 필 ##터 ##링 결과를 바탕으로 이 ##진 에 ##지 영상을 생성 ##하기 위하여 O ##tsu ##임 ##계 ##화 기법 ##을 이용 ##하였다. 고 ##주파 필 ##터 ##링 결과는 다양한 값을 갖는 집 ##합 ##이기 때문에 논 ##의 경 ##계 ##와 비 ##경 ##계에 대한 두 개의 인 ##덱 ##스 ##( ##inde ##x ##) 값 ##만 ##을 갖는 새로운 영상 ##으로 변 ##환 ##할 필요가 있다. O ##tsu 임 ##계 ##화 기법 ##은 영상 ##의 히 ##스 ##토 ##그램 형태 ##가 쌍 ##봉 ##형 ##( ##bi ##mo ##dal ##)이라 ##고 가정 ##하였 ##을 때 계 ##곡 ##점을 찾 ##아 ##서 그 점 ##을 임 ##계 ##값 ##으로 설정 ##한다( ##O ##tsu ##, 1975 ##). O ##tsu 임 ##계 ##화 ##는 클 ##래 ##스 내 ##외 ##의 분 ##산 ##을 이용 ##하는데 E ##q ##. ( ##1) ##과 같이 통계 ##학적으로 전체 분 ##산 ##은 클 ##래 ##스 내 분 ##산 ##( ##σ ##w ##)과 클 ##래 ##스 간 분 ##산 ##( ##σ ##b ##)의 합 ##으로 나타 ##낼 수 있다. 클 ##래 ##스 내 분 ##산 ##은 클 ##래 ##스 1 ##과 2 ##의 가 ##중 ##치 합 ##인 E ##q ##. ( ##2) ##로 표현 ##된다. [SEP]\n",
      "I1125 11:12:38.388227 47903194205696 run_squad.py:404] tokens: [CLS] 공간 주파 ##수의 정의 ##는 무 ##엇 ##인 ##가 ##? [SEP] 위 ##성 ##영상 ##에서 주파 ##수 ##란 일반적으로 공간 주파 ##수를 의미 ##하며 공간 주파 ##수 ##란 단위 ##거 ##리에 대하여 변화 ##하는 화 ##소 ##값 ##으로 정의 ##할 수 있다. 주 ##어진 지역 ##에서 반 ##사 ##값 ##이 거의 변 ##하지 않는 경우 저 ##주파 ##지역 ##이라 할 수 있으며, 짧 ##은 거 ##리에 ##서 많은 변화 ##가 있다 ##면 고 ##주파 지역 ##이라 ##고 할 수 있다( ##J ##ense ##n ##, 1995 ##). 고 ##주파 필 ##터 ##링 ##은 저 ##주파 성 ##분을 제거 ##하고 지역 ##적인 변화 ##인 고 ##주파 성 ##분을 강 ##조 ##함으로써 물 ##체의 윤 ##곽 ##이나 경 ##계 ##선 부분 ##을 강 ##조 ##하거나 에 ##지를 검 ##출 ##하는데 이용 ##된다. 따라서 고 ##주파 필 ##터 ##링 ##은 영상을 선 ##명 ##하게 하는 효과 ##가 있다. 일반적으로 윈 ##도 ##우 기반 ##의 커 ##널 ##( ##kern ##el ##) 구조 ##를 이용하여 필 ##터 ##링 ##이 수행 ##되는 ##데 고 ##주파 필 ##터 ##링 ##의 경우 중 ##앙 ##에 높은 값 ##의 가 ##중 ##치를 지 ##니 ##며 주 ##변 ##부에 ##는 음 ##( ##nega ##tive ##)의 가 ##중 ##치를 갖는 커 ##널 ##을 이용한 ##다 ( ##H ##ara ##lick et al., 1987 ##). 본 연구에서는 3 ##× ##3 크 ##기 커 ##널 ##을 이용하여 영상 ##의 각 밴 ##드 ##별 고 ##주파 필 ##터 ##링 ##을 수행 ##하였다. 필 ##터 ##링 결과를 바탕으로 이 ##진 에 ##지 영상을 생성 ##하기 위하여 O ##tsu ##임 ##계 ##화 기법 ##을 이용 ##하였다. 고 ##주파 필 ##터 ##링 결과는 다양한 값을 갖는 집 ##합 ##이기 때문에 논 ##의 경 ##계 ##와 비 ##경 ##계에 대한 두 개의 인 ##덱 ##스 ##( ##inde ##x ##) 값 ##만 ##을 갖는 새로운 영상 ##으로 변 ##환 ##할 필요가 있다. O ##tsu 임 ##계 ##화 기법 ##은 영상 ##의 히 ##스 ##토 ##그램 형태 ##가 쌍 ##봉 ##형 ##( ##bi ##mo ##dal ##)이라 ##고 가정 ##하였 ##을 때 계 ##곡 ##점을 찾 ##아 ##서 그 점 ##을 임 ##계 ##값 ##으로 설정 ##한다( ##O ##tsu ##, 1975 ##). O ##tsu 임 ##계 ##화 ##는 클 ##래 ##스 내 ##외 ##의 분 ##산 ##을 이용 ##하는데 E ##q ##. ( ##1) ##과 같이 통계 ##학적으로 전체 분 ##산 ##은 클 ##래 ##스 내 분 ##산 ##( ##σ ##w ##)과 클 ##래 ##스 간 분 ##산 ##( ##σ ##b ##)의 합 ##으로 나타 ##낼 수 있다. 클 ##래 ##스 내 분 ##산 ##은 클 ##래 ##스 1 ##과 2 ##의 가 ##중 ##치 합 ##인 E ##q ##. ( ##2) ##로 표현 ##된다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 12:0 13:0 14:0 15:0 16:1 17:1 18:1 19:2 20:3 21:4 22:4 23:5 24:5 25:6 26:7 27:7 28:7 29:8 30:8 31:8 32:9 33:10 34:10 35:11 36:11 37:11 38:11 39:12 40:12 41:13 42:14 43:15 44:15 45:16 46:16 47:17 48:17 49:17 50:17 51:18 52:19 53:19 54:20 55:21 56:22 57:22 58:22 59:22 60:23 61:24 62:25 63:26 64:26 65:27 66:27 67:27 68:28 69:29 70:29 71:30 72:30 73:31 74:31 75:32 76:32 77:32 78:33 79:34 80:35 81:35 82:35 83:35 84:35 85:36 86:36 87:37 88:37 89:38 90:38 91:38 92:38 93:39 94:39 95:40 96:40 97:41 98:41 99:42 100:42 101:43 102:43 103:44 104:44 105:45 106:45 107:46 108:46 109:46 110:47 111:47 112:48 113:48 114:48 115:49 116:49 117:49 118:50 119:50 120:51 121:51 122:51 123:52 124:52 125:53 126:53 127:53 128:54 129:54 130:55 131:56 132:56 133:57 134:57 135:57 136:57 137:58 138:59 139:59 140:59 141:60 142:61 143:61 144:62 145:63 146:64 147:64 148:64 149:65 150:65 151:66 152:66 153:66 154:66 155:66 156:66 157:67 158:67 159:68 160:69 161:69 162:69 163:69 164:70 165:70 166:70 167:71 168:71 169:72 170:72 171:72 172:72 173:73 174:74 175:74 176:74 177:75 178:76 179:76 180:77 181:77 182:77 183:78 184:78 185:78 186:79 187:79 188:79 189:79 190:80 191:80 192:80 193:80 194:80 195:81 196:81 197:81 198:82 199:83 200:83 201:83 202:84 203:84 204:85 205:85 206:85 207:85 208:86 209:87 210:88 211:88 212:89 213:90 214:91 215:91 216:91 217:92 218:92 219:93 220:93 221:93 222:94 223:95 224:95 225:96 226:97 227:97 228:97 229:98 230:98 231:99 232:99 233:99 234:99 235:100 236:100 237:101 238:101 239:101 240:102 241:103 242:104 243:104 244:105 245:105 246:106 247:107 248:107 249:108 250:109 251:109 252:109 253:109 254:109 255:110 256:110 257:111 258:111 259:112 260:112 261:113 262:113 263:113 264:114 265:115 266:116 267:117 268:118 269:118 270:118 271:119 272:120 273:120 274:121 275:121 276:121 277:122 278:122 279:122 280:123 281:124 282:125 283:126 284:126 285:126 286:126 287:126 288:126 289:126 290:127 291:127 292:127 293:128 294:129 295:130 296:130 297:131 298:131 299:131 300:132 301:133 302:134 303:134 304:135 305:135 306:135 307:136 308:136 309:137 310:137 311:138 312:138 313:138 314:138 315:139 316:139 317:140 318:140 319:140 320:140 321:140 322:140 323:140 324:140 325:140 326:141 327:141 328:141 329:142 330:143 331:143 332:143 333:144 334:144 335:144 336:145 337:146 338:146 339:147 340:147 341:147 342:147 343:148 344:148 345:148 346:148 347:148 348:149 349:149 350:150 351:150 352:151 353:151 354:151 355:151 356:152 357:152 358:152 359:153 360:153 361:153 362:154 363:154 364:154 365:155 366:155 367:156 368:156 369:156 370:157 371:157 372:157 373:158 374:159 375:159 376:160 377:161 378:161 379:161 380:162 381:162 382:162 383:163 384:164 385:164 386:164 387:164 388:164 389:164 390:165 391:165 392:165 393:166 394:167 395:167 396:167 397:167 398:167 399:167 400:168 401:168 402:169 403:169 404:170 405:171 406:172 407:172 408:172 409:173 410:174 411:174 412:174 413:175 414:175 415:175 416:176 417:176 418:177 419:177 420:178 421:178 422:178 423:179 424:179 425:180 426:180 427:180 428:181 429:181 430:181 431:182 432:182\n",
      "I1125 11:12:38.388443 47903194205696 run_squad.py:406] token_to_orig_map: 12:0 13:0 14:0 15:0 16:1 17:1 18:1 19:2 20:3 21:4 22:4 23:5 24:5 25:6 26:7 27:7 28:7 29:8 30:8 31:8 32:9 33:10 34:10 35:11 36:11 37:11 38:11 39:12 40:12 41:13 42:14 43:15 44:15 45:16 46:16 47:17 48:17 49:17 50:17 51:18 52:19 53:19 54:20 55:21 56:22 57:22 58:22 59:22 60:23 61:24 62:25 63:26 64:26 65:27 66:27 67:27 68:28 69:29 70:29 71:30 72:30 73:31 74:31 75:32 76:32 77:32 78:33 79:34 80:35 81:35 82:35 83:35 84:35 85:36 86:36 87:37 88:37 89:38 90:38 91:38 92:38 93:39 94:39 95:40 96:40 97:41 98:41 99:42 100:42 101:43 102:43 103:44 104:44 105:45 106:45 107:46 108:46 109:46 110:47 111:47 112:48 113:48 114:48 115:49 116:49 117:49 118:50 119:50 120:51 121:51 122:51 123:52 124:52 125:53 126:53 127:53 128:54 129:54 130:55 131:56 132:56 133:57 134:57 135:57 136:57 137:58 138:59 139:59 140:59 141:60 142:61 143:61 144:62 145:63 146:64 147:64 148:64 149:65 150:65 151:66 152:66 153:66 154:66 155:66 156:66 157:67 158:67 159:68 160:69 161:69 162:69 163:69 164:70 165:70 166:70 167:71 168:71 169:72 170:72 171:72 172:72 173:73 174:74 175:74 176:74 177:75 178:76 179:76 180:77 181:77 182:77 183:78 184:78 185:78 186:79 187:79 188:79 189:79 190:80 191:80 192:80 193:80 194:80 195:81 196:81 197:81 198:82 199:83 200:83 201:83 202:84 203:84 204:85 205:85 206:85 207:85 208:86 209:87 210:88 211:88 212:89 213:90 214:91 215:91 216:91 217:92 218:92 219:93 220:93 221:93 222:94 223:95 224:95 225:96 226:97 227:97 228:97 229:98 230:98 231:99 232:99 233:99 234:99 235:100 236:100 237:101 238:101 239:101 240:102 241:103 242:104 243:104 244:105 245:105 246:106 247:107 248:107 249:108 250:109 251:109 252:109 253:109 254:109 255:110 256:110 257:111 258:111 259:112 260:112 261:113 262:113 263:113 264:114 265:115 266:116 267:117 268:118 269:118 270:118 271:119 272:120 273:120 274:121 275:121 276:121 277:122 278:122 279:122 280:123 281:124 282:125 283:126 284:126 285:126 286:126 287:126 288:126 289:126 290:127 291:127 292:127 293:128 294:129 295:130 296:130 297:131 298:131 299:131 300:132 301:133 302:134 303:134 304:135 305:135 306:135 307:136 308:136 309:137 310:137 311:138 312:138 313:138 314:138 315:139 316:139 317:140 318:140 319:140 320:140 321:140 322:140 323:140 324:140 325:140 326:141 327:141 328:141 329:142 330:143 331:143 332:143 333:144 334:144 335:144 336:145 337:146 338:146 339:147 340:147 341:147 342:147 343:148 344:148 345:148 346:148 347:148 348:149 349:149 350:150 351:150 352:151 353:151 354:151 355:151 356:152 357:152 358:152 359:153 360:153 361:153 362:154 363:154 364:154 365:155 366:155 367:156 368:156 369:156 370:157 371:157 372:157 373:158 374:159 375:159 376:160 377:161 378:161 379:161 380:162 381:162 382:162 383:163 384:164 385:164 386:164 387:164 388:164 389:164 390:165 391:165 392:165 393:166 394:167 395:167 396:167 397:167 398:167 399:167 400:168 401:168 402:169 403:169 404:170 405:171 406:172 407:172 408:172 409:173 410:174 411:174 412:174 413:175 414:175 415:175 416:176 417:176 418:177 419:177 420:178 421:178 422:178 423:179 424:179 425:180 426:180 427:180 428:181 429:181 430:181 431:182 432:182\n",
      "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True\n",
      "I1125 11:12:38.388627 47903194205696 run_squad.py:408] token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True\n",
      "INFO:tensorflow:input_ids: 101 119711 120088 57138 119765 11018 9294 119137 12030 11287 110871 102 9619 17138 120218 11489 120088 15891 49919 79055 119711 120088 61099 119614 22766 119711 120088 15891 49919 120057 41521 46766 68357 119586 12178 9993 22333 118611 11467 119765 14843 9460 119547 9689 46572 58939 11489 9321 12945 118611 10739 55067 9352 23665 55698 28467 9663 120282 119788 119671 9955 9460 119661 9717 10892 8863 46766 12424 25685 119586 11287 11506 14867 8888 120282 58939 119671 11664 9955 9460 119798 15417 23643 10115 110862 10436 119558 8888 120282 9949 21876 80174 10892 9663 120282 9434 97005 119976 12453 58939 15387 119586 12030 8888 120282 9434 97005 8853 20626 119866 9299 79025 9627 118646 43739 8885 21611 18471 119725 10622 8853 20626 120054 9559 36908 8868 52363 119885 119580 119574 52579 8888 120282 9949 21876 80174 10892 120316 9428 16758 17594 23969 119620 11287 119547 79055 9621 12092 27355 119658 10459 9798 49881 110858 93931 10570 110859 119605 11513 119593 9949 21876 80174 10739 119570 24683 28911 8888 120282 9949 21876 80174 10459 28467 9694 119119 10530 55600 8850 10459 8843 41693 62672 9706 25503 21406 9689 118985 52961 11018 9634 110858 24267 14079 119592 8843 41693 62672 120021 9798 49881 10622 119728 11903 113 12396 12677 64791 10131 119680 10581 119558 9358 119618 124 54673 10884 9834 12310 9798 49881 10622 119593 119859 10459 8844 9332 15001 61844 8888 120282 9949 21876 80174 10622 119570 119548 9949 21876 80174 119639 119983 9638 18623 9559 12508 120316 119786 22440 68010 152 36296 36240 21611 18227 119878 10622 119580 119548 8888 120282 9949 21876 80174 119811 53645 119864 120021 9711 33188 120099 20729 9024 10459 8885 21611 12638 9379 31720 105653 18154 9102 68599 9640 118789 12605 110858 17720 10686 110859 8850 19105 10622 120021 39773 119859 11467 9352 51745 14843 120075 119547 152 36296 9644 21611 18227 119878 10892 119859 10459 10025 12605 26444 101472 119652 11287 9500 118989 27506 110858 11645 11033 14555 120458 11664 119853 119585 10622 9137 8887 55670 67477 9737 16985 12424 8924 9668 10622 9644 21611 118611 11467 119734 120232 11403 36296 110862 10665 119558 152 36296 9644 21611 18227 11018 9836 37388 12605 8996 78705 10459 9367 21386 10622 119580 119885 142 11703 110864 113 119627 11882 38401 119709 120380 96567 9367 21386 10892 9836 37388 12605 8996 9367 21386 110858 111053 10874 119863 9836 37388 12605 8845 9367 21386 110858 111053 10457 119592 9957 11467 119965 118724 9460 119547 9836 37388 12605 8996 9367 21386 10892 9836 37388 12605 122 11882 123 10459 8843 41693 18622 9957 12030 142 11703 110864 113 119647 11261 119750 119574 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.390014 47903194205696 run_squad.py:410] input_ids: 101 119711 120088 57138 119765 11018 9294 119137 12030 11287 110871 102 9619 17138 120218 11489 120088 15891 49919 79055 119711 120088 61099 119614 22766 119711 120088 15891 49919 120057 41521 46766 68357 119586 12178 9993 22333 118611 11467 119765 14843 9460 119547 9689 46572 58939 11489 9321 12945 118611 10739 55067 9352 23665 55698 28467 9663 120282 119788 119671 9955 9460 119661 9717 10892 8863 46766 12424 25685 119586 11287 11506 14867 8888 120282 58939 119671 11664 9955 9460 119798 15417 23643 10115 110862 10436 119558 8888 120282 9949 21876 80174 10892 9663 120282 9434 97005 119976 12453 58939 15387 119586 12030 8888 120282 9434 97005 8853 20626 119866 9299 79025 9627 118646 43739 8885 21611 18471 119725 10622 8853 20626 120054 9559 36908 8868 52363 119885 119580 119574 52579 8888 120282 9949 21876 80174 10892 120316 9428 16758 17594 23969 119620 11287 119547 79055 9621 12092 27355 119658 10459 9798 49881 110858 93931 10570 110859 119605 11513 119593 9949 21876 80174 10739 119570 24683 28911 8888 120282 9949 21876 80174 10459 28467 9694 119119 10530 55600 8850 10459 8843 41693 62672 9706 25503 21406 9689 118985 52961 11018 9634 110858 24267 14079 119592 8843 41693 62672 120021 9798 49881 10622 119728 11903 113 12396 12677 64791 10131 119680 10581 119558 9358 119618 124 54673 10884 9834 12310 9798 49881 10622 119593 119859 10459 8844 9332 15001 61844 8888 120282 9949 21876 80174 10622 119570 119548 9949 21876 80174 119639 119983 9638 18623 9559 12508 120316 119786 22440 68010 152 36296 36240 21611 18227 119878 10622 119580 119548 8888 120282 9949 21876 80174 119811 53645 119864 120021 9711 33188 120099 20729 9024 10459 8885 21611 12638 9379 31720 105653 18154 9102 68599 9640 118789 12605 110858 17720 10686 110859 8850 19105 10622 120021 39773 119859 11467 9352 51745 14843 120075 119547 152 36296 9644 21611 18227 119878 10892 119859 10459 10025 12605 26444 101472 119652 11287 9500 118989 27506 110858 11645 11033 14555 120458 11664 119853 119585 10622 9137 8887 55670 67477 9737 16985 12424 8924 9668 10622 9644 21611 118611 11467 119734 120232 11403 36296 110862 10665 119558 152 36296 9644 21611 18227 11018 9836 37388 12605 8996 78705 10459 9367 21386 10622 119580 119885 142 11703 110864 113 119627 11882 38401 119709 120380 96567 9367 21386 10892 9836 37388 12605 8996 9367 21386 110858 111053 10874 119863 9836 37388 12605 8845 9367 21386 110858 111053 10457 119592 9957 11467 119965 118724 9460 119547 9836 37388 12605 8996 9367 21386 10892 9836 37388 12605 122 11882 123 10459 8843 41693 18622 9957 12030 142 11703 110864 113 119647 11261 119750 119574 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.390228 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.390373 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.391694 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000010\n",
      "I1125 11:12:38.391785 47903194205696 run_squad.py:400] unique_id: 1000000010\n",
      "INFO:tensorflow:example_index: 10\n",
      "I1125 11:12:38.391841 47903194205696 run_squad.py:401] example_index: 10\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.391890 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 정보 ##화 ##시대 ##의 도 ##래 ##로 변화 ##하고 있는 것은 ##? [SEP] 우리 ##는 현대 ##사회 ##를 디지털 정보 ##화 시대 ##라고 한다. 정보 ##화 사회 ##란 정보 ##가 모든 것 ##의 가 ##치 ##기준 ##이 되어 정보 자 ##체가 중요한 자 ##원의 원 ##천 ##이 되는 사회 ##를 의미 ##하는 것이다. 정보 ##화 ##시대 ##의 도 ##래 ##로 많은 기업 ##의 경 ##영 환경 ##과 경 ##영 ##방식 ##을 바 ##꾸 ##어 놓 ##고 있고 개인 ##의 삶 방식 ##도 많이 바 ##꾸 ##었으며 ##, 특히 기업 ##에서는 일 ##하는 방법을 바 ##꾸 ##어 가 ##고 있다. 학 ##문 ##의 요 ##람 ##인 대학 조직 내 ##에서도 이러한 변화 ##의 요구 ##가 시작 ##되어 대학 전 부 ##문 ##에 걸쳐 패 ##러 ##다 ##임 ##의 전 ##환 ##을 요구 ##받 ##고 있다. [SEP]\n",
      "I1125 11:12:38.391973 47903194205696 run_squad.py:404] tokens: [CLS] 정보 ##화 ##시대 ##의 도 ##래 ##로 변화 ##하고 있는 것은 ##? [SEP] 우리 ##는 현대 ##사회 ##를 디지털 정보 ##화 시대 ##라고 한다. 정보 ##화 사회 ##란 정보 ##가 모든 것 ##의 가 ##치 ##기준 ##이 되어 정보 자 ##체가 중요한 자 ##원의 원 ##천 ##이 되는 사회 ##를 의미 ##하는 것이다. 정보 ##화 ##시대 ##의 도 ##래 ##로 많은 기업 ##의 경 ##영 환경 ##과 경 ##영 ##방식 ##을 바 ##꾸 ##어 놓 ##고 있고 개인 ##의 삶 방식 ##도 많이 바 ##꾸 ##었으며 ##, 특히 기업 ##에서는 일 ##하는 방법을 바 ##꾸 ##어 가 ##고 있다. 학 ##문 ##의 요 ##람 ##인 대학 조직 내 ##에서도 이러한 변화 ##의 요구 ##가 시작 ##되어 대학 전 부 ##문 ##에 걸쳐 패 ##러 ##다 ##임 ##의 전 ##환 ##을 요구 ##받 ##고 있다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 14:0 15:0 16:1 17:1 18:1 19:2 20:3 21:3 22:4 23:4 24:5 25:6 26:6 27:7 28:7 29:8 30:8 31:9 32:10 33:10 34:11 35:11 36:11 37:11 38:12 39:13 40:14 41:14 42:15 43:16 44:16 45:17 46:17 47:17 48:18 49:19 50:19 51:20 52:20 53:21 54:22 55:22 56:22 57:22 58:23 59:23 60:23 61:24 62:25 63:25 64:26 65:26 66:27 67:27 68:28 69:28 70:28 71:28 72:29 73:29 74:29 75:30 76:30 77:31 78:32 79:32 80:33 81:34 82:34 83:35 84:36 85:36 86:36 87:36 88:37 89:38 90:38 91:39 92:39 93:40 94:41 95:41 96:41 97:42 98:42 99:43 100:44 101:44 102:44 103:45 104:45 105:45 106:46 107:47 108:48 109:48 110:49 111:50 112:50 113:51 114:51 115:52 116:52 117:53 118:54 119:55 120:55 121:55 122:56 123:57 124:57 125:57 126:57 127:57 128:58 129:58 130:58 131:59 132:59 133:59 134:60\n",
      "I1125 11:12:38.392079 47903194205696 run_squad.py:406] token_to_orig_map: 14:0 15:0 16:1 17:1 18:1 19:2 20:3 21:3 22:4 23:4 24:5 25:6 26:6 27:7 28:7 29:8 30:8 31:9 32:10 33:10 34:11 35:11 36:11 37:11 38:12 39:13 40:14 41:14 42:15 43:16 44:16 45:17 46:17 47:17 48:18 49:19 50:19 51:20 52:20 53:21 54:22 55:22 56:22 57:22 58:23 59:23 60:23 61:24 62:25 63:25 64:26 65:26 66:27 67:27 68:28 69:28 70:28 71:28 72:29 73:29 74:29 75:30 76:30 77:31 78:32 79:32 80:33 81:34 82:34 83:35 84:36 85:36 86:36 87:36 88:37 89:38 90:38 91:39 92:39 93:40 94:41 95:41 96:41 97:42 98:42 99:43 100:44 101:44 102:44 103:45 104:45 105:45 106:46 107:47 108:48 109:48 110:49 111:50 112:50 113:51 114:51 115:52 116:52 117:53 118:54 119:55 120:55 121:55 122:56 123:57 124:57 125:57 126:57 127:57 128:58 129:58 130:58 131:59 132:59 133:59 134:60\n",
      "INFO:tensorflow:token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True\n",
      "I1125 11:12:38.392168 47903194205696 run_squad.py:408] token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True\n",
      "INFO:tensorflow:input_ids: 101 119596 18227 110670 10459 9087 37388 11261 119586 12453 13767 30050 110871 102 120142 11018 104518 120114 11513 108266 119596 18227 102080 59894 119575 119596 18227 119701 49919 119596 11287 25701 8870 10459 8843 18622 119992 10739 37909 119596 9651 92319 63552 9651 74125 9612 38631 10739 54780 119701 11513 119614 12178 119584 119596 18227 110670 10459 9087 37388 11261 25685 119667 10459 8885 30858 119606 11882 8885 30858 120117 10622 9318 118694 12965 9029 11664 40523 119686 10459 9409 119693 12092 47058 9318 118694 52476 110862 39671 119667 23635 9641 12178 119986 9318 118694 12965 8843 11664 119547 9953 25934 10459 9599 61250 12030 67778 119682 8996 119829 34079 119586 10459 119703 11287 119889 16855 67778 9665 9365 25934 10530 92210 9909 30873 11903 36240 10459 9665 51745 10622 119703 118965 11664 119547 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.392331 47903194205696 run_squad.py:410] input_ids: 101 119596 18227 110670 10459 9087 37388 11261 119586 12453 13767 30050 110871 102 120142 11018 104518 120114 11513 108266 119596 18227 102080 59894 119575 119596 18227 119701 49919 119596 11287 25701 8870 10459 8843 18622 119992 10739 37909 119596 9651 92319 63552 9651 74125 9612 38631 10739 54780 119701 11513 119614 12178 119584 119596 18227 110670 10459 9087 37388 11261 25685 119667 10459 8885 30858 119606 11882 8885 30858 120117 10622 9318 118694 12965 9029 11664 40523 119686 10459 9409 119693 12092 47058 9318 118694 52476 110862 39671 119667 23635 9641 12178 119986 9318 118694 12965 8843 11664 119547 9953 25934 10459 9599 61250 12030 67778 119682 8996 119829 34079 119586 10459 119703 11287 119889 16855 67778 9665 9365 25934 10530 92210 9909 30873 11903 36240 10459 9665 51745 10622 119703 118965 11664 119547 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.392483 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.392624 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.398627 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000011\n",
      "I1125 11:12:38.398721 47903194205696 run_squad.py:400] unique_id: 1000000011\n",
      "INFO:tensorflow:example_index: 11\n",
      "I1125 11:12:38.398778 47903194205696 run_squad.py:401] example_index: 11\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.398832 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 치 ##과 ##위 ##생 ##사의 전문 ##적인 의료 ##서비스 수행 ##능 ##력을 향상 시 ##키 ##고 유지 ##하기 위해 필요한 요인 ##은 ##? [SEP] 본 연구는 치 ##과의료 ##인 ##력을 효율 ##적으로 관리 ##할 수 있는 방안 ##을 모 ##색 ##하고자 서울 ##, 인 ##천 경기도 ##, 대전 충 ##정 ##도, 대 ##구 울 ##산 경 ##상 ##도, 광 ##주 전 ##라 ##도 소 ##재 ##의 치 ##과 병 의 ##원에 재 ##직 ##중 ##인 328 ##명의 치 ##과 ##위 ##생 ##사를 대상으로 감 ##성 ##리 ##더 ##십 ##, 몰 ##입 ##도, 환자 ##지 ##향 ##성 수준 ##과 상호 관련 ##성을 파악 ##하고, 이 ##들이 직무 ##성과 ##에 미치는 영향을 분석하였다. 치 ##과 ##위 ##생 ##사의 감 ##성 ##리 ##더 ##십 ##은 3. ##48 ##점이 ##었다. 하 ##위 ##영역 ##에서 자기 ##인식 능 ##력이 3. ##82 ##점 ##으로 가장 높 ##았고 ##, 사회 ##인식 능 ##력이 3. ##66 ##점이 ##었으며 ##, 자기 ##관리 능 ##력이 3. ##38 ##점 ##, 관계 ##관리 능 ##력이 3. ##33 ##점이 ##었다. 몰 ##입 ##도는 3. ##30 ##점 ##으로 조직 ##몰 ##입 ##( ##3. ##34 ##점 ##)이 변화 ##몰 ##입 ##( ##3. ##28 ##점 ##) ##보다 높 ##았다. 환자 ##지 ##향 ##성은 3. ##9 ##5 ##점이 ##었고 ##, 직무 ##성과 ##는 3. ##39 ##점이 ##었다. 감 ##성 ##리 ##더 ##십 ##과 몰 ##입 ##도, 환자 ##지 ##향 ##성 및 직무 ##성과 ##는 물 ##론 하 ##위 ##영역 간 ##에도 상호 간 유의한 양 ##( ##+ ##)의 상관관계를 나타 ##냈다 ##(p ##$ ##{ ##\\ ##beta ##} ##= ##0. ##30 ##6 ##$ ##)이 ##었고 ##, 관계 ##관리 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##20 ##9 ##$ ##), 연령 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##16 ##2 ##$ ##), 자기 ##인식 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##139 ##$ ##), 사회 ##인식 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##12 ##3 ##$ ##), 병 ##원 ##형태 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##101 ##$ ##) 등이 주요 ##한 관련 ##요인 ##으로 분석 ##되었다. 이를 바탕으로 치 ##과 ##위 ##생 ##사의 감 ##성 ##리 ##더 ##십 ##, 몰 ##입 ##도, 환자 ##지 ##향 ##성과 직무 ##성과 ##는 상호 관련 ##성이 깊 ##은 것으로 나타났다. 치 ##과 ##위 ##생 ##사의 전문 ##적인 의료 ##서비스 수행 ##능 ##력을 향상 시 ##키 ##고 유지 ##시키는 다양한 감 ##성 ##적 역 ##량 ##에 대한 폭 ##넓 ##은 인식 ##과 개발 방안 ##에 대한 검토 ##가 필요 ##할 것으로 생각 ##된다. This study intended to search for measures to effectively improve and manage the job performance and personality of dental hy ##gien ##ists ##. In this study ##, the effects on job performance of the following variables were analy ##zed ##: emotional leadership ##, commitment ##, and patient ##- ##orie ##ntation ##. The subjects of the study were 328 dental hy ##gien ##ists who were working in a dental c ##lini ##c and the assessment was made based on a self ##- ##ad ##minister ##ed question ##naire ##. T ##- ##test ##, one ##- ##way AN ##O ##VA ##, [SEP]\n",
      "I1125 11:12:38.399016 47903194205696 run_squad.py:404] tokens: [CLS] 치 ##과 ##위 ##생 ##사의 전문 ##적인 의료 ##서비스 수행 ##능 ##력을 향상 시 ##키 ##고 유지 ##하기 위해 필요한 요인 ##은 ##? [SEP] 본 연구는 치 ##과의료 ##인 ##력을 효율 ##적으로 관리 ##할 수 있는 방안 ##을 모 ##색 ##하고자 서울 ##, 인 ##천 경기도 ##, 대전 충 ##정 ##도, 대 ##구 울 ##산 경 ##상 ##도, 광 ##주 전 ##라 ##도 소 ##재 ##의 치 ##과 병 의 ##원에 재 ##직 ##중 ##인 328 ##명의 치 ##과 ##위 ##생 ##사를 대상으로 감 ##성 ##리 ##더 ##십 ##, 몰 ##입 ##도, 환자 ##지 ##향 ##성 수준 ##과 상호 관련 ##성을 파악 ##하고, 이 ##들이 직무 ##성과 ##에 미치는 영향을 분석하였다. 치 ##과 ##위 ##생 ##사의 감 ##성 ##리 ##더 ##십 ##은 3. ##48 ##점이 ##었다. 하 ##위 ##영역 ##에서 자기 ##인식 능 ##력이 3. ##82 ##점 ##으로 가장 높 ##았고 ##, 사회 ##인식 능 ##력이 3. ##66 ##점이 ##었으며 ##, 자기 ##관리 능 ##력이 3. ##38 ##점 ##, 관계 ##관리 능 ##력이 3. ##33 ##점이 ##었다. 몰 ##입 ##도는 3. ##30 ##점 ##으로 조직 ##몰 ##입 ##( ##3. ##34 ##점 ##)이 변화 ##몰 ##입 ##( ##3. ##28 ##점 ##) ##보다 높 ##았다. 환자 ##지 ##향 ##성은 3. ##9 ##5 ##점이 ##었고 ##, 직무 ##성과 ##는 3. ##39 ##점이 ##었다. 감 ##성 ##리 ##더 ##십 ##과 몰 ##입 ##도, 환자 ##지 ##향 ##성 및 직무 ##성과 ##는 물 ##론 하 ##위 ##영역 간 ##에도 상호 간 유의한 양 ##( ##+ ##)의 상관관계를 나타 ##냈다 ##(p ##$ ##{ ##\\ ##beta ##} ##= ##0. ##30 ##6 ##$ ##)이 ##었고 ##, 관계 ##관리 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##20 ##9 ##$ ##), 연령 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##16 ##2 ##$ ##), 자기 ##인식 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##139 ##$ ##), 사회 ##인식 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##12 ##3 ##$ ##), 병 ##원 ##형태 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##101 ##$ ##) 등이 주요 ##한 관련 ##요인 ##으로 분석 ##되었다. 이를 바탕으로 치 ##과 ##위 ##생 ##사의 감 ##성 ##리 ##더 ##십 ##, 몰 ##입 ##도, 환자 ##지 ##향 ##성과 직무 ##성과 ##는 상호 관련 ##성이 깊 ##은 것으로 나타났다. 치 ##과 ##위 ##생 ##사의 전문 ##적인 의료 ##서비스 수행 ##능 ##력을 향상 시 ##키 ##고 유지 ##시키는 다양한 감 ##성 ##적 역 ##량 ##에 대한 폭 ##넓 ##은 인식 ##과 개발 방안 ##에 대한 검토 ##가 필요 ##할 것으로 생각 ##된다. This study intended to search for measures to effectively improve and manage the job performance and personality of dental hy ##gien ##ists ##. In this study ##, the effects on job performance of the following variables were analy ##zed ##: emotional leadership ##, commitment ##, and patient ##- ##orie ##ntation ##. The subjects of the study were 328 dental hy ##gien ##ists who were working in a dental c ##lini ##c and the assessment was made based on a self ##- ##ad ##minister ##ed question ##naire ##. T ##- ##test ##, one ##- ##way AN ##O ##VA ##, [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 25:0 26:1 27:2 28:2 29:2 30:2 31:3 32:3 33:4 34:4 35:5 36:6 37:7 38:7 39:8 40:8 41:8 42:9 43:9 44:10 45:10 46:11 47:11 48:12 49:13 50:13 51:13 52:14 53:14 54:15 55:15 56:16 57:16 58:16 59:17 60:17 61:18 62:18 63:18 64:19 65:19 66:19 67:20 68:20 69:21 70:22 71:22 72:23 73:23 74:23 75:23 76:24 77:24 78:25 79:25 80:25 81:25 82:25 83:26 84:27 85:27 86:27 87:27 88:27 89:27 90:28 91:28 92:28 93:29 94:29 95:29 96:29 97:30 98:30 99:31 100:32 101:32 102:33 103:33 104:34 105:34 106:35 107:35 108:35 109:36 110:37 111:38 112:39 113:39 114:39 115:39 116:39 117:40 118:40 119:40 120:40 121:40 122:40 123:41 124:41 125:41 126:41 127:42 128:42 129:42 130:42 131:43 132:43 133:44 134:44 135:45 136:45 137:45 138:45 139:46 140:47 141:47 142:47 143:48 144:48 145:49 146:49 147:50 148:50 149:50 150:50 151:50 152:51 153:51 154:52 155:52 156:53 157:53 158:53 159:53 160:54 161:54 162:55 163:55 164:56 165:56 166:56 167:56 168:57 169:57 170:57 171:58 172:58 173:58 174:58 175:59 176:59 177:59 178:59 179:59 180:59 181:59 182:59 183:60 184:60 185:60 186:60 187:60 188:60 189:60 190:60 191:60 192:61 193:61 194:62 195:62 196:62 197:62 198:63 199:63 200:63 201:63 202:63 203:63 204:64 205:64 206:64 207:65 208:65 209:65 210:65 211:66 212:66 213:66 214:66 215:66 216:66 217:67 218:67 219:67 220:68 221:68 222:68 223:68 224:69 225:70 226:70 227:70 228:71 229:71 230:72 231:72 232:72 233:73 234:73 235:74 236:75 237:76 238:77 239:77 240:77 241:77 242:78 243:79 244:79 245:79 246:79 247:79 248:79 249:79 250:79 251:79 252:79 253:79 254:79 255:79 256:79 257:79 258:79 259:80 260:80 261:81 262:81 263:81 264:81 265:81 266:81 267:81 268:81 269:81 270:81 271:81 272:81 273:81 274:81 275:82 276:82 277:82 278:82 279:82 280:82 281:82 282:82 283:82 284:82 285:82 286:82 287:82 288:83 289:83 290:84 291:84 292:84 293:84 294:84 295:84 296:84 297:84 298:84 299:84 300:84 301:84 302:84 303:85 304:85 305:86 306:86 307:86 308:86 309:86 310:86 311:86 312:86 313:86 314:86 315:86 316:86 317:86 318:86 319:87 320:87 321:87 322:87 323:87 324:87 325:87 326:87 327:87 328:87 329:87 330:87 331:87 332:87 333:88 334:89 335:89 336:90 337:90 338:90 339:91 340:91 341:92 342:93 343:94 344:94 345:94 346:94 347:94 348:95 349:95 350:95 351:95 352:95 353:95 354:96 355:96 356:96 357:97 358:97 359:97 360:97 361:98 362:98 363:98 364:99 365:100 366:100 367:101 368:101 369:102 370:103 371:104 372:104 373:104 374:104 375:104 376:105 377:105 378:106 379:106 380:107 381:107 382:107 383:108 384:109 385:109 386:109 387:110 388:110 389:111 390:112 391:112 392:112 393:113 394:113 395:113 396:114 397:115 398:115 399:115 400:116 401:116 402:117 403:118 404:118 405:119 406:120 407:120 408:121 409:121 410:122 411:123 412:123 413:124 414:125 415:126 416:127 417:128 418:129 419:130 420:131 421:132 422:133 423:134 424:135 425:136 426:137 427:138 428:139 429:140 430:141 431:142 432:143 433:143 434:143 435:143 436:144 437:145 438:146 439:146 440:147 441:148 442:149 443:150 444:151 445:152 446:153 447:154 448:155 449:156 450:157 451:157 452:157 453:158 454:159 455:159 456:160 457:160 458:161 459:162 460:162 461:162 462:162 463:162 464:163 465:164 466:165 467:166 468:167 469:168 470:169 471:170 472:171 473:171 474:171 475:172 476:173 477:174 478:175 479:176 480:177 481:178 482:178 483:178 484:179 485:180 486:181 487:182 488:183 489:184 490:185 491:186 492:187 493:187 494:187 495:187 496:187 497:188 498:188 499:188 500:189 501:189 502:189 503:189 504:190 505:190 506:190 507:191 508:191 509:191 510:191\n",
      "I1125 11:12:38.399245 47903194205696 run_squad.py:406] token_to_orig_map: 25:0 26:1 27:2 28:2 29:2 30:2 31:3 32:3 33:4 34:4 35:5 36:6 37:7 38:7 39:8 40:8 41:8 42:9 43:9 44:10 45:10 46:11 47:11 48:12 49:13 50:13 51:13 52:14 53:14 54:15 55:15 56:16 57:16 58:16 59:17 60:17 61:18 62:18 63:18 64:19 65:19 66:19 67:20 68:20 69:21 70:22 71:22 72:23 73:23 74:23 75:23 76:24 77:24 78:25 79:25 80:25 81:25 82:25 83:26 84:27 85:27 86:27 87:27 88:27 89:27 90:28 91:28 92:28 93:29 94:29 95:29 96:29 97:30 98:30 99:31 100:32 101:32 102:33 103:33 104:34 105:34 106:35 107:35 108:35 109:36 110:37 111:38 112:39 113:39 114:39 115:39 116:39 117:40 118:40 119:40 120:40 121:40 122:40 123:41 124:41 125:41 126:41 127:42 128:42 129:42 130:42 131:43 132:43 133:44 134:44 135:45 136:45 137:45 138:45 139:46 140:47 141:47 142:47 143:48 144:48 145:49 146:49 147:50 148:50 149:50 150:50 151:50 152:51 153:51 154:52 155:52 156:53 157:53 158:53 159:53 160:54 161:54 162:55 163:55 164:56 165:56 166:56 167:56 168:57 169:57 170:57 171:58 172:58 173:58 174:58 175:59 176:59 177:59 178:59 179:59 180:59 181:59 182:59 183:60 184:60 185:60 186:60 187:60 188:60 189:60 190:60 191:60 192:61 193:61 194:62 195:62 196:62 197:62 198:63 199:63 200:63 201:63 202:63 203:63 204:64 205:64 206:64 207:65 208:65 209:65 210:65 211:66 212:66 213:66 214:66 215:66 216:66 217:67 218:67 219:67 220:68 221:68 222:68 223:68 224:69 225:70 226:70 227:70 228:71 229:71 230:72 231:72 232:72 233:73 234:73 235:74 236:75 237:76 238:77 239:77 240:77 241:77 242:78 243:79 244:79 245:79 246:79 247:79 248:79 249:79 250:79 251:79 252:79 253:79 254:79 255:79 256:79 257:79 258:79 259:80 260:80 261:81 262:81 263:81 264:81 265:81 266:81 267:81 268:81 269:81 270:81 271:81 272:81 273:81 274:81 275:82 276:82 277:82 278:82 279:82 280:82 281:82 282:82 283:82 284:82 285:82 286:82 287:82 288:83 289:83 290:84 291:84 292:84 293:84 294:84 295:84 296:84 297:84 298:84 299:84 300:84 301:84 302:84 303:85 304:85 305:86 306:86 307:86 308:86 309:86 310:86 311:86 312:86 313:86 314:86 315:86 316:86 317:86 318:86 319:87 320:87 321:87 322:87 323:87 324:87 325:87 326:87 327:87 328:87 329:87 330:87 331:87 332:87 333:88 334:89 335:89 336:90 337:90 338:90 339:91 340:91 341:92 342:93 343:94 344:94 345:94 346:94 347:94 348:95 349:95 350:95 351:95 352:95 353:95 354:96 355:96 356:96 357:97 358:97 359:97 360:97 361:98 362:98 363:98 364:99 365:100 366:100 367:101 368:101 369:102 370:103 371:104 372:104 373:104 374:104 375:104 376:105 377:105 378:106 379:106 380:107 381:107 382:107 383:108 384:109 385:109 386:109 387:110 388:110 389:111 390:112 391:112 392:112 393:113 394:113 395:113 396:114 397:115 398:115 399:115 400:116 401:116 402:117 403:118 404:118 405:119 406:120 407:120 408:121 409:121 410:122 411:123 412:123 413:124 414:125 415:126 416:127 417:128 418:129 419:130 420:131 421:132 422:133 423:134 424:135 425:136 426:137 427:138 428:139 429:140 430:141 431:142 432:143 433:143 434:143 435:143 436:144 437:145 438:146 439:146 440:147 441:148 442:149 443:150 444:151 445:152 446:153 447:154 448:155 449:156 450:157 451:157 452:157 453:158 454:159 455:159 456:160 457:160 458:161 459:162 460:162 461:162 462:162 463:162 464:163 465:164 466:165 467:166 468:167 469:168 470:169 471:170 472:171 473:171 474:171 475:172 476:173 477:174 478:175 479:176 480:177 481:178 482:178 483:178 484:179 485:180 486:181 487:182 488:183 489:184 490:185 491:186 492:187 493:187 494:187 495:187 496:187 497:188 498:188 499:188 500:189 501:189 502:189 503:189 504:190 505:190 506:190 507:191 508:191 509:191 510:191\n",
      "INFO:tensorflow:token_is_max_context: 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "I1125 11:12:38.399438 47903194205696 run_squad.py:408] token_is_max_context: 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "INFO:tensorflow:input_ids: 101 9779 11882 19855 24017 53023 119762 15387 119883 120047 119570 74986 33975 119776 9485 21039 11664 119729 22440 19905 119873 119602 10892 110871 102 9358 119634 9779 121094 12030 33975 119747 17022 119649 14843 9460 13767 120086 10622 9283 41442 119713 48253 110862 9640 38631 58461 110862 103988 9770 16605 119768 9069 17196 9607 21386 8885 14871 119768 8903 16323 9665 17342 12092 9448 36210 10459 9779 11882 9355 9637 108280 9659 33077 41693 12030 31815 45441 9779 11882 19855 24017 32159 119640 8848 17138 12692 54141 119085 110862 9287 58303 119768 119896 12508 79544 17138 119636 11882 119800 86080 36456 119720 119604 9638 20173 119879 119683 10530 119610 58088 120012 9779 11882 19855 24017 53023 8848 17138 12692 54141 119085 10892 119631 32168 119928 119664 9952 19855 120118 11489 119760 120243 9046 61964 119631 78675 34907 11467 22224 9028 77172 110862 119701 120243 9046 61964 119631 87372 119928 52476 110862 119760 119648 9046 61964 119631 78533 34907 110862 119657 119648 9046 61964 119631 69646 119928 119664 9287 58303 60884 119631 32792 34907 11467 119682 118937 58303 110858 119573 78301 34907 119782 119586 118937 58303 110858 119573 77850 34907 110859 80001 9028 119662 119896 12508 79544 107442 119631 11373 11166 119928 48754 110862 119879 119683 11018 119631 120247 119928 119664 8848 17138 12692 54141 119085 11882 9287 58303 119768 119896 12508 79544 17138 9316 119879 119683 11018 9299 42769 9952 19855 120118 8845 35979 119800 8845 119767 9543 110858 110861 119592 120225 119965 60209 120079 110854 110878 110874 65379 110880 110869 119677 32792 11211 110854 119782 48754 110862 119657 119648 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 22650 11373 110854 119557 120020 110858 110854 110878 110874 65379 110880 110869 119677 37301 10729 110854 119557 119760 120243 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 121345 110854 119557 119701 120243 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 24747 10884 110854 119557 9355 14279 120205 110858 110854 110878 110874 65379 110880 110869 119677 121136 110854 110859 36322 55368 11102 86080 119816 11467 119552 119582 35756 119983 9779 11882 19855 24017 53023 8848 17138 12692 54141 119085 110862 9287 58303 119768 119896 12508 79544 119683 119879 119683 11018 119800 86080 53371 8938 10892 23925 119588 9779 11882 19855 24017 53023 119762 15387 119883 120047 119570 74986 33975 119776 9485 21039 11664 119729 119950 53645 8848 17138 14801 9566 44321 10530 18154 9929 118731 10892 119644 11882 110176 120086 10530 18154 120081 11287 119629 14843 23925 119735 119574 10747 14687 24071 10114 22419 10142 38606 10114 46767 33992 10111 59251 10105 23627 14432 10111 45669 10108 108591 15165 55713 18206 110864 10167 10531 14687 110862 10105 21274 10135 23627 14432 10108 10105 11901 39523 10309 119848 18309 110866 59995 25121 110862 75010 110862 10111 38607 110863 51690 67167 110864 10117 38567 10108 10105 14687 10309 31815 108591 15165 55713 18206 10479 10309 14616 10106 169 108591 171 27542 10350 10111 10105 62492 10134 11019 11610 10135 169 16567 110863 11488 25957 10336 20210 26196 110864 157 110863 42615 110862 10464 110863 14132 50972 11403 47172 110862 102\n",
      "I1125 11:12:38.400697 47903194205696 run_squad.py:410] input_ids: 101 9779 11882 19855 24017 53023 119762 15387 119883 120047 119570 74986 33975 119776 9485 21039 11664 119729 22440 19905 119873 119602 10892 110871 102 9358 119634 9779 121094 12030 33975 119747 17022 119649 14843 9460 13767 120086 10622 9283 41442 119713 48253 110862 9640 38631 58461 110862 103988 9770 16605 119768 9069 17196 9607 21386 8885 14871 119768 8903 16323 9665 17342 12092 9448 36210 10459 9779 11882 9355 9637 108280 9659 33077 41693 12030 31815 45441 9779 11882 19855 24017 32159 119640 8848 17138 12692 54141 119085 110862 9287 58303 119768 119896 12508 79544 17138 119636 11882 119800 86080 36456 119720 119604 9638 20173 119879 119683 10530 119610 58088 120012 9779 11882 19855 24017 53023 8848 17138 12692 54141 119085 10892 119631 32168 119928 119664 9952 19855 120118 11489 119760 120243 9046 61964 119631 78675 34907 11467 22224 9028 77172 110862 119701 120243 9046 61964 119631 87372 119928 52476 110862 119760 119648 9046 61964 119631 78533 34907 110862 119657 119648 9046 61964 119631 69646 119928 119664 9287 58303 60884 119631 32792 34907 11467 119682 118937 58303 110858 119573 78301 34907 119782 119586 118937 58303 110858 119573 77850 34907 110859 80001 9028 119662 119896 12508 79544 107442 119631 11373 11166 119928 48754 110862 119879 119683 11018 119631 120247 119928 119664 8848 17138 12692 54141 119085 11882 9287 58303 119768 119896 12508 79544 17138 9316 119879 119683 11018 9299 42769 9952 19855 120118 8845 35979 119800 8845 119767 9543 110858 110861 119592 120225 119965 60209 120079 110854 110878 110874 65379 110880 110869 119677 32792 11211 110854 119782 48754 110862 119657 119648 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 22650 11373 110854 119557 120020 110858 110854 110878 110874 65379 110880 110869 119677 37301 10729 110854 119557 119760 120243 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 121345 110854 119557 119701 120243 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 24747 10884 110854 119557 9355 14279 120205 110858 110854 110878 110874 65379 110880 110869 119677 121136 110854 110859 36322 55368 11102 86080 119816 11467 119552 119582 35756 119983 9779 11882 19855 24017 53023 8848 17138 12692 54141 119085 110862 9287 58303 119768 119896 12508 79544 119683 119879 119683 11018 119800 86080 53371 8938 10892 23925 119588 9779 11882 19855 24017 53023 119762 15387 119883 120047 119570 74986 33975 119776 9485 21039 11664 119729 119950 53645 8848 17138 14801 9566 44321 10530 18154 9929 118731 10892 119644 11882 110176 120086 10530 18154 120081 11287 119629 14843 23925 119735 119574 10747 14687 24071 10114 22419 10142 38606 10114 46767 33992 10111 59251 10105 23627 14432 10111 45669 10108 108591 15165 55713 18206 110864 10167 10531 14687 110862 10105 21274 10135 23627 14432 10108 10105 11901 39523 10309 119848 18309 110866 59995 25121 110862 75010 110862 10111 38607 110863 51690 67167 110864 10117 38567 10108 10105 14687 10309 31815 108591 15165 55713 18206 10479 10309 14616 10106 169 108591 171 27542 10350 10111 10105 62492 10134 11019 11610 10135 169 16567 110863 11488 25957 10336 20210 26196 110864 157 110863 42615 110862 10464 110863 14132 50972 11403 47172 110862 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.400861 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.401010 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.402755 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000012\n",
      "I1125 11:12:38.402843 47903194205696 run_squad.py:400] unique_id: 1000000012\n",
      "INFO:tensorflow:example_index: 11\n",
      "I1125 11:12:38.402905 47903194205696 run_squad.py:401] example_index: 11\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "I1125 11:12:38.402956 47903194205696 run_squad.py:402] doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] 치 ##과 ##위 ##생 ##사의 전문 ##적인 의료 ##서비스 수행 ##능 ##력을 향상 시 ##키 ##고 유지 ##하기 위해 필요한 요인 ##은 ##? [SEP] ##관리 능 ##력이 3. ##38 ##점 ##, 관계 ##관리 능 ##력이 3. ##33 ##점이 ##었다. 몰 ##입 ##도는 3. ##30 ##점 ##으로 조직 ##몰 ##입 ##( ##3. ##34 ##점 ##)이 변화 ##몰 ##입 ##( ##3. ##28 ##점 ##) ##보다 높 ##았다. 환자 ##지 ##향 ##성은 3. ##9 ##5 ##점이 ##었고 ##, 직무 ##성과 ##는 3. ##39 ##점이 ##었다. 감 ##성 ##리 ##더 ##십 ##과 몰 ##입 ##도, 환자 ##지 ##향 ##성 및 직무 ##성과 ##는 물 ##론 하 ##위 ##영역 간 ##에도 상호 간 유의한 양 ##( ##+ ##)의 상관관계를 나타 ##냈다 ##(p ##$ ##{ ##\\ ##beta ##} ##= ##0. ##30 ##6 ##$ ##)이 ##었고 ##, 관계 ##관리 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##20 ##9 ##$ ##), 연령 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##16 ##2 ##$ ##), 자기 ##인식 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##139 ##$ ##), 사회 ##인식 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##12 ##3 ##$ ##), 병 ##원 ##형태 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##101 ##$ ##) 등이 주요 ##한 관련 ##요인 ##으로 분석 ##되었다. 이를 바탕으로 치 ##과 ##위 ##생 ##사의 감 ##성 ##리 ##더 ##십 ##, 몰 ##입 ##도, 환자 ##지 ##향 ##성과 직무 ##성과 ##는 상호 관련 ##성이 깊 ##은 것으로 나타났다. 치 ##과 ##위 ##생 ##사의 전문 ##적인 의료 ##서비스 수행 ##능 ##력을 향상 시 ##키 ##고 유지 ##시키는 다양한 감 ##성 ##적 역 ##량 ##에 대한 폭 ##넓 ##은 인식 ##과 개발 방안 ##에 대한 검토 ##가 필요 ##할 것으로 생각 ##된다. This study intended to search for measures to effectively improve and manage the job performance and personality of dental hy ##gien ##ists ##. In this study ##, the effects on job performance of the following variables were analy ##zed ##: emotional leadership ##, commitment ##, and patient ##- ##orie ##ntation ##. The subjects of the study were 328 dental hy ##gien ##ists who were working in a dental c ##lini ##c and the assessment was made based on a self ##- ##ad ##minister ##ed question ##naire ##. T ##- ##test ##, one ##- ##way AN ##O ##VA ##, and Step ##wise multiple reg ##ression were performed for analysis ##. The average of emotional leadership was 3. ##48 points ##, and commitment was 3. ##30 points ##. Also ##, the average of patient ##- ##orie ##ntation was 3. ##9 ##5 points and that of job performance was 3. ##39 points ##. Em ##otion ##al leadership and commitment ##, as well as patient ##- ##orie ##ntation and job performance ##, showed positive corre ##lation ( ##p ##$ ##{ ##\\ ##beta ##} ##= ##0. ##30 ##6 ##$ ##), followed by the following ##: relationship management ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##20 ##9 ##$ ##) ##; age ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##16 ##2 ##$ ##) ##; self ##- ##awa ##rene ##ss ( ##$ [SEP]\n",
      "I1125 11:12:38.403134 47903194205696 run_squad.py:404] tokens: [CLS] 치 ##과 ##위 ##생 ##사의 전문 ##적인 의료 ##서비스 수행 ##능 ##력을 향상 시 ##키 ##고 유지 ##하기 위해 필요한 요인 ##은 ##? [SEP] ##관리 능 ##력이 3. ##38 ##점 ##, 관계 ##관리 능 ##력이 3. ##33 ##점이 ##었다. 몰 ##입 ##도는 3. ##30 ##점 ##으로 조직 ##몰 ##입 ##( ##3. ##34 ##점 ##)이 변화 ##몰 ##입 ##( ##3. ##28 ##점 ##) ##보다 높 ##았다. 환자 ##지 ##향 ##성은 3. ##9 ##5 ##점이 ##었고 ##, 직무 ##성과 ##는 3. ##39 ##점이 ##었다. 감 ##성 ##리 ##더 ##십 ##과 몰 ##입 ##도, 환자 ##지 ##향 ##성 및 직무 ##성과 ##는 물 ##론 하 ##위 ##영역 간 ##에도 상호 간 유의한 양 ##( ##+ ##)의 상관관계를 나타 ##냈다 ##(p ##$ ##{ ##\\ ##beta ##} ##= ##0. ##30 ##6 ##$ ##)이 ##었고 ##, 관계 ##관리 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##20 ##9 ##$ ##), 연령 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##16 ##2 ##$ ##), 자기 ##인식 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##139 ##$ ##), 사회 ##인식 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##12 ##3 ##$ ##), 병 ##원 ##형태 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##101 ##$ ##) 등이 주요 ##한 관련 ##요인 ##으로 분석 ##되었다. 이를 바탕으로 치 ##과 ##위 ##생 ##사의 감 ##성 ##리 ##더 ##십 ##, 몰 ##입 ##도, 환자 ##지 ##향 ##성과 직무 ##성과 ##는 상호 관련 ##성이 깊 ##은 것으로 나타났다. 치 ##과 ##위 ##생 ##사의 전문 ##적인 의료 ##서비스 수행 ##능 ##력을 향상 시 ##키 ##고 유지 ##시키는 다양한 감 ##성 ##적 역 ##량 ##에 대한 폭 ##넓 ##은 인식 ##과 개발 방안 ##에 대한 검토 ##가 필요 ##할 것으로 생각 ##된다. This study intended to search for measures to effectively improve and manage the job performance and personality of dental hy ##gien ##ists ##. In this study ##, the effects on job performance of the following variables were analy ##zed ##: emotional leadership ##, commitment ##, and patient ##- ##orie ##ntation ##. The subjects of the study were 328 dental hy ##gien ##ists who were working in a dental c ##lini ##c and the assessment was made based on a self ##- ##ad ##minister ##ed question ##naire ##. T ##- ##test ##, one ##- ##way AN ##O ##VA ##, and Step ##wise multiple reg ##ression were performed for analysis ##. The average of emotional leadership was 3. ##48 points ##, and commitment was 3. ##30 points ##. Also ##, the average of patient ##- ##orie ##ntation was 3. ##9 ##5 points and that of job performance was 3. ##39 points ##. Em ##otion ##al leadership and commitment ##, as well as patient ##- ##orie ##ntation and job performance ##, showed positive corre ##lation ( ##p ##$ ##{ ##\\ ##beta ##} ##= ##0. ##30 ##6 ##$ ##), followed by the following ##: relationship management ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##20 ##9 ##$ ##) ##; age ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##16 ##2 ##$ ##) ##; self ##- ##awa ##rene ##ss ( ##$ [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 25:51 26:52 27:52 28:53 29:53 30:53 31:53 32:54 33:54 34:55 35:55 36:56 37:56 38:56 39:56 40:57 41:57 42:57 43:58 44:58 45:58 46:58 47:59 48:59 49:59 50:59 51:59 52:59 53:59 54:59 55:60 56:60 57:60 58:60 59:60 60:60 61:60 62:60 63:60 64:61 65:61 66:62 67:62 68:62 69:62 70:63 71:63 72:63 73:63 74:63 75:63 76:64 77:64 78:64 79:65 80:65 81:65 82:65 83:66 84:66 85:66 86:66 87:66 88:66 89:67 90:67 91:67 92:68 93:68 94:68 95:68 96:69 97:70 98:70 99:70 100:71 101:71 102:72 103:72 104:72 105:73 106:73 107:74 108:75 109:76 110:77 111:77 112:77 113:77 114:78 115:79 116:79 117:79 118:79 119:79 120:79 121:79 122:79 123:79 124:79 125:79 126:79 127:79 128:79 129:79 130:79 131:80 132:80 133:81 134:81 135:81 136:81 137:81 138:81 139:81 140:81 141:81 142:81 143:81 144:81 145:81 146:81 147:82 148:82 149:82 150:82 151:82 152:82 153:82 154:82 155:82 156:82 157:82 158:82 159:82 160:83 161:83 162:84 163:84 164:84 165:84 166:84 167:84 168:84 169:84 170:84 171:84 172:84 173:84 174:84 175:85 176:85 177:86 178:86 179:86 180:86 181:86 182:86 183:86 184:86 185:86 186:86 187:86 188:86 189:86 190:86 191:87 192:87 193:87 194:87 195:87 196:87 197:87 198:87 199:87 200:87 201:87 202:87 203:87 204:87 205:88 206:89 207:89 208:90 209:90 210:90 211:91 212:91 213:92 214:93 215:94 216:94 217:94 218:94 219:94 220:95 221:95 222:95 223:95 224:95 225:95 226:96 227:96 228:96 229:97 230:97 231:97 232:97 233:98 234:98 235:98 236:99 237:100 238:100 239:101 240:101 241:102 242:103 243:104 244:104 245:104 246:104 247:104 248:105 249:105 250:106 251:106 252:107 253:107 254:107 255:108 256:109 257:109 258:109 259:110 260:110 261:111 262:112 263:112 264:112 265:113 266:113 267:113 268:114 269:115 270:115 271:115 272:116 273:116 274:117 275:118 276:118 277:119 278:120 279:120 280:121 281:121 282:122 283:123 284:123 285:124 286:125 287:126 288:127 289:128 290:129 291:130 292:131 293:132 294:133 295:134 296:135 297:136 298:137 299:138 300:139 301:140 302:141 303:142 304:143 305:143 306:143 307:143 308:144 309:145 310:146 311:146 312:147 313:148 314:149 315:150 316:151 317:152 318:153 319:154 320:155 321:156 322:157 323:157 324:157 325:158 326:159 327:159 328:160 329:160 330:161 331:162 332:162 333:162 334:162 335:162 336:163 337:164 338:165 339:166 340:167 341:168 342:169 343:170 344:171 345:171 346:171 347:172 348:173 349:174 350:175 351:176 352:177 353:178 354:178 355:178 356:179 357:180 358:181 359:182 360:183 361:184 362:185 363:186 364:187 365:187 366:187 367:187 368:187 369:188 370:188 371:188 372:189 373:189 374:189 375:189 376:190 377:190 378:190 379:191 380:191 381:191 382:191 383:192 384:193 385:193 386:194 387:195 388:195 389:196 390:197 391:198 392:199 393:199 394:200 395:201 396:202 397:203 398:204 399:205 400:206 401:206 402:207 403:207 404:208 405:209 406:210 407:211 408:211 409:212 410:212 411:213 412:213 413:214 414:215 415:216 416:217 417:217 418:217 419:217 420:218 421:219 422:219 423:219 424:220 425:221 426:222 427:223 428:224 429:225 430:226 431:227 432:227 433:228 434:228 435:229 436:229 437:229 438:230 439:231 440:232 441:232 442:233 443:234 444:235 445:236 446:236 447:236 448:236 449:237 450:238 451:239 452:239 453:240 454:241 455:242 456:242 457:243 458:243 459:243 460:243 461:243 462:243 463:243 464:243 465:243 466:243 467:243 468:243 469:243 470:244 471:245 472:246 473:247 474:247 475:248 476:249 477:250 478:250 479:250 480:250 481:250 482:250 483:250 484:250 485:250 486:250 487:250 488:250 489:250 490:251 491:252 492:252 493:252 494:252 495:252 496:252 497:252 498:252 499:252 500:252 501:252 502:252 503:252 504:253 505:253 506:253 507:253 508:253 509:254 510:254\n",
      "I1125 11:12:38.403352 47903194205696 run_squad.py:406] token_to_orig_map: 25:51 26:52 27:52 28:53 29:53 30:53 31:53 32:54 33:54 34:55 35:55 36:56 37:56 38:56 39:56 40:57 41:57 42:57 43:58 44:58 45:58 46:58 47:59 48:59 49:59 50:59 51:59 52:59 53:59 54:59 55:60 56:60 57:60 58:60 59:60 60:60 61:60 62:60 63:60 64:61 65:61 66:62 67:62 68:62 69:62 70:63 71:63 72:63 73:63 74:63 75:63 76:64 77:64 78:64 79:65 80:65 81:65 82:65 83:66 84:66 85:66 86:66 87:66 88:66 89:67 90:67 91:67 92:68 93:68 94:68 95:68 96:69 97:70 98:70 99:70 100:71 101:71 102:72 103:72 104:72 105:73 106:73 107:74 108:75 109:76 110:77 111:77 112:77 113:77 114:78 115:79 116:79 117:79 118:79 119:79 120:79 121:79 122:79 123:79 124:79 125:79 126:79 127:79 128:79 129:79 130:79 131:80 132:80 133:81 134:81 135:81 136:81 137:81 138:81 139:81 140:81 141:81 142:81 143:81 144:81 145:81 146:81 147:82 148:82 149:82 150:82 151:82 152:82 153:82 154:82 155:82 156:82 157:82 158:82 159:82 160:83 161:83 162:84 163:84 164:84 165:84 166:84 167:84 168:84 169:84 170:84 171:84 172:84 173:84 174:84 175:85 176:85 177:86 178:86 179:86 180:86 181:86 182:86 183:86 184:86 185:86 186:86 187:86 188:86 189:86 190:86 191:87 192:87 193:87 194:87 195:87 196:87 197:87 198:87 199:87 200:87 201:87 202:87 203:87 204:87 205:88 206:89 207:89 208:90 209:90 210:90 211:91 212:91 213:92 214:93 215:94 216:94 217:94 218:94 219:94 220:95 221:95 222:95 223:95 224:95 225:95 226:96 227:96 228:96 229:97 230:97 231:97 232:97 233:98 234:98 235:98 236:99 237:100 238:100 239:101 240:101 241:102 242:103 243:104 244:104 245:104 246:104 247:104 248:105 249:105 250:106 251:106 252:107 253:107 254:107 255:108 256:109 257:109 258:109 259:110 260:110 261:111 262:112 263:112 264:112 265:113 266:113 267:113 268:114 269:115 270:115 271:115 272:116 273:116 274:117 275:118 276:118 277:119 278:120 279:120 280:121 281:121 282:122 283:123 284:123 285:124 286:125 287:126 288:127 289:128 290:129 291:130 292:131 293:132 294:133 295:134 296:135 297:136 298:137 299:138 300:139 301:140 302:141 303:142 304:143 305:143 306:143 307:143 308:144 309:145 310:146 311:146 312:147 313:148 314:149 315:150 316:151 317:152 318:153 319:154 320:155 321:156 322:157 323:157 324:157 325:158 326:159 327:159 328:160 329:160 330:161 331:162 332:162 333:162 334:162 335:162 336:163 337:164 338:165 339:166 340:167 341:168 342:169 343:170 344:171 345:171 346:171 347:172 348:173 349:174 350:175 351:176 352:177 353:178 354:178 355:178 356:179 357:180 358:181 359:182 360:183 361:184 362:185 363:186 364:187 365:187 366:187 367:187 368:187 369:188 370:188 371:188 372:189 373:189 374:189 375:189 376:190 377:190 378:190 379:191 380:191 381:191 382:191 383:192 384:193 385:193 386:194 387:195 388:195 389:196 390:197 391:198 392:199 393:199 394:200 395:201 396:202 397:203 398:204 399:205 400:206 401:206 402:207 403:207 404:208 405:209 406:210 407:211 408:211 409:212 410:212 411:213 412:213 413:214 414:215 415:216 416:217 417:217 418:217 419:217 420:218 421:219 422:219 423:219 424:220 425:221 426:222 427:223 428:224 429:225 430:226 431:227 432:227 433:228 434:228 435:229 436:229 437:229 438:230 439:231 440:232 441:232 442:233 443:234 444:235 445:236 446:236 447:236 448:236 449:237 450:238 451:239 452:239 453:240 454:241 455:242 456:242 457:243 458:243 459:243 460:243 461:243 462:243 463:243 464:243 465:243 466:243 467:243 468:243 469:243 470:244 471:245 472:246 473:247 474:247 475:248 476:249 477:250 478:250 479:250 480:250 481:250 482:250 483:250 484:250 485:250 486:250 487:250 488:250 489:250 490:251 491:252 492:252 493:252 494:252 495:252 496:252 497:252 498:252 499:252 500:252 501:252 502:252 503:252 504:253 505:253 506:253 507:253 508:253 509:254 510:254\n",
      "INFO:tensorflow:token_is_max_context: 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:False 202:False 203:False 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "I1125 11:12:38.403547 47903194205696 run_squad.py:408] token_is_max_context: 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:False 202:False 203:False 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "INFO:tensorflow:input_ids: 101 9779 11882 19855 24017 53023 119762 15387 119883 120047 119570 74986 33975 119776 9485 21039 11664 119729 22440 19905 119873 119602 10892 110871 102 119648 9046 61964 119631 78533 34907 110862 119657 119648 9046 61964 119631 69646 119928 119664 9287 58303 60884 119631 32792 34907 11467 119682 118937 58303 110858 119573 78301 34907 119782 119586 118937 58303 110858 119573 77850 34907 110859 80001 9028 119662 119896 12508 79544 107442 119631 11373 11166 119928 48754 110862 119879 119683 11018 119631 120247 119928 119664 8848 17138 12692 54141 119085 11882 9287 58303 119768 119896 12508 79544 17138 9316 119879 119683 11018 9299 42769 9952 19855 120118 8845 35979 119800 8845 119767 9543 110858 110861 119592 120225 119965 60209 120079 110854 110878 110874 65379 110880 110869 119677 32792 11211 110854 119782 48754 110862 119657 119648 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 22650 11373 110854 119557 120020 110858 110854 110878 110874 65379 110880 110869 119677 37301 10729 110854 119557 119760 120243 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 121345 110854 119557 119701 120243 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 24747 10884 110854 119557 9355 14279 120205 110858 110854 110878 110874 65379 110880 110869 119677 121136 110854 110859 36322 55368 11102 86080 119816 11467 119552 119582 35756 119983 9779 11882 19855 24017 53023 8848 17138 12692 54141 119085 110862 9287 58303 119768 119896 12508 79544 119683 119879 119683 11018 119800 86080 53371 8938 10892 23925 119588 9779 11882 19855 24017 53023 119762 15387 119883 120047 119570 74986 33975 119776 9485 21039 11664 119729 119950 53645 8848 17138 14801 9566 44321 10530 18154 9929 118731 10892 119644 11882 110176 120086 10530 18154 120081 11287 119629 14843 23925 119735 119574 10747 14687 24071 10114 22419 10142 38606 10114 46767 33992 10111 59251 10105 23627 14432 10111 45669 10108 108591 15165 55713 18206 110864 10167 10531 14687 110862 10105 21274 10135 23627 14432 10108 10105 11901 39523 10309 119848 18309 110866 59995 25121 110862 75010 110862 10111 38607 110863 51690 67167 110864 10117 38567 10108 10105 14687 10309 31815 108591 15165 55713 18206 10479 10309 14616 10106 169 108591 171 27542 10350 10111 10105 62492 10134 11019 11610 10135 169 16567 110863 11488 25957 10336 20210 26196 110864 157 110863 42615 110862 10464 110863 14132 50972 11403 47172 110862 10111 41653 48339 19865 120158 45791 10309 15282 10142 19129 110864 10117 13551 10108 59995 25121 10134 119631 32168 12789 110862 10111 75010 10134 119631 32792 12789 110864 20593 110862 10105 13551 10108 38607 110863 51690 67167 10134 119631 11373 11166 12789 10111 10189 10108 23627 14432 10134 119631 120247 12789 110864 11289 70984 10415 25121 10111 75010 110862 10146 11206 10146 38607 110863 51690 67167 10111 23627 14432 110862 27463 19737 64741 19718 113 10410 110854 110878 110874 65379 110880 110869 119677 32792 11211 110854 119557 15689 10155 10105 11901 110866 19808 17150 113 110854 110878 110874 65379 110880 110869 119677 22650 11373 110854 110859 110867 12089 113 110854 110878 110874 65379 110880 110869 119677 37301 10729 110854 110859 110867 16567 110863 27593 36363 13420 113 110854 102\n",
      "I1125 11:12:38.404736 47903194205696 run_squad.py:410] input_ids: 101 9779 11882 19855 24017 53023 119762 15387 119883 120047 119570 74986 33975 119776 9485 21039 11664 119729 22440 19905 119873 119602 10892 110871 102 119648 9046 61964 119631 78533 34907 110862 119657 119648 9046 61964 119631 69646 119928 119664 9287 58303 60884 119631 32792 34907 11467 119682 118937 58303 110858 119573 78301 34907 119782 119586 118937 58303 110858 119573 77850 34907 110859 80001 9028 119662 119896 12508 79544 107442 119631 11373 11166 119928 48754 110862 119879 119683 11018 119631 120247 119928 119664 8848 17138 12692 54141 119085 11882 9287 58303 119768 119896 12508 79544 17138 9316 119879 119683 11018 9299 42769 9952 19855 120118 8845 35979 119800 8845 119767 9543 110858 110861 119592 120225 119965 60209 120079 110854 110878 110874 65379 110880 110869 119677 32792 11211 110854 119782 48754 110862 119657 119648 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 22650 11373 110854 119557 120020 110858 110854 110878 110874 65379 110880 110869 119677 37301 10729 110854 119557 119760 120243 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 121345 110854 119557 119701 120243 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 24747 10884 110854 119557 9355 14279 120205 110858 110854 110878 110874 65379 110880 110869 119677 121136 110854 110859 36322 55368 11102 86080 119816 11467 119552 119582 35756 119983 9779 11882 19855 24017 53023 8848 17138 12692 54141 119085 110862 9287 58303 119768 119896 12508 79544 119683 119879 119683 11018 119800 86080 53371 8938 10892 23925 119588 9779 11882 19855 24017 53023 119762 15387 119883 120047 119570 74986 33975 119776 9485 21039 11664 119729 119950 53645 8848 17138 14801 9566 44321 10530 18154 9929 118731 10892 119644 11882 110176 120086 10530 18154 120081 11287 119629 14843 23925 119735 119574 10747 14687 24071 10114 22419 10142 38606 10114 46767 33992 10111 59251 10105 23627 14432 10111 45669 10108 108591 15165 55713 18206 110864 10167 10531 14687 110862 10105 21274 10135 23627 14432 10108 10105 11901 39523 10309 119848 18309 110866 59995 25121 110862 75010 110862 10111 38607 110863 51690 67167 110864 10117 38567 10108 10105 14687 10309 31815 108591 15165 55713 18206 10479 10309 14616 10106 169 108591 171 27542 10350 10111 10105 62492 10134 11019 11610 10135 169 16567 110863 11488 25957 10336 20210 26196 110864 157 110863 42615 110862 10464 110863 14132 50972 11403 47172 110862 10111 41653 48339 19865 120158 45791 10309 15282 10142 19129 110864 10117 13551 10108 59995 25121 10134 119631 32168 12789 110862 10111 75010 10134 119631 32792 12789 110864 20593 110862 10105 13551 10108 38607 110863 51690 67167 10134 119631 11373 11166 12789 10111 10189 10108 23627 14432 10134 119631 120247 12789 110864 11289 70984 10415 25121 10111 75010 110862 10146 11206 10146 38607 110863 51690 67167 10111 23627 14432 110862 27463 19737 64741 19718 113 10410 110854 110878 110874 65379 110880 110869 119677 32792 11211 110854 119557 15689 10155 10105 11901 110866 19808 17150 113 110854 110878 110874 65379 110880 110869 119677 22650 11373 110854 110859 110867 12089 113 110854 110878 110874 65379 110880 110869 119677 37301 10729 110854 110859 110867 16567 110863 27593 36363 13420 113 110854 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.405913 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.406064 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.407595 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000013\n",
      "I1125 11:12:38.407677 47903194205696 run_squad.py:400] unique_id: 1000000013\n",
      "INFO:tensorflow:example_index: 11\n",
      "I1125 11:12:38.407729 47903194205696 run_squad.py:401] example_index: 11\n",
      "INFO:tensorflow:doc_span_index: 2\n",
      "I1125 11:12:38.407776 47903194205696 run_squad.py:402] doc_span_index: 2\n",
      "INFO:tensorflow:tokens: [CLS] 치 ##과 ##위 ##생 ##사의 전문 ##적인 의료 ##서비스 수행 ##능 ##력을 향상 시 ##키 ##고 유지 ##하기 위해 필요한 요인 ##은 ##? [SEP] ##} ##= ##0. ##16 ##2 ##$ ##), 자기 ##인식 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##139 ##$ ##), 사회 ##인식 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##12 ##3 ##$ ##), 병 ##원 ##형태 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##101 ##$ ##) 등이 주요 ##한 관련 ##요인 ##으로 분석 ##되었다. 이를 바탕으로 치 ##과 ##위 ##생 ##사의 감 ##성 ##리 ##더 ##십 ##, 몰 ##입 ##도, 환자 ##지 ##향 ##성과 직무 ##성과 ##는 상호 관련 ##성이 깊 ##은 것으로 나타났다. 치 ##과 ##위 ##생 ##사의 전문 ##적인 의료 ##서비스 수행 ##능 ##력을 향상 시 ##키 ##고 유지 ##시키는 다양한 감 ##성 ##적 역 ##량 ##에 대한 폭 ##넓 ##은 인식 ##과 개발 방안 ##에 대한 검토 ##가 필요 ##할 것으로 생각 ##된다. This study intended to search for measures to effectively improve and manage the job performance and personality of dental hy ##gien ##ists ##. In this study ##, the effects on job performance of the following variables were analy ##zed ##: emotional leadership ##, commitment ##, and patient ##- ##orie ##ntation ##. The subjects of the study were 328 dental hy ##gien ##ists who were working in a dental c ##lini ##c and the assessment was made based on a self ##- ##ad ##minister ##ed question ##naire ##. T ##- ##test ##, one ##- ##way AN ##O ##VA ##, and Step ##wise multiple reg ##ression were performed for analysis ##. The average of emotional leadership was 3. ##48 points ##, and commitment was 3. ##30 points ##. Also ##, the average of patient ##- ##orie ##ntation was 3. ##9 ##5 points and that of job performance was 3. ##39 points ##. Em ##otion ##al leadership and commitment ##, as well as patient ##- ##orie ##ntation and job performance ##, showed positive corre ##lation ( ##p ##$ ##{ ##\\ ##beta ##} ##= ##0. ##30 ##6 ##$ ##), followed by the following ##: relationship management ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##20 ##9 ##$ ##) ##; age ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##16 ##2 ##$ ##) ##; self ##- ##awa ##rene ##ss ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##139 ##$ ##) ##; social ##- ##awa ##rene ##ss ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##12 ##3 ##$ ##) ##; and c ##lini ##c type ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##101 ##$ ##). Based from the results of the study ##, there is a need to recognize the relationship among emotional leadership ##, commitment ##, and patient ##- ##orie ##ntation in connection with job performance ##. [SEP]\n",
      "I1125 11:12:38.407936 47903194205696 run_squad.py:404] tokens: [CLS] 치 ##과 ##위 ##생 ##사의 전문 ##적인 의료 ##서비스 수행 ##능 ##력을 향상 시 ##키 ##고 유지 ##하기 위해 필요한 요인 ##은 ##? [SEP] ##} ##= ##0. ##16 ##2 ##$ ##), 자기 ##인식 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##139 ##$ ##), 사회 ##인식 능 ##력 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##12 ##3 ##$ ##), 병 ##원 ##형태 ##( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##101 ##$ ##) 등이 주요 ##한 관련 ##요인 ##으로 분석 ##되었다. 이를 바탕으로 치 ##과 ##위 ##생 ##사의 감 ##성 ##리 ##더 ##십 ##, 몰 ##입 ##도, 환자 ##지 ##향 ##성과 직무 ##성과 ##는 상호 관련 ##성이 깊 ##은 것으로 나타났다. 치 ##과 ##위 ##생 ##사의 전문 ##적인 의료 ##서비스 수행 ##능 ##력을 향상 시 ##키 ##고 유지 ##시키는 다양한 감 ##성 ##적 역 ##량 ##에 대한 폭 ##넓 ##은 인식 ##과 개발 방안 ##에 대한 검토 ##가 필요 ##할 것으로 생각 ##된다. This study intended to search for measures to effectively improve and manage the job performance and personality of dental hy ##gien ##ists ##. In this study ##, the effects on job performance of the following variables were analy ##zed ##: emotional leadership ##, commitment ##, and patient ##- ##orie ##ntation ##. The subjects of the study were 328 dental hy ##gien ##ists who were working in a dental c ##lini ##c and the assessment was made based on a self ##- ##ad ##minister ##ed question ##naire ##. T ##- ##test ##, one ##- ##way AN ##O ##VA ##, and Step ##wise multiple reg ##ression were performed for analysis ##. The average of emotional leadership was 3. ##48 points ##, and commitment was 3. ##30 points ##. Also ##, the average of patient ##- ##orie ##ntation was 3. ##9 ##5 points and that of job performance was 3. ##39 points ##. Em ##otion ##al leadership and commitment ##, as well as patient ##- ##orie ##ntation and job performance ##, showed positive corre ##lation ( ##p ##$ ##{ ##\\ ##beta ##} ##= ##0. ##30 ##6 ##$ ##), followed by the following ##: relationship management ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##20 ##9 ##$ ##) ##; age ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##16 ##2 ##$ ##) ##; self ##- ##awa ##rene ##ss ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##139 ##$ ##) ##; social ##- ##awa ##rene ##ss ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##12 ##3 ##$ ##) ##; and c ##lini ##c type ( ##$ ##{ ##\\ ##beta ##} ##= ##0. ##101 ##$ ##). Based from the results of the study ##, there is a need to recognize the relationship among emotional leadership ##, commitment ##, and patient ##- ##orie ##ntation in connection with job performance ##. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 25:82 26:82 27:82 28:82 29:82 30:82 31:82 32:83 33:83 34:84 35:84 36:84 37:84 38:84 39:84 40:84 41:84 42:84 43:84 44:84 45:84 46:84 47:85 48:85 49:86 50:86 51:86 52:86 53:86 54:86 55:86 56:86 57:86 58:86 59:86 60:86 61:86 62:86 63:87 64:87 65:87 66:87 67:87 68:87 69:87 70:87 71:87 72:87 73:87 74:87 75:87 76:87 77:88 78:89 79:89 80:90 81:90 82:90 83:91 84:91 85:92 86:93 87:94 88:94 89:94 90:94 91:94 92:95 93:95 94:95 95:95 96:95 97:95 98:96 99:96 100:96 101:97 102:97 103:97 104:97 105:98 106:98 107:98 108:99 109:100 110:100 111:101 112:101 113:102 114:103 115:104 116:104 117:104 118:104 119:104 120:105 121:105 122:106 123:106 124:107 125:107 126:107 127:108 128:109 129:109 130:109 131:110 132:110 133:111 134:112 135:112 136:112 137:113 138:113 139:113 140:114 141:115 142:115 143:115 144:116 145:116 146:117 147:118 148:118 149:119 150:120 151:120 152:121 153:121 154:122 155:123 156:123 157:124 158:125 159:126 160:127 161:128 162:129 163:130 164:131 165:132 166:133 167:134 168:135 169:136 170:137 171:138 172:139 173:140 174:141 175:142 176:143 177:143 178:143 179:143 180:144 181:145 182:146 183:146 184:147 185:148 186:149 187:150 188:151 189:152 190:153 191:154 192:155 193:156 194:157 195:157 196:157 197:158 198:159 199:159 200:160 201:160 202:161 203:162 204:162 205:162 206:162 207:162 208:163 209:164 210:165 211:166 212:167 213:168 214:169 215:170 216:171 217:171 218:171 219:172 220:173 221:174 222:175 223:176 224:177 225:178 226:178 227:178 228:179 229:180 230:181 231:182 232:183 233:184 234:185 235:186 236:187 237:187 238:187 239:187 240:187 241:188 242:188 243:188 244:189 245:189 246:189 247:189 248:190 249:190 250:190 251:191 252:191 253:191 254:191 255:192 256:193 257:193 258:194 259:195 260:195 261:196 262:197 263:198 264:199 265:199 266:200 267:201 268:202 269:203 270:204 271:205 272:206 273:206 274:207 275:207 276:208 277:209 278:210 279:211 280:211 281:212 282:212 283:213 284:213 285:214 286:215 287:216 288:217 289:217 290:217 291:217 292:218 293:219 294:219 295:219 296:220 297:221 298:222 299:223 300:224 301:225 302:226 303:227 304:227 305:228 306:228 307:229 308:229 309:229 310:230 311:231 312:232 313:232 314:233 315:234 316:235 317:236 318:236 319:236 320:236 321:237 322:238 323:239 324:239 325:240 326:241 327:242 328:242 329:243 330:243 331:243 332:243 333:243 334:243 335:243 336:243 337:243 338:243 339:243 340:243 341:243 342:244 343:245 344:246 345:247 346:247 347:248 348:249 349:250 350:250 351:250 352:250 353:250 354:250 355:250 356:250 357:250 358:250 359:250 360:250 361:250 362:251 363:252 364:252 365:252 366:252 367:252 368:252 369:252 370:252 371:252 372:252 373:252 374:252 375:252 376:253 377:253 378:253 379:253 380:253 381:254 382:254 383:254 384:254 385:254 386:254 387:254 388:254 389:254 390:254 391:254 392:254 393:255 394:255 395:255 396:255 397:255 398:256 399:256 400:256 401:256 402:256 403:256 404:256 405:256 406:256 407:256 408:256 409:256 410:256 411:257 412:258 413:258 414:258 415:259 416:260 417:260 418:260 419:260 420:260 421:260 422:260 423:260 424:260 425:260 426:260 427:261 428:262 429:263 430:264 431:265 432:266 433:267 434:267 435:268 436:269 437:270 438:271 439:272 440:273 441:274 442:275 443:276 444:277 445:278 446:278 447:279 448:279 449:280 450:281 451:281 452:281 453:281 454:282 455:283 456:284 457:285 458:286 459:286\n",
      "I1125 11:12:38.408137 47903194205696 run_squad.py:406] token_to_orig_map: 25:82 26:82 27:82 28:82 29:82 30:82 31:82 32:83 33:83 34:84 35:84 36:84 37:84 38:84 39:84 40:84 41:84 42:84 43:84 44:84 45:84 46:84 47:85 48:85 49:86 50:86 51:86 52:86 53:86 54:86 55:86 56:86 57:86 58:86 59:86 60:86 61:86 62:86 63:87 64:87 65:87 66:87 67:87 68:87 69:87 70:87 71:87 72:87 73:87 74:87 75:87 76:87 77:88 78:89 79:89 80:90 81:90 82:90 83:91 84:91 85:92 86:93 87:94 88:94 89:94 90:94 91:94 92:95 93:95 94:95 95:95 96:95 97:95 98:96 99:96 100:96 101:97 102:97 103:97 104:97 105:98 106:98 107:98 108:99 109:100 110:100 111:101 112:101 113:102 114:103 115:104 116:104 117:104 118:104 119:104 120:105 121:105 122:106 123:106 124:107 125:107 126:107 127:108 128:109 129:109 130:109 131:110 132:110 133:111 134:112 135:112 136:112 137:113 138:113 139:113 140:114 141:115 142:115 143:115 144:116 145:116 146:117 147:118 148:118 149:119 150:120 151:120 152:121 153:121 154:122 155:123 156:123 157:124 158:125 159:126 160:127 161:128 162:129 163:130 164:131 165:132 166:133 167:134 168:135 169:136 170:137 171:138 172:139 173:140 174:141 175:142 176:143 177:143 178:143 179:143 180:144 181:145 182:146 183:146 184:147 185:148 186:149 187:150 188:151 189:152 190:153 191:154 192:155 193:156 194:157 195:157 196:157 197:158 198:159 199:159 200:160 201:160 202:161 203:162 204:162 205:162 206:162 207:162 208:163 209:164 210:165 211:166 212:167 213:168 214:169 215:170 216:171 217:171 218:171 219:172 220:173 221:174 222:175 223:176 224:177 225:178 226:178 227:178 228:179 229:180 230:181 231:182 232:183 233:184 234:185 235:186 236:187 237:187 238:187 239:187 240:187 241:188 242:188 243:188 244:189 245:189 246:189 247:189 248:190 249:190 250:190 251:191 252:191 253:191 254:191 255:192 256:193 257:193 258:194 259:195 260:195 261:196 262:197 263:198 264:199 265:199 266:200 267:201 268:202 269:203 270:204 271:205 272:206 273:206 274:207 275:207 276:208 277:209 278:210 279:211 280:211 281:212 282:212 283:213 284:213 285:214 286:215 287:216 288:217 289:217 290:217 291:217 292:218 293:219 294:219 295:219 296:220 297:221 298:222 299:223 300:224 301:225 302:226 303:227 304:227 305:228 306:228 307:229 308:229 309:229 310:230 311:231 312:232 313:232 314:233 315:234 316:235 317:236 318:236 319:236 320:236 321:237 322:238 323:239 324:239 325:240 326:241 327:242 328:242 329:243 330:243 331:243 332:243 333:243 334:243 335:243 336:243 337:243 338:243 339:243 340:243 341:243 342:244 343:245 344:246 345:247 346:247 347:248 348:249 349:250 350:250 351:250 352:250 353:250 354:250 355:250 356:250 357:250 358:250 359:250 360:250 361:250 362:251 363:252 364:252 365:252 366:252 367:252 368:252 369:252 370:252 371:252 372:252 373:252 374:252 375:252 376:253 377:253 378:253 379:253 380:253 381:254 382:254 383:254 384:254 385:254 386:254 387:254 388:254 389:254 390:254 391:254 392:254 393:255 394:255 395:255 396:255 397:255 398:256 399:256 400:256 401:256 402:256 403:256 404:256 405:256 406:256 407:256 408:256 409:256 410:256 411:257 412:258 413:258 414:258 415:259 416:260 417:260 418:260 419:260 420:260 421:260 422:260 423:260 424:260 425:260 426:260 427:261 428:262 429:263 430:264 431:265 432:266 433:267 434:267 435:268 436:269 437:270 438:271 439:272 440:273 441:274 442:275 443:276 444:277 445:278 446:278 447:279 448:279 449:280 450:281 451:281 452:281 453:281 454:282 455:283 456:284 457:285 458:286 459:286\n",
      "INFO:tensorflow:token_is_max_context: 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:False 202:False 203:False 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True\n",
      "I1125 11:12:38.412881 47903194205696 run_squad.py:408] token_is_max_context: 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:False 202:False 203:False 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True\n",
      "INFO:tensorflow:input_ids: 101 9779 11882 19855 24017 53023 119762 15387 119883 120047 119570 74986 33975 119776 9485 21039 11664 119729 22440 19905 119873 119602 10892 110871 102 110880 110869 119677 37301 10729 110854 119557 119760 120243 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 121345 110854 119557 119701 120243 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 24747 10884 110854 119557 9355 14279 120205 110858 110854 110878 110874 65379 110880 110869 119677 121136 110854 110859 36322 55368 11102 86080 119816 11467 119552 119582 35756 119983 9779 11882 19855 24017 53023 8848 17138 12692 54141 119085 110862 9287 58303 119768 119896 12508 79544 119683 119879 119683 11018 119800 86080 53371 8938 10892 23925 119588 9779 11882 19855 24017 53023 119762 15387 119883 120047 119570 74986 33975 119776 9485 21039 11664 119729 119950 53645 8848 17138 14801 9566 44321 10530 18154 9929 118731 10892 119644 11882 110176 120086 10530 18154 120081 11287 119629 14843 23925 119735 119574 10747 14687 24071 10114 22419 10142 38606 10114 46767 33992 10111 59251 10105 23627 14432 10111 45669 10108 108591 15165 55713 18206 110864 10167 10531 14687 110862 10105 21274 10135 23627 14432 10108 10105 11901 39523 10309 119848 18309 110866 59995 25121 110862 75010 110862 10111 38607 110863 51690 67167 110864 10117 38567 10108 10105 14687 10309 31815 108591 15165 55713 18206 10479 10309 14616 10106 169 108591 171 27542 10350 10111 10105 62492 10134 11019 11610 10135 169 16567 110863 11488 25957 10336 20210 26196 110864 157 110863 42615 110862 10464 110863 14132 50972 11403 47172 110862 10111 41653 48339 19865 120158 45791 10309 15282 10142 19129 110864 10117 13551 10108 59995 25121 10134 119631 32168 12789 110862 10111 75010 10134 119631 32792 12789 110864 20593 110862 10105 13551 10108 38607 110863 51690 67167 10134 119631 11373 11166 12789 10111 10189 10108 23627 14432 10134 119631 120247 12789 110864 11289 70984 10415 25121 10111 75010 110862 10146 11206 10146 38607 110863 51690 67167 10111 23627 14432 110862 27463 19737 64741 19718 113 10410 110854 110878 110874 65379 110880 110869 119677 32792 11211 110854 119557 15689 10155 10105 11901 110866 19808 17150 113 110854 110878 110874 65379 110880 110869 119677 22650 11373 110854 110859 110867 12089 113 110854 110878 110874 65379 110880 110869 119677 37301 10729 110854 110859 110867 16567 110863 27593 36363 13420 113 110854 110878 110874 65379 110880 110869 119677 121345 110854 110859 110867 12142 110863 27593 36363 13420 113 110854 110878 110874 65379 110880 110869 119677 24747 10884 110854 110859 110867 10111 171 27542 10350 12807 113 110854 110878 110874 65379 110880 110869 119677 121136 110854 119558 39264 10188 10105 17466 10108 10105 14687 110862 11155 10124 169 17367 10114 80673 10105 19808 13328 59995 25121 110862 75010 110862 10111 38607 110863 51690 67167 10106 31671 10169 23627 14432 110864 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.413113 47903194205696 run_squad.py:410] input_ids: 101 9779 11882 19855 24017 53023 119762 15387 119883 120047 119570 74986 33975 119776 9485 21039 11664 119729 22440 19905 119873 119602 10892 110871 102 110880 110869 119677 37301 10729 110854 119557 119760 120243 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 121345 110854 119557 119701 120243 9046 28143 110858 110854 110878 110874 65379 110880 110869 119677 24747 10884 110854 119557 9355 14279 120205 110858 110854 110878 110874 65379 110880 110869 119677 121136 110854 110859 36322 55368 11102 86080 119816 11467 119552 119582 35756 119983 9779 11882 19855 24017 53023 8848 17138 12692 54141 119085 110862 9287 58303 119768 119896 12508 79544 119683 119879 119683 11018 119800 86080 53371 8938 10892 23925 119588 9779 11882 19855 24017 53023 119762 15387 119883 120047 119570 74986 33975 119776 9485 21039 11664 119729 119950 53645 8848 17138 14801 9566 44321 10530 18154 9929 118731 10892 119644 11882 110176 120086 10530 18154 120081 11287 119629 14843 23925 119735 119574 10747 14687 24071 10114 22419 10142 38606 10114 46767 33992 10111 59251 10105 23627 14432 10111 45669 10108 108591 15165 55713 18206 110864 10167 10531 14687 110862 10105 21274 10135 23627 14432 10108 10105 11901 39523 10309 119848 18309 110866 59995 25121 110862 75010 110862 10111 38607 110863 51690 67167 110864 10117 38567 10108 10105 14687 10309 31815 108591 15165 55713 18206 10479 10309 14616 10106 169 108591 171 27542 10350 10111 10105 62492 10134 11019 11610 10135 169 16567 110863 11488 25957 10336 20210 26196 110864 157 110863 42615 110862 10464 110863 14132 50972 11403 47172 110862 10111 41653 48339 19865 120158 45791 10309 15282 10142 19129 110864 10117 13551 10108 59995 25121 10134 119631 32168 12789 110862 10111 75010 10134 119631 32792 12789 110864 20593 110862 10105 13551 10108 38607 110863 51690 67167 10134 119631 11373 11166 12789 10111 10189 10108 23627 14432 10134 119631 120247 12789 110864 11289 70984 10415 25121 10111 75010 110862 10146 11206 10146 38607 110863 51690 67167 10111 23627 14432 110862 27463 19737 64741 19718 113 10410 110854 110878 110874 65379 110880 110869 119677 32792 11211 110854 119557 15689 10155 10105 11901 110866 19808 17150 113 110854 110878 110874 65379 110880 110869 119677 22650 11373 110854 110859 110867 12089 113 110854 110878 110874 65379 110880 110869 119677 37301 10729 110854 110859 110867 16567 110863 27593 36363 13420 113 110854 110878 110874 65379 110880 110869 119677 121345 110854 110859 110867 12142 110863 27593 36363 13420 113 110854 110878 110874 65379 110880 110869 119677 24747 10884 110854 110859 110867 10111 171 27542 10350 12807 113 110854 110878 110874 65379 110880 110869 119677 121136 110854 119558 39264 10188 10105 17466 10108 10105 14687 110862 11155 10124 169 17367 10114 80673 10105 19808 13328 59995 25121 110862 75010 110862 10111 38607 110863 51690 67167 10106 31671 10169 23627 14432 110864 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.414131 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.414292 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.415582 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000014\n",
      "I1125 11:12:38.415674 47903194205696 run_squad.py:400] unique_id: 1000000014\n",
      "INFO:tensorflow:example_index: 12\n",
      "I1125 11:12:38.415739 47903194205696 run_squad.py:401] example_index: 12\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.415791 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 치 ##과 ##위 ##생 ##사의 자 ##질 ##은 무 ##엇 ##인 ##가 ##? [SEP] 치 ##과 ##위 ##생 ##사는 치 ##과의료 ##기관 ##의 핵 ##심 인 ##적 ##자 ##원으로 구 ##강 ##진 ##료 일 ##선 ##에서 환자를 직접 대 ##면 ##하여 관리 ##하는 업무 ##를 수행 ##한다. 최근 의료 ##소비 ##자는 치료 ##와 회 ##복 ##은 물 ##론 정 ##서 ##적 만족 ##감 ##까지 충 ##족 ##하 ##길 요구 ##한다. 따라서 치 ##과 ##위 ##생 ##사는 수준 높은 의료 ##서비스 ##를 제공 ##하는 기본 업무 외 ##에도 의료 ##소비 ##자의 다양한 상황 ##에 유 ##연 ##하게 대 ##처 ##하며 다양한 사람 ##들의 감 ##성을 조절 ##하여 문제 ##를 복 ##합 ##적으로 해결 ##할 수 있는 감 ##성능 ##력을 소 ##유 ##하고 있어 ##야 한다. [SEP]\n",
      "I1125 11:12:38.415873 47903194205696 run_squad.py:404] tokens: [CLS] 치 ##과 ##위 ##생 ##사의 자 ##질 ##은 무 ##엇 ##인 ##가 ##? [SEP] 치 ##과 ##위 ##생 ##사는 치 ##과의료 ##기관 ##의 핵 ##심 인 ##적 ##자 ##원으로 구 ##강 ##진 ##료 일 ##선 ##에서 환자를 직접 대 ##면 ##하여 관리 ##하는 업무 ##를 수행 ##한다. 최근 의료 ##소비 ##자는 치료 ##와 회 ##복 ##은 물 ##론 정 ##서 ##적 만족 ##감 ##까지 충 ##족 ##하 ##길 요구 ##한다. 따라서 치 ##과 ##위 ##생 ##사는 수준 높은 의료 ##서비스 ##를 제공 ##하는 기본 업무 외 ##에도 의료 ##소비 ##자의 다양한 상황 ##에 유 ##연 ##하게 대 ##처 ##하며 다양한 사람 ##들의 감 ##성을 조절 ##하여 문제 ##를 복 ##합 ##적으로 해결 ##할 수 있는 감 ##성능 ##력을 소 ##유 ##하고 있어 ##야 한다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 15:0 16:0 17:0 18:0 19:0 20:1 21:1 22:1 23:1 24:2 25:2 26:3 27:3 28:3 29:3 30:4 31:4 32:4 33:4 34:5 35:5 36:5 37:6 38:7 39:8 40:8 41:8 42:9 43:9 44:10 45:10 46:11 47:11 48:12 49:13 50:13 51:13 52:14 53:14 54:15 55:15 56:15 57:16 58:16 59:17 60:17 61:17 62:18 63:18 64:18 65:19 66:19 67:19 68:19 69:20 70:20 71:21 72:22 73:22 74:22 75:22 76:22 77:23 78:24 79:25 80:25 81:25 82:26 83:26 84:27 85:28 86:29 87:29 88:30 89:30 90:30 91:31 92:32 93:32 94:33 95:33 96:33 97:34 98:34 99:34 100:35 101:36 102:36 103:37 104:37 105:38 106:38 107:39 108:39 109:40 110:40 111:40 112:41 113:41 114:42 115:43 116:44 117:44 118:44 119:45 120:45 121:45 122:46 123:46 124:47\n",
      "I1125 11:12:38.415967 47903194205696 run_squad.py:406] token_to_orig_map: 15:0 16:0 17:0 18:0 19:0 20:1 21:1 22:1 23:1 24:2 25:2 26:3 27:3 28:3 29:3 30:4 31:4 32:4 33:4 34:5 35:5 36:5 37:6 38:7 39:8 40:8 41:8 42:9 43:9 44:10 45:10 46:11 47:11 48:12 49:13 50:13 51:13 52:14 53:14 54:15 55:15 56:15 57:16 58:16 59:17 60:17 61:17 62:18 63:18 64:18 65:19 66:19 67:19 68:19 69:20 70:20 71:21 72:22 73:22 74:22 75:22 76:22 77:23 78:24 79:25 80:25 81:25 82:26 83:26 84:27 85:28 86:29 87:29 88:30 89:30 90:30 91:31 92:32 93:32 94:33 95:33 96:33 97:34 98:34 99:34 100:35 101:36 102:36 103:37 104:37 105:38 106:38 107:39 108:39 109:40 110:40 111:40 112:41 113:41 114:42 115:43 116:44 117:44 118:44 119:45 120:45 121:45 122:46 123:46 124:47\n",
      "INFO:tensorflow:token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True\n",
      "I1125 11:12:38.416061 47903194205696 run_squad.py:408] token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True\n",
      "INFO:tensorflow:input_ids: 101 9779 11882 19855 24017 53023 9651 48599 10892 9294 119137 12030 11287 110871 102 9779 11882 19855 24017 64379 9779 121094 119874 10459 9961 71013 9640 14801 13764 78686 8908 47181 18623 38688 9641 18471 11489 120408 67288 9069 14867 13374 119649 12178 119901 11513 119570 119554 119852 119883 120332 53639 119807 12638 9998 70915 10892 9299 42769 9670 12424 14801 119673 105197 18382 9770 52560 35506 118666 119703 119554 52579 9779 11882 19855 24017 64379 119636 55600 119883 120047 11513 119611 12178 119875 119901 9597 35979 119883 120332 42984 53645 119742 10530 9625 25486 17594 9069 60469 22766 53645 119806 25258 8848 36456 120032 13374 119581 11513 9357 33188 17022 119927 14843 9460 13767 8848 120184 33975 9448 42815 12453 45893 21711 119575 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.416218 47903194205696 run_squad.py:410] input_ids: 101 9779 11882 19855 24017 53023 9651 48599 10892 9294 119137 12030 11287 110871 102 9779 11882 19855 24017 64379 9779 121094 119874 10459 9961 71013 9640 14801 13764 78686 8908 47181 18623 38688 9641 18471 11489 120408 67288 9069 14867 13374 119649 12178 119901 11513 119570 119554 119852 119883 120332 53639 119807 12638 9998 70915 10892 9299 42769 9670 12424 14801 119673 105197 18382 9770 52560 35506 118666 119703 119554 52579 9779 11882 19855 24017 64379 119636 55600 119883 120047 11513 119611 12178 119875 119901 9597 35979 119883 120332 42984 53645 119742 10530 9625 25486 17594 9069 60469 22766 53645 119806 25258 8848 36456 120032 13374 119581 11513 9357 33188 17022 119927 14843 9460 13767 8848 120184 33975 9448 42815 12453 45893 21711 119575 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.416370 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.416516 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.417585 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000015\n",
      "I1125 11:12:38.417677 47903194205696 run_squad.py:400] unique_id: 1000000015\n",
      "INFO:tensorflow:example_index: 13\n",
      "I1125 11:12:38.417731 47903194205696 run_squad.py:401] example_index: 13\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.417779 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 웃 ##음 ##요 ##법 ##의 장 ##점 ##은 ##? [SEP] 웃 ##음 ##요 ##법 ##은 다른 중 ##재 ##방안 ##에 비해 특 ##별 ##한 준 ##비 ##가 필요 ##없 ##고, 비용 ##이 들 ##지 않 ##으며, 언 ##제 ##, 어 ##디 ##에서 ##나 사용 가능 ##하고, 고 ##도의 기술 ##이나 교육 ##이 필요 ##하지 않 ##으며, 약 ##간의 훈 ##련 ##만 ##을 통해 사용 가능 ##하다 ##는 장 ##점이 있 ##기 때문에 스트레스 ##에 대한 중 ##재 ##방안 ##으로 떠 ##오 ##르고 있다 ##[ ##7 ##, ##8 ##] ##. [SEP]\n",
      "I1125 11:12:38.417851 47903194205696 run_squad.py:404] tokens: [CLS] 웃 ##음 ##요 ##법 ##의 장 ##점 ##은 ##? [SEP] 웃 ##음 ##요 ##법 ##은 다른 중 ##재 ##방안 ##에 비해 특 ##별 ##한 준 ##비 ##가 필요 ##없 ##고, 비용 ##이 들 ##지 않 ##으며, 언 ##제 ##, 어 ##디 ##에서 ##나 사용 가능 ##하고, 고 ##도의 기술 ##이나 교육 ##이 필요 ##하지 않 ##으며, 약 ##간의 훈 ##련 ##만 ##을 통해 사용 가능 ##하다 ##는 장 ##점이 있 ##기 때문에 스트레스 ##에 대한 중 ##재 ##방안 ##으로 떠 ##오 ##르고 있다 ##[ ##7 ##, ##8 ##] ##. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:0 12:0 13:0 14:0 15:0 16:1 17:2 18:2 19:2 20:2 21:3 22:4 23:4 24:4 25:5 26:5 27:5 28:6 29:6 30:6 31:7 32:7 33:8 34:8 35:9 36:9 37:10 38:10 39:10 40:11 41:11 42:11 43:11 44:12 45:13 46:13 47:14 48:14 49:15 50:15 51:16 52:16 53:17 54:17 55:18 56:18 57:19 58:19 59:20 60:20 61:20 62:20 63:21 64:22 65:23 66:23 67:23 68:24 69:24 70:25 71:25 72:26 73:27 74:27 75:28 76:29 77:29 78:29 79:29 80:30 81:30 82:30 83:31 84:31 85:31 86:31 87:31 88:31 89:31\n",
      "I1125 11:12:38.417940 47903194205696 run_squad.py:406] token_to_orig_map: 11:0 12:0 13:0 14:0 15:0 16:1 17:2 18:2 19:2 20:2 21:3 22:4 23:4 24:4 25:5 26:5 27:5 28:6 29:6 30:6 31:7 32:7 33:8 34:8 35:9 36:9 37:10 38:10 39:10 40:11 41:11 42:11 43:11 44:12 45:13 46:13 47:14 48:14 49:15 50:15 51:16 52:16 53:17 54:17 55:18 56:18 57:19 58:19 59:20 60:20 61:20 62:20 63:21 64:22 65:23 66:23 67:23 68:24 69:24 70:25 71:25 72:26 73:27 74:27 75:28 76:29 77:29 78:29 79:29 80:30 81:30 82:30 83:31 84:31 85:31 86:31 87:31 88:31 89:31\n",
      "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True\n",
      "I1125 11:12:38.418019 47903194205696 run_squad.py:408] token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True\n",
      "INFO:tensorflow:input_ids: 101 9609 32158 48549 33768 10459 9657 34907 10892 110871 102 9609 32158 48549 33768 10892 19709 9694 36210 120208 10530 100876 9891 61844 11102 9691 29455 11287 119629 119136 119563 120104 10739 9117 12508 9523 119579 9548 17730 110862 9546 48446 11489 16439 119550 119609 119604 8888 54469 119578 43739 119583 10739 119629 23665 9523 119579 9539 60454 10004 101440 19105 10622 25605 119550 119609 32679 11018 9657 119928 9647 12310 20729 119985 10530 18154 9694 36210 120208 11467 9138 28188 81220 11506 110873 11305 110862 11396 110875 110864 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.418167 47903194205696 run_squad.py:410] input_ids: 101 9609 32158 48549 33768 10459 9657 34907 10892 110871 102 9609 32158 48549 33768 10892 19709 9694 36210 120208 10530 100876 9891 61844 11102 9691 29455 11287 119629 119136 119563 120104 10739 9117 12508 9523 119579 9548 17730 110862 9546 48446 11489 16439 119550 119609 119604 8888 54469 119578 43739 119583 10739 119629 23665 9523 119579 9539 60454 10004 101440 19105 10622 25605 119550 119609 32679 11018 9657 119928 9647 12310 20729 119985 10530 18154 9694 36210 120208 11467 9138 28188 81220 11506 110873 11305 110862 11396 110875 110864 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.418317 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.418462 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.423951 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000016\n",
      "I1125 11:12:38.424042 47903194205696 run_squad.py:400] unique_id: 1000000016\n",
      "INFO:tensorflow:example_index: 14\n",
      "I1125 11:12:38.424104 47903194205696 run_squad.py:401] example_index: 14\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.424161 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 곡 ##관 ##내 ##의 유 ##동 ##해석 ##은 어떤 산업 분야 ##에서 응 ##용이 가능한 ##가 ##? [SEP] 곡 ##관 ##내 ##의 유 ##동 ##해석 ##은 유 ##체 ##기 ##계 ##( ##원 ##심 ##압 ##축 ##기 ##, 원 ##심 ##펌 ##프 ##, 터 ##빈 ##장 ##치 등 ##)의 유 ##로 ##, 열 ##교 ##환 ##기의 냉 ##각 ##코 ##일 ##, 발전기의 내부 ##냉 ##각 ##통 ##로 ##, 공 ##장 내 ##의 파 ##이 ##프 ##시스템 등과 같은 다양한 산업 ##분야 ##에 응 ##용이 가능 ##하면서 많은 연구가 이루어 ##지고 있다 ##[ ##1 ##] ##, ##[ ##2 ##] ##. 연구 ##동 ##향 ##으로서 Sohn 등 ##[ ##3 ##] ##, ##[ ##4 ##] ##는 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 ##에 연결 ##된 직 ##관 ##덕 ##트 ##의 출 ##구 ##영역 ##에서 발 ##달 ##되는 층 ##류 ##정 ##상 ##유 ##동 ##에 대해 P ##IV 실험 ##과 CF ##D ##해석 ##을 통하여 축 ##방향 ##속 ##도 ##분포 및 2 ##차 ##유 ##동 ##에 대한 유 ##동 ##특성을 고 ##찰 ##하였으며, Park 등 ##[ ##5 ##] ##는 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 ##덕 ##트 ##의 입 ##구 ##영역 ##에서 L ##D ##V ##시스템 ##을 이용하여 곡 ##관 ##에서 실험 적 ##으로 규 ##명 ##하기 위해 천 ##이유 ##동 ##의 축 ##방향 속 ##도 ##분포 ##와 2 ##차 ##원 ##유 ##동 등을 계 ##측 ##하여 유 ##체 ##역 ##학적 길 ##이를 잘 제시 ##하였으며, Bon ##g ##과 Cho ##[ ##6 ##] ##은 정 ##방 ##형 180 곡 ##관 ##내 ##에서 공 ##기 ##유 ##동 ##특성이 원 ##심 ##력 ##에 미치는 영향을 실험 및 해석 ##적으로 고 ##찰 ##하여 축 ##방향 ##속 ##도 ##분포 ##는 원 ##심 ##력 ##에 큰 영향을 받 ##으며 곡 ##관 180 근 ##방 ##에서 좌 ##우 ##대 ##칭 ##의 속 ##보 ##분포 ##를 보였다. 그리고 Lim ##과 Yoo ##[ ##7 ##] ##은 정 ##사 ##각 ##형 덕 ##트 ##의 출 ##구 ##영역 ##에서 속 ##도 ##분포 ##에 대한 유 ##동 ##특성을 고 ##찰 ##하기 위해 실험 ##결과 ##와 비교 ##한 결과 ##로 RN ##G k ##- 모델 ##이 표준 k ##- 모델 ##보다 좋은 결과를 나타 ##냈 ##으며, Yang ##과 Choi ##[ ##8 ##] ##은 정 ##사 ##각 ##형 ##단 ##면 ##을 갖는 180 곡 ##관 ##내 ##의 열 ##전 ##달 ##해석 ##을 위하여 난 ##류 열 ##유 ##속 ##의 모형 ##을 적용 ##하여 Nu ##ssel ##t ##수 및 무 ##차 ##원 ##온 ##도의 특성을 Johnson ##[ ##9 ##] ##의 실험 ##결과 ##와 비교 ##하여 수 ##치 ##해석 ##의 예측 ##을 보였다. Lee 등 ##[ ##10 ##] ##은 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 덕 ##트 ##로 구성 ##된 덕 ##트 ##입 ##구 ##영역 ##에서 L ##D ##V ##를 이용하여 축 ##방향 및 횡 ##방향 ##의 위치 ##변화 ##에 따른 축 ##방향 ##의 속 ##도 ##분포 ##와 유 ##동 ##특성을 고 ##찰 ##하였고, Bon ##g ##과 Cho ##[ ##11 ##] ##은 정 ##방 ##형 180 곡 ##관 ##덕 ##트 ##내 ##에서 공 ##기 ##유 ##동 ##특성이 원 ##심 ##력 ##에 미치는 영향을 실험 ##적으로 규 ##명 ##하기 위해 L ##D [SEP]\n",
      "I1125 11:12:38.424337 47903194205696 run_squad.py:404] tokens: [CLS] 곡 ##관 ##내 ##의 유 ##동 ##해석 ##은 어떤 산업 분야 ##에서 응 ##용이 가능한 ##가 ##? [SEP] 곡 ##관 ##내 ##의 유 ##동 ##해석 ##은 유 ##체 ##기 ##계 ##( ##원 ##심 ##압 ##축 ##기 ##, 원 ##심 ##펌 ##프 ##, 터 ##빈 ##장 ##치 등 ##)의 유 ##로 ##, 열 ##교 ##환 ##기의 냉 ##각 ##코 ##일 ##, 발전기의 내부 ##냉 ##각 ##통 ##로 ##, 공 ##장 내 ##의 파 ##이 ##프 ##시스템 등과 같은 다양한 산업 ##분야 ##에 응 ##용이 가능 ##하면서 많은 연구가 이루어 ##지고 있다 ##[ ##1 ##] ##, ##[ ##2 ##] ##. 연구 ##동 ##향 ##으로서 Sohn 등 ##[ ##3 ##] ##, ##[ ##4 ##] ##는 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 ##에 연결 ##된 직 ##관 ##덕 ##트 ##의 출 ##구 ##영역 ##에서 발 ##달 ##되는 층 ##류 ##정 ##상 ##유 ##동 ##에 대해 P ##IV 실험 ##과 CF ##D ##해석 ##을 통하여 축 ##방향 ##속 ##도 ##분포 및 2 ##차 ##유 ##동 ##에 대한 유 ##동 ##특성을 고 ##찰 ##하였으며, Park 등 ##[ ##5 ##] ##는 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 ##덕 ##트 ##의 입 ##구 ##영역 ##에서 L ##D ##V ##시스템 ##을 이용하여 곡 ##관 ##에서 실험 적 ##으로 규 ##명 ##하기 위해 천 ##이유 ##동 ##의 축 ##방향 속 ##도 ##분포 ##와 2 ##차 ##원 ##유 ##동 등을 계 ##측 ##하여 유 ##체 ##역 ##학적 길 ##이를 잘 제시 ##하였으며, Bon ##g ##과 Cho ##[ ##6 ##] ##은 정 ##방 ##형 180 곡 ##관 ##내 ##에서 공 ##기 ##유 ##동 ##특성이 원 ##심 ##력 ##에 미치는 영향을 실험 및 해석 ##적으로 고 ##찰 ##하여 축 ##방향 ##속 ##도 ##분포 ##는 원 ##심 ##력 ##에 큰 영향을 받 ##으며 곡 ##관 180 근 ##방 ##에서 좌 ##우 ##대 ##칭 ##의 속 ##보 ##분포 ##를 보였다. 그리고 Lim ##과 Yoo ##[ ##7 ##] ##은 정 ##사 ##각 ##형 덕 ##트 ##의 출 ##구 ##영역 ##에서 속 ##도 ##분포 ##에 대한 유 ##동 ##특성을 고 ##찰 ##하기 위해 실험 ##결과 ##와 비교 ##한 결과 ##로 RN ##G k ##- 모델 ##이 표준 k ##- 모델 ##보다 좋은 결과를 나타 ##냈 ##으며, Yang ##과 Choi ##[ ##8 ##] ##은 정 ##사 ##각 ##형 ##단 ##면 ##을 갖는 180 곡 ##관 ##내 ##의 열 ##전 ##달 ##해석 ##을 위하여 난 ##류 열 ##유 ##속 ##의 모형 ##을 적용 ##하여 Nu ##ssel ##t ##수 및 무 ##차 ##원 ##온 ##도의 특성을 Johnson ##[ ##9 ##] ##의 실험 ##결과 ##와 비교 ##하여 수 ##치 ##해석 ##의 예측 ##을 보였다. Lee 등 ##[ ##10 ##] ##은 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 덕 ##트 ##로 구성 ##된 덕 ##트 ##입 ##구 ##영역 ##에서 L ##D ##V ##를 이용하여 축 ##방향 및 횡 ##방향 ##의 위치 ##변화 ##에 따른 축 ##방향 ##의 속 ##도 ##분포 ##와 유 ##동 ##특성을 고 ##찰 ##하였고, Bon ##g ##과 Cho ##[ ##11 ##] ##은 정 ##방 ##형 180 곡 ##관 ##덕 ##트 ##내 ##에서 공 ##기 ##유 ##동 ##특성이 원 ##심 ##력 ##에 미치는 영향을 실험 ##적으로 규 ##명 ##하기 위해 L ##D [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 19:0 20:0 21:0 22:0 23:1 24:1 25:1 26:1 27:2 28:2 29:2 30:2 31:2 32:2 33:2 34:2 35:2 36:2 37:2 38:3 39:3 40:3 41:3 42:3 43:4 44:4 45:4 46:4 47:5 48:5 49:6 50:6 51:6 52:7 53:7 54:7 55:7 56:8 57:8 58:8 59:8 60:8 61:9 62:10 63:10 64:10 65:10 66:10 67:10 68:11 69:11 70:12 71:12 72:13 73:13 74:13 75:13 76:14 77:15 78:16 79:17 80:17 81:17 82:18 83:18 84:19 85:19 86:20 87:21 88:22 89:22 90:23 91:23 92:23 93:23 94:23 95:23 96:23 97:23 98:23 99:24 100:24 101:24 102:24 103:25 104:26 105:26 106:26 107:26 108:26 109:26 110:26 111:26 112:26 113:27 114:27 115:27 116:27 117:28 118:28 119:29 120:30 121:30 122:30 123:31 124:31 125:32 126:32 127:32 128:32 129:32 130:33 131:33 132:33 133:33 134:34 135:34 136:34 137:35 138:35 139:35 140:35 141:35 142:35 143:35 144:36 145:37 146:37 147:38 148:38 149:39 150:39 151:39 152:39 153:40 154:41 155:41 156:41 157:41 158:41 159:42 160:43 161:43 162:43 163:43 164:43 165:44 166:45 167:45 168:45 169:46 170:46 171:46 172:47 173:48 174:48 175:48 176:48 177:48 178:49 179:49 180:49 181:49 182:50 183:50 184:51 185:52 186:52 187:52 188:52 189:52 190:53 191:53 192:53 193:53 194:54 195:54 196:54 197:54 198:54 199:55 200:56 201:56 202:56 203:57 204:58 205:58 206:59 207:59 208:59 209:60 210:61 211:61 212:61 213:61 214:62 215:62 216:63 217:63 218:63 219:63 220:64 221:64 222:64 223:64 224:64 225:65 226:66 227:66 228:66 229:67 230:67 231:67 232:67 233:68 234:68 235:69 236:70 237:70 238:71 239:71 240:71 241:72 242:72 243:72 244:72 245:72 246:73 247:73 248:73 249:74 250:75 251:75 252:75 253:75 254:76 255:76 256:76 257:76 258:76 259:77 260:77 261:77 262:77 263:78 264:79 265:80 266:81 267:82 268:82 269:83 270:83 271:83 272:84 273:84 274:84 275:84 276:84 277:84 278:85 279:85 280:85 281:85 282:86 283:87 284:88 285:88 286:89 287:89 288:90 289:91 290:91 291:91 292:92 293:92 294:92 295:92 296:92 297:93 298:93 299:93 300:93 301:94 302:95 303:96 304:96 305:97 306:97 307:97 308:97 309:97 310:98 311:98 312:98 313:98 314:99 315:99 316:99 317:100 318:100 319:100 320:100 321:101 322:101 323:101 324:101 325:102 326:103 327:103 328:103 329:104 330:104 331:104 332:105 333:106 334:106 335:106 336:107 337:107 338:108 339:108 340:109 341:109 342:110 343:110 344:111 345:111 346:112 347:113 348:113 349:114 350:114 351:115 352:116 353:117 354:117 355:117 356:118 357:118 358:119 359:119 360:119 361:119 362:119 363:120 364:120 365:120 366:120 367:120 368:120 369:120 370:121 371:122 372:123 373:123 374:123 375:123 376:124 377:124 378:124 379:124 380:124 381:125 382:126 383:126 384:127 385:127 386:127 387:127 388:128 389:128 390:129 391:129 392:130 393:130 394:130 395:130 396:131 397:132 398:132 399:132 400:132 401:132 402:133 403:134 404:134 405:134 406:134 407:134 408:135 409:135 410:135 411:136 412:136 413:137 414:137 415:137 416:137 417:138 418:138 419:139 420:140 421:141 422:141 423:141 424:141 425:141 426:142 427:142 428:142 429:142 430:143 431:143 432:144 433:145 434:145 435:146 436:146 437:146 438:147 439:147 440:148 441:148 442:148 443:148 444:148 445:148 446:149 447:149 448:149 449:149 450:150 451:151 452:151 453:152 454:153 455:153 456:153 457:154 458:154 459:154 460:155 461:156 462:156 463:156 464:157 465:157 466:157 467:157 468:158 469:158 470:158 471:159 472:159 473:159 474:160 475:160 476:160 477:161 478:161 479:161 480:161 481:161 482:162 483:162 484:162 485:163 486:164 487:164 488:164 489:164 490:164 491:164 492:165 493:165 494:165 495:165 496:165 497:166 498:166 499:166 500:166 501:167 502:168 503:169 504:169 505:170 506:170 507:170 508:171 509:172 510:172\n",
      "I1125 11:12:38.424569 47903194205696 run_squad.py:406] token_to_orig_map: 19:0 20:0 21:0 22:0 23:1 24:1 25:1 26:1 27:2 28:2 29:2 30:2 31:2 32:2 33:2 34:2 35:2 36:2 37:2 38:3 39:3 40:3 41:3 42:3 43:4 44:4 45:4 46:4 47:5 48:5 49:6 50:6 51:6 52:7 53:7 54:7 55:7 56:8 57:8 58:8 59:8 60:8 61:9 62:10 63:10 64:10 65:10 66:10 67:10 68:11 69:11 70:12 71:12 72:13 73:13 74:13 75:13 76:14 77:15 78:16 79:17 80:17 81:17 82:18 83:18 84:19 85:19 86:20 87:21 88:22 89:22 90:23 91:23 92:23 93:23 94:23 95:23 96:23 97:23 98:23 99:24 100:24 101:24 102:24 103:25 104:26 105:26 106:26 107:26 108:26 109:26 110:26 111:26 112:26 113:27 114:27 115:27 116:27 117:28 118:28 119:29 120:30 121:30 122:30 123:31 124:31 125:32 126:32 127:32 128:32 129:32 130:33 131:33 132:33 133:33 134:34 135:34 136:34 137:35 138:35 139:35 140:35 141:35 142:35 143:35 144:36 145:37 146:37 147:38 148:38 149:39 150:39 151:39 152:39 153:40 154:41 155:41 156:41 157:41 158:41 159:42 160:43 161:43 162:43 163:43 164:43 165:44 166:45 167:45 168:45 169:46 170:46 171:46 172:47 173:48 174:48 175:48 176:48 177:48 178:49 179:49 180:49 181:49 182:50 183:50 184:51 185:52 186:52 187:52 188:52 189:52 190:53 191:53 192:53 193:53 194:54 195:54 196:54 197:54 198:54 199:55 200:56 201:56 202:56 203:57 204:58 205:58 206:59 207:59 208:59 209:60 210:61 211:61 212:61 213:61 214:62 215:62 216:63 217:63 218:63 219:63 220:64 221:64 222:64 223:64 224:64 225:65 226:66 227:66 228:66 229:67 230:67 231:67 232:67 233:68 234:68 235:69 236:70 237:70 238:71 239:71 240:71 241:72 242:72 243:72 244:72 245:72 246:73 247:73 248:73 249:74 250:75 251:75 252:75 253:75 254:76 255:76 256:76 257:76 258:76 259:77 260:77 261:77 262:77 263:78 264:79 265:80 266:81 267:82 268:82 269:83 270:83 271:83 272:84 273:84 274:84 275:84 276:84 277:84 278:85 279:85 280:85 281:85 282:86 283:87 284:88 285:88 286:89 287:89 288:90 289:91 290:91 291:91 292:92 293:92 294:92 295:92 296:92 297:93 298:93 299:93 300:93 301:94 302:95 303:96 304:96 305:97 306:97 307:97 308:97 309:97 310:98 311:98 312:98 313:98 314:99 315:99 316:99 317:100 318:100 319:100 320:100 321:101 322:101 323:101 324:101 325:102 326:103 327:103 328:103 329:104 330:104 331:104 332:105 333:106 334:106 335:106 336:107 337:107 338:108 339:108 340:109 341:109 342:110 343:110 344:111 345:111 346:112 347:113 348:113 349:114 350:114 351:115 352:116 353:117 354:117 355:117 356:118 357:118 358:119 359:119 360:119 361:119 362:119 363:120 364:120 365:120 366:120 367:120 368:120 369:120 370:121 371:122 372:123 373:123 374:123 375:123 376:124 377:124 378:124 379:124 380:124 381:125 382:126 383:126 384:127 385:127 386:127 387:127 388:128 389:128 390:129 391:129 392:130 393:130 394:130 395:130 396:131 397:132 398:132 399:132 400:132 401:132 402:133 403:134 404:134 405:134 406:134 407:134 408:135 409:135 410:135 411:136 412:136 413:137 414:137 415:137 416:137 417:138 418:138 419:139 420:140 421:141 422:141 423:141 424:141 425:141 426:142 427:142 428:142 429:142 430:143 431:143 432:144 433:145 434:145 435:146 436:146 437:146 438:147 439:147 440:148 441:148 442:148 443:148 444:148 445:148 446:149 447:149 448:149 449:149 450:150 451:151 452:151 453:152 454:153 455:153 456:153 457:154 458:154 459:154 460:155 461:156 462:156 463:156 464:157 465:157 466:157 467:157 468:158 469:158 470:158 471:159 472:159 473:159 474:160 475:160 476:160 477:161 478:161 479:161 480:161 481:161 482:162 483:162 484:162 485:163 486:164 487:164 488:164 489:164 490:164 491:164 492:165 493:165 494:165 495:165 496:165 497:166 498:166 499:166 500:166 501:167 502:168 503:169 504:169 505:170 506:170 507:170 508:171 509:172 510:172\n",
      "INFO:tensorflow:token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "I1125 11:12:38.424775 47903194205696 run_squad.py:408] token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "INFO:tensorflow:input_ids: 101 8889 20595 31605 10459 9625 18778 120120 10892 55910 119787 119820 11489 9636 96404 120015 11287 110871 102 8889 20595 31605 10459 9625 18778 120120 10892 9625 29683 12310 21611 110858 14279 71013 119116 70122 12310 110862 9612 71013 119389 28396 110862 9861 102360 13890 18622 9121 119592 9625 11261 110862 9569 25242 51745 46874 9001 66540 25517 18392 110862 121086 119856 118727 66540 43022 11261 110862 8896 13890 8996 10459 9901 10739 28396 119821 105464 18589 53645 119787 120165 10530 9636 96404 119609 37341 25685 119778 119645 68833 11506 110873 10759 110875 110862 110873 10729 110875 110864 91785 18778 79544 120024 14870 9121 110873 10884 110875 110862 110873 11011 110875 11018 9670 12945 66540 27506 9059 14867 13912 8889 20595 10530 119830 13441 9707 20595 118782 15184 10459 9768 17196 120118 11489 9323 89851 24683 9778 46520 16605 14871 42815 18778 10530 33378 153 91238 119569 11882 29551 11490 120120 10622 119834 9766 119996 43962 12092 120150 9316 123 23466 42815 18778 10530 18154 9625 18778 120305 8888 99118 119654 11239 9121 110873 11166 110875 11018 9670 12945 66540 27506 9059 14867 13912 8889 20595 118782 15184 10459 9645 17196 120118 11489 149 11490 11779 119821 10622 119593 8889 20595 11489 119569 9664 11467 8922 16758 22440 19905 9746 121040 18778 10459 9766 119996 9449 12092 120150 12638 123 23466 14279 42815 18778 33727 8887 119281 13374 9625 29683 23160 87503 8934 66623 9654 119591 119654 30120 10240 11882 50690 110873 11211 110875 10892 9670 42337 27506 13912 8889 20595 31605 11489 8896 12310 42815 18778 120682 9612 71013 28143 10530 119610 58088 119569 9316 119700 17022 8888 99118 13374 9766 119996 43962 12092 120150 11018 9612 71013 28143 10530 9835 58088 9322 24098 8889 20595 13912 8926 42337 11489 9686 27355 14423 52094 10459 9449 30005 120150 11513 119978 23289 64200 11882 89009 110873 11305 110875 10892 9670 12945 66540 27506 9075 15184 10459 9768 17196 120118 11489 9449 12092 120150 10530 18154 9625 18778 120305 8888 99118 22440 19905 119569 119712 12638 119572 11102 85533 11261 71327 11447 179 110863 119615 10739 119727 179 110863 119615 80001 79633 119639 119965 118726 119579 18837 11882 52651 110873 11396 110875 10892 9670 12945 66540 27506 24989 14867 10622 120021 13912 8889 20595 31605 10459 9569 16617 89851 120120 10622 68010 8984 46520 9569 42815 43962 10459 119736 10622 119564 13374 28336 49235 10123 15891 9316 9294 23466 14279 37093 54469 119772 13241 110873 11373 110875 10459 119569 119712 12638 119572 13374 9460 18622 120120 10459 119759 10622 119978 12006 9121 110873 20305 110875 10892 9670 12945 66540 27506 9059 14867 13912 8889 20595 9075 15184 11261 119571 13441 9075 15184 58303 17196 120118 11489 149 11490 11779 11513 119593 9766 119996 9316 10001 119996 10459 119656 120121 10530 110463 9766 119996 10459 9449 12092 120150 12638 9625 18778 120305 8888 99118 119773 30120 10240 11882 50690 110873 37115 110875 10892 9670 42337 27506 13912 8889 20595 118782 15184 31605 11489 8896 12310 42815 18778 120682 9612 71013 28143 10530 119610 58088 119569 17022 8922 16758 22440 19905 149 11490 102\n",
      "I1125 11:12:38.426115 47903194205696 run_squad.py:410] input_ids: 101 8889 20595 31605 10459 9625 18778 120120 10892 55910 119787 119820 11489 9636 96404 120015 11287 110871 102 8889 20595 31605 10459 9625 18778 120120 10892 9625 29683 12310 21611 110858 14279 71013 119116 70122 12310 110862 9612 71013 119389 28396 110862 9861 102360 13890 18622 9121 119592 9625 11261 110862 9569 25242 51745 46874 9001 66540 25517 18392 110862 121086 119856 118727 66540 43022 11261 110862 8896 13890 8996 10459 9901 10739 28396 119821 105464 18589 53645 119787 120165 10530 9636 96404 119609 37341 25685 119778 119645 68833 11506 110873 10759 110875 110862 110873 10729 110875 110864 91785 18778 79544 120024 14870 9121 110873 10884 110875 110862 110873 11011 110875 11018 9670 12945 66540 27506 9059 14867 13912 8889 20595 10530 119830 13441 9707 20595 118782 15184 10459 9768 17196 120118 11489 9323 89851 24683 9778 46520 16605 14871 42815 18778 10530 33378 153 91238 119569 11882 29551 11490 120120 10622 119834 9766 119996 43962 12092 120150 9316 123 23466 42815 18778 10530 18154 9625 18778 120305 8888 99118 119654 11239 9121 110873 11166 110875 11018 9670 12945 66540 27506 9059 14867 13912 8889 20595 118782 15184 10459 9645 17196 120118 11489 149 11490 11779 119821 10622 119593 8889 20595 11489 119569 9664 11467 8922 16758 22440 19905 9746 121040 18778 10459 9766 119996 9449 12092 120150 12638 123 23466 14279 42815 18778 33727 8887 119281 13374 9625 29683 23160 87503 8934 66623 9654 119591 119654 30120 10240 11882 50690 110873 11211 110875 10892 9670 42337 27506 13912 8889 20595 31605 11489 8896 12310 42815 18778 120682 9612 71013 28143 10530 119610 58088 119569 9316 119700 17022 8888 99118 13374 9766 119996 43962 12092 120150 11018 9612 71013 28143 10530 9835 58088 9322 24098 8889 20595 13912 8926 42337 11489 9686 27355 14423 52094 10459 9449 30005 120150 11513 119978 23289 64200 11882 89009 110873 11305 110875 10892 9670 12945 66540 27506 9075 15184 10459 9768 17196 120118 11489 9449 12092 120150 10530 18154 9625 18778 120305 8888 99118 22440 19905 119569 119712 12638 119572 11102 85533 11261 71327 11447 179 110863 119615 10739 119727 179 110863 119615 80001 79633 119639 119965 118726 119579 18837 11882 52651 110873 11396 110875 10892 9670 12945 66540 27506 24989 14867 10622 120021 13912 8889 20595 31605 10459 9569 16617 89851 120120 10622 68010 8984 46520 9569 42815 43962 10459 119736 10622 119564 13374 28336 49235 10123 15891 9316 9294 23466 14279 37093 54469 119772 13241 110873 11373 110875 10459 119569 119712 12638 119572 13374 9460 18622 120120 10459 119759 10622 119978 12006 9121 110873 20305 110875 10892 9670 12945 66540 27506 9059 14867 13912 8889 20595 9075 15184 11261 119571 13441 9075 15184 58303 17196 120118 11489 149 11490 11779 11513 119593 9766 119996 9316 10001 119996 10459 119656 120121 10530 110463 9766 119996 10459 9449 12092 120150 12638 9625 18778 120305 8888 99118 119773 30120 10240 11882 50690 110873 37115 110875 10892 9670 42337 27506 13912 8889 20595 118782 15184 31605 11489 8896 12310 42815 18778 120682 9612 71013 28143 10530 119610 58088 119569 17022 8922 16758 22440 19905 149 11490 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.426282 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.426429 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.428331 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000017\n",
      "I1125 11:12:38.428416 47903194205696 run_squad.py:400] unique_id: 1000000017\n",
      "INFO:tensorflow:example_index: 14\n",
      "I1125 11:12:38.428474 47903194205696 run_squad.py:401] example_index: 14\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "I1125 11:12:38.428522 47903194205696 run_squad.py:402] doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] 곡 ##관 ##내 ##의 유 ##동 ##해석 ##은 어떤 산업 분야 ##에서 응 ##용이 가능한 ##가 ##? [SEP] 실험 ##과 CF ##D ##해석 ##을 통하여 축 ##방향 ##속 ##도 ##분포 및 2 ##차 ##유 ##동 ##에 대한 유 ##동 ##특성을 고 ##찰 ##하였으며, Park 등 ##[ ##5 ##] ##는 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 ##덕 ##트 ##의 입 ##구 ##영역 ##에서 L ##D ##V ##시스템 ##을 이용하여 곡 ##관 ##에서 실험 적 ##으로 규 ##명 ##하기 위해 천 ##이유 ##동 ##의 축 ##방향 속 ##도 ##분포 ##와 2 ##차 ##원 ##유 ##동 등을 계 ##측 ##하여 유 ##체 ##역 ##학적 길 ##이를 잘 제시 ##하였으며, Bon ##g ##과 Cho ##[ ##6 ##] ##은 정 ##방 ##형 180 곡 ##관 ##내 ##에서 공 ##기 ##유 ##동 ##특성이 원 ##심 ##력 ##에 미치는 영향을 실험 및 해석 ##적으로 고 ##찰 ##하여 축 ##방향 ##속 ##도 ##분포 ##는 원 ##심 ##력 ##에 큰 영향을 받 ##으며 곡 ##관 180 근 ##방 ##에서 좌 ##우 ##대 ##칭 ##의 속 ##보 ##분포 ##를 보였다. 그리고 Lim ##과 Yoo ##[ ##7 ##] ##은 정 ##사 ##각 ##형 덕 ##트 ##의 출 ##구 ##영역 ##에서 속 ##도 ##분포 ##에 대한 유 ##동 ##특성을 고 ##찰 ##하기 위해 실험 ##결과 ##와 비교 ##한 결과 ##로 RN ##G k ##- 모델 ##이 표준 k ##- 모델 ##보다 좋은 결과를 나타 ##냈 ##으며, Yang ##과 Choi ##[ ##8 ##] ##은 정 ##사 ##각 ##형 ##단 ##면 ##을 갖는 180 곡 ##관 ##내 ##의 열 ##전 ##달 ##해석 ##을 위하여 난 ##류 열 ##유 ##속 ##의 모형 ##을 적용 ##하여 Nu ##ssel ##t ##수 및 무 ##차 ##원 ##온 ##도의 특성을 Johnson ##[ ##9 ##] ##의 실험 ##결과 ##와 비교 ##하여 수 ##치 ##해석 ##의 예측 ##을 보였다. Lee 등 ##[ ##10 ##] ##은 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 덕 ##트 ##로 구성 ##된 덕 ##트 ##입 ##구 ##영역 ##에서 L ##D ##V ##를 이용하여 축 ##방향 및 횡 ##방향 ##의 위치 ##변화 ##에 따른 축 ##방향 ##의 속 ##도 ##분포 ##와 유 ##동 ##특성을 고 ##찰 ##하였고, Bon ##g ##과 Cho ##[ ##11 ##] ##은 정 ##방 ##형 180 곡 ##관 ##덕 ##트 ##내 ##에서 공 ##기 ##유 ##동 ##특성이 원 ##심 ##력 ##에 미치는 영향을 실험 ##적으로 규 ##명 ##하기 위해 L ##D ##V ##로 계 ##측 ##하여 FL ##UE ##NT 수 ##치 ##해석 ##과 비교 ##한 결과 ##로 축 ##방향 ##속 ##도 ##분포 ##는 원 ##심 ##력 ##의 영향을 받 ##음을 보여 ##주 ##었다. 또한 Rudolf ##와 Des ##ova ##[ ##12 ##] ##는 여러 형태 ##의 곡 ##관 ##을 모델 ##링 ##하여 레 ##이 ##놀 ##즈 수 ##를 60 ##, ##000 ##으로 동일 ##하게 적용 ##한 후 속 ##도 ##분포 ##, 와 ##류 및 수 ##력 ##손 ##실 발생 등의 현 ##상을 수 ##치 ##해석 ##적으로 고 ##찰 ##하여 완전히 발 ##달 ##된 난 ##류 ##영역 ##은 곡 ##관 ##후 ##류 ##로부터 직 ##관 ##거 ##리는 40 ##배 이상 ##이 필요 ##하다 ##고 하였 ##고, Carla ##nder ##와 Dels ##ing ##[ ##13 ##] 은 엘 ##보 1 ##개 ##와 다른 [SEP]\n",
      "I1125 11:12:38.428700 47903194205696 run_squad.py:404] tokens: [CLS] 곡 ##관 ##내 ##의 유 ##동 ##해석 ##은 어떤 산업 분야 ##에서 응 ##용이 가능한 ##가 ##? [SEP] 실험 ##과 CF ##D ##해석 ##을 통하여 축 ##방향 ##속 ##도 ##분포 및 2 ##차 ##유 ##동 ##에 대한 유 ##동 ##특성을 고 ##찰 ##하였으며, Park 등 ##[ ##5 ##] ##는 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 ##덕 ##트 ##의 입 ##구 ##영역 ##에서 L ##D ##V ##시스템 ##을 이용하여 곡 ##관 ##에서 실험 적 ##으로 규 ##명 ##하기 위해 천 ##이유 ##동 ##의 축 ##방향 속 ##도 ##분포 ##와 2 ##차 ##원 ##유 ##동 등을 계 ##측 ##하여 유 ##체 ##역 ##학적 길 ##이를 잘 제시 ##하였으며, Bon ##g ##과 Cho ##[ ##6 ##] ##은 정 ##방 ##형 180 곡 ##관 ##내 ##에서 공 ##기 ##유 ##동 ##특성이 원 ##심 ##력 ##에 미치는 영향을 실험 및 해석 ##적으로 고 ##찰 ##하여 축 ##방향 ##속 ##도 ##분포 ##는 원 ##심 ##력 ##에 큰 영향을 받 ##으며 곡 ##관 180 근 ##방 ##에서 좌 ##우 ##대 ##칭 ##의 속 ##보 ##분포 ##를 보였다. 그리고 Lim ##과 Yoo ##[ ##7 ##] ##은 정 ##사 ##각 ##형 덕 ##트 ##의 출 ##구 ##영역 ##에서 속 ##도 ##분포 ##에 대한 유 ##동 ##특성을 고 ##찰 ##하기 위해 실험 ##결과 ##와 비교 ##한 결과 ##로 RN ##G k ##- 모델 ##이 표준 k ##- 모델 ##보다 좋은 결과를 나타 ##냈 ##으며, Yang ##과 Choi ##[ ##8 ##] ##은 정 ##사 ##각 ##형 ##단 ##면 ##을 갖는 180 곡 ##관 ##내 ##의 열 ##전 ##달 ##해석 ##을 위하여 난 ##류 열 ##유 ##속 ##의 모형 ##을 적용 ##하여 Nu ##ssel ##t ##수 및 무 ##차 ##원 ##온 ##도의 특성을 Johnson ##[ ##9 ##] ##의 실험 ##결과 ##와 비교 ##하여 수 ##치 ##해석 ##의 예측 ##을 보였다. Lee 등 ##[ ##10 ##] ##은 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 덕 ##트 ##로 구성 ##된 덕 ##트 ##입 ##구 ##영역 ##에서 L ##D ##V ##를 이용하여 축 ##방향 및 횡 ##방향 ##의 위치 ##변화 ##에 따른 축 ##방향 ##의 속 ##도 ##분포 ##와 유 ##동 ##특성을 고 ##찰 ##하였고, Bon ##g ##과 Cho ##[ ##11 ##] ##은 정 ##방 ##형 180 곡 ##관 ##덕 ##트 ##내 ##에서 공 ##기 ##유 ##동 ##특성이 원 ##심 ##력 ##에 미치는 영향을 실험 ##적으로 규 ##명 ##하기 위해 L ##D ##V ##로 계 ##측 ##하여 FL ##UE ##NT 수 ##치 ##해석 ##과 비교 ##한 결과 ##로 축 ##방향 ##속 ##도 ##분포 ##는 원 ##심 ##력 ##의 영향을 받 ##음을 보여 ##주 ##었다. 또한 Rudolf ##와 Des ##ova ##[ ##12 ##] ##는 여러 형태 ##의 곡 ##관 ##을 모델 ##링 ##하여 레 ##이 ##놀 ##즈 수 ##를 60 ##, ##000 ##으로 동일 ##하게 적용 ##한 후 속 ##도 ##분포 ##, 와 ##류 및 수 ##력 ##손 ##실 발생 등의 현 ##상을 수 ##치 ##해석 ##적으로 고 ##찰 ##하여 완전히 발 ##달 ##된 난 ##류 ##영역 ##은 곡 ##관 ##후 ##류 ##로부터 직 ##관 ##거 ##리는 40 ##배 이상 ##이 필요 ##하다 ##고 하였 ##고, Carla ##nder ##와 Dels ##ing ##[ ##13 ##] 은 엘 ##보 1 ##개 ##와 다른 [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 19:38 20:38 21:39 22:39 23:39 24:39 25:40 26:41 27:41 28:41 29:41 30:41 31:42 32:43 33:43 34:43 35:43 36:43 37:44 38:45 39:45 40:45 41:46 42:46 43:46 44:47 45:48 46:48 47:48 48:48 49:48 50:49 51:49 52:49 53:49 54:50 55:50 56:51 57:52 58:52 59:52 60:52 61:52 62:53 63:53 64:53 65:53 66:54 67:54 68:54 69:54 70:54 71:55 72:56 73:56 74:56 75:57 76:58 77:58 78:59 79:59 80:59 81:60 82:61 83:61 84:61 85:61 86:62 87:62 88:63 89:63 90:63 91:63 92:64 93:64 94:64 95:64 96:64 97:65 98:66 99:66 100:66 101:67 102:67 103:67 104:67 105:68 106:68 107:69 108:70 109:70 110:71 111:71 112:71 113:72 114:72 115:72 116:72 117:72 118:73 119:73 120:73 121:74 122:75 123:75 124:75 125:75 126:76 127:76 128:76 129:76 130:76 131:77 132:77 133:77 134:77 135:78 136:79 137:80 138:81 139:82 140:82 141:83 142:83 143:83 144:84 145:84 146:84 147:84 148:84 149:84 150:85 151:85 152:85 153:85 154:86 155:87 156:88 157:88 158:89 159:89 160:90 161:91 162:91 163:91 164:92 165:92 166:92 167:92 168:92 169:93 170:93 171:93 172:93 173:94 174:95 175:96 176:96 177:97 178:97 179:97 180:97 181:97 182:98 183:98 184:98 185:98 186:99 187:99 188:99 189:100 190:100 191:100 192:100 193:101 194:101 195:101 196:101 197:102 198:103 199:103 200:103 201:104 202:104 203:104 204:105 205:106 206:106 207:106 208:107 209:107 210:108 211:108 212:109 213:109 214:110 215:110 216:111 217:111 218:112 219:113 220:113 221:114 222:114 223:115 224:116 225:117 226:117 227:117 228:118 229:118 230:119 231:119 232:119 233:119 234:119 235:120 236:120 237:120 238:120 239:120 240:120 241:120 242:121 243:122 244:123 245:123 246:123 247:123 248:124 249:124 250:124 251:124 252:124 253:125 254:126 255:126 256:127 257:127 258:127 259:127 260:128 261:128 262:129 263:129 264:130 265:130 266:130 267:130 268:131 269:132 270:132 271:132 272:132 273:132 274:133 275:134 276:134 277:134 278:134 279:134 280:135 281:135 282:135 283:136 284:136 285:137 286:137 287:137 288:137 289:138 290:138 291:139 292:140 293:141 294:141 295:141 296:141 297:141 298:142 299:142 300:142 301:142 302:143 303:143 304:144 305:145 306:145 307:146 308:146 309:146 310:147 311:147 312:148 313:148 314:148 315:148 316:148 317:148 318:149 319:149 320:149 321:149 322:150 323:151 324:151 325:152 326:153 327:153 328:153 329:154 330:154 331:154 332:155 333:156 334:156 335:156 336:157 337:157 338:157 339:157 340:158 341:158 342:158 343:159 344:159 345:159 346:160 347:160 348:160 349:161 350:161 351:161 352:161 353:161 354:162 355:162 356:162 357:163 358:164 359:164 360:164 361:164 362:164 363:164 364:165 365:165 366:165 367:165 368:165 369:166 370:166 371:166 372:166 373:167 374:168 375:169 376:169 377:170 378:170 379:170 380:171 381:172 382:172 383:172 384:172 385:173 386:173 387:173 388:174 389:174 390:174 391:175 392:175 393:175 394:175 395:176 396:176 397:177 398:177 399:178 400:178 401:178 402:178 403:178 404:178 405:179 406:179 407:179 408:179 409:180 410:181 411:181 412:182 413:182 414:182 415:183 416:184 417:184 418:185 419:185 420:185 421:185 422:185 423:185 424:186 425:187 426:187 427:188 428:188 429:188 430:189 431:189 432:189 433:190 434:190 435:190 436:190 437:191 438:191 439:192 440:192 441:192 442:192 443:193 444:193 445:194 446:194 447:195 448:196 449:196 450:196 451:196 452:197 453:197 454:198 455:199 456:199 457:199 458:199 459:200 460:201 461:202 462:202 463:203 464:203 465:203 466:203 467:204 468:204 469:204 470:205 471:206 472:206 473:206 474:207 475:207 476:207 477:207 478:208 479:208 480:208 481:208 482:208 483:209 484:209 485:209 486:209 487:210 488:210 489:211 490:211 491:212 492:212 493:212 494:213 495:213 496:214 497:214 498:214 499:215 500:215 501:215 502:215 503:215 504:216 505:217 506:217 507:218 508:218 509:218 510:219\n",
      "I1125 11:12:38.428929 47903194205696 run_squad.py:406] token_to_orig_map: 19:38 20:38 21:39 22:39 23:39 24:39 25:40 26:41 27:41 28:41 29:41 30:41 31:42 32:43 33:43 34:43 35:43 36:43 37:44 38:45 39:45 40:45 41:46 42:46 43:46 44:47 45:48 46:48 47:48 48:48 49:48 50:49 51:49 52:49 53:49 54:50 55:50 56:51 57:52 58:52 59:52 60:52 61:52 62:53 63:53 64:53 65:53 66:54 67:54 68:54 69:54 70:54 71:55 72:56 73:56 74:56 75:57 76:58 77:58 78:59 79:59 80:59 81:60 82:61 83:61 84:61 85:61 86:62 87:62 88:63 89:63 90:63 91:63 92:64 93:64 94:64 95:64 96:64 97:65 98:66 99:66 100:66 101:67 102:67 103:67 104:67 105:68 106:68 107:69 108:70 109:70 110:71 111:71 112:71 113:72 114:72 115:72 116:72 117:72 118:73 119:73 120:73 121:74 122:75 123:75 124:75 125:75 126:76 127:76 128:76 129:76 130:76 131:77 132:77 133:77 134:77 135:78 136:79 137:80 138:81 139:82 140:82 141:83 142:83 143:83 144:84 145:84 146:84 147:84 148:84 149:84 150:85 151:85 152:85 153:85 154:86 155:87 156:88 157:88 158:89 159:89 160:90 161:91 162:91 163:91 164:92 165:92 166:92 167:92 168:92 169:93 170:93 171:93 172:93 173:94 174:95 175:96 176:96 177:97 178:97 179:97 180:97 181:97 182:98 183:98 184:98 185:98 186:99 187:99 188:99 189:100 190:100 191:100 192:100 193:101 194:101 195:101 196:101 197:102 198:103 199:103 200:103 201:104 202:104 203:104 204:105 205:106 206:106 207:106 208:107 209:107 210:108 211:108 212:109 213:109 214:110 215:110 216:111 217:111 218:112 219:113 220:113 221:114 222:114 223:115 224:116 225:117 226:117 227:117 228:118 229:118 230:119 231:119 232:119 233:119 234:119 235:120 236:120 237:120 238:120 239:120 240:120 241:120 242:121 243:122 244:123 245:123 246:123 247:123 248:124 249:124 250:124 251:124 252:124 253:125 254:126 255:126 256:127 257:127 258:127 259:127 260:128 261:128 262:129 263:129 264:130 265:130 266:130 267:130 268:131 269:132 270:132 271:132 272:132 273:132 274:133 275:134 276:134 277:134 278:134 279:134 280:135 281:135 282:135 283:136 284:136 285:137 286:137 287:137 288:137 289:138 290:138 291:139 292:140 293:141 294:141 295:141 296:141 297:141 298:142 299:142 300:142 301:142 302:143 303:143 304:144 305:145 306:145 307:146 308:146 309:146 310:147 311:147 312:148 313:148 314:148 315:148 316:148 317:148 318:149 319:149 320:149 321:149 322:150 323:151 324:151 325:152 326:153 327:153 328:153 329:154 330:154 331:154 332:155 333:156 334:156 335:156 336:157 337:157 338:157 339:157 340:158 341:158 342:158 343:159 344:159 345:159 346:160 347:160 348:160 349:161 350:161 351:161 352:161 353:161 354:162 355:162 356:162 357:163 358:164 359:164 360:164 361:164 362:164 363:164 364:165 365:165 366:165 367:165 368:165 369:166 370:166 371:166 372:166 373:167 374:168 375:169 376:169 377:170 378:170 379:170 380:171 381:172 382:172 383:172 384:172 385:173 386:173 387:173 388:174 389:174 390:174 391:175 392:175 393:175 394:175 395:176 396:176 397:177 398:177 399:178 400:178 401:178 402:178 403:178 404:178 405:179 406:179 407:179 408:179 409:180 410:181 411:181 412:182 413:182 414:182 415:183 416:184 417:184 418:185 419:185 420:185 421:185 422:185 423:185 424:186 425:187 426:187 427:188 428:188 429:188 430:189 431:189 432:189 433:190 434:190 435:190 436:190 437:191 438:191 439:192 440:192 441:192 442:192 443:193 444:193 445:194 446:194 447:195 448:196 449:196 450:196 451:196 452:197 453:197 454:198 455:199 456:199 457:199 458:199 459:200 460:201 461:202 462:202 463:203 464:203 465:203 466:203 467:204 468:204 469:204 470:205 471:206 472:206 473:206 474:207 475:207 476:207 477:207 478:208 479:208 480:208 481:208 482:208 483:209 484:209 485:209 486:209 487:210 488:210 489:211 490:211 491:212 492:212 493:212 494:213 495:213 496:214 497:214 498:214 499:215 500:215 501:215 502:215 503:215 504:216 505:217 506:217 507:218 508:218 509:218 510:219\n",
      "INFO:tensorflow:token_is_max_context: 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "I1125 11:12:38.430068 47903194205696 run_squad.py:408] token_is_max_context: 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "INFO:tensorflow:input_ids: 101 8889 20595 31605 10459 9625 18778 120120 10892 55910 119787 119820 11489 9636 96404 120015 11287 110871 102 119569 11882 29551 11490 120120 10622 119834 9766 119996 43962 12092 120150 9316 123 23466 42815 18778 10530 18154 9625 18778 120305 8888 99118 119654 11239 9121 110873 11166 110875 11018 9670 12945 66540 27506 9059 14867 13912 8889 20595 118782 15184 10459 9645 17196 120118 11489 149 11490 11779 119821 10622 119593 8889 20595 11489 119569 9664 11467 8922 16758 22440 19905 9746 121040 18778 10459 9766 119996 9449 12092 120150 12638 123 23466 14279 42815 18778 33727 8887 119281 13374 9625 29683 23160 87503 8934 66623 9654 119591 119654 30120 10240 11882 50690 110873 11211 110875 10892 9670 42337 27506 13912 8889 20595 31605 11489 8896 12310 42815 18778 120682 9612 71013 28143 10530 119610 58088 119569 9316 119700 17022 8888 99118 13374 9766 119996 43962 12092 120150 11018 9612 71013 28143 10530 9835 58088 9322 24098 8889 20595 13912 8926 42337 11489 9686 27355 14423 52094 10459 9449 30005 120150 11513 119978 23289 64200 11882 89009 110873 11305 110875 10892 9670 12945 66540 27506 9075 15184 10459 9768 17196 120118 11489 9449 12092 120150 10530 18154 9625 18778 120305 8888 99118 22440 19905 119569 119712 12638 119572 11102 85533 11261 71327 11447 179 110863 119615 10739 119727 179 110863 119615 80001 79633 119639 119965 118726 119579 18837 11882 52651 110873 11396 110875 10892 9670 12945 66540 27506 24989 14867 10622 120021 13912 8889 20595 31605 10459 9569 16617 89851 120120 10622 68010 8984 46520 9569 42815 43962 10459 119736 10622 119564 13374 28336 49235 10123 15891 9316 9294 23466 14279 37093 54469 119772 13241 110873 11373 110875 10459 119569 119712 12638 119572 13374 9460 18622 120120 10459 119759 10622 119978 12006 9121 110873 20305 110875 10892 9670 12945 66540 27506 9059 14867 13912 8889 20595 9075 15184 11261 119571 13441 9075 15184 58303 17196 120118 11489 149 11490 11779 11513 119593 9766 119996 9316 10001 119996 10459 119656 120121 10530 110463 9766 119996 10459 9449 12092 120150 12638 9625 18778 120305 8888 99118 119773 30120 10240 11882 50690 110873 37115 110875 10892 9670 42337 27506 13912 8889 20595 118782 15184 31605 11489 8896 12310 42815 18778 120682 9612 71013 28143 10530 119610 58088 119569 17022 8922 16758 22440 19905 149 11490 11779 11261 8887 119281 13374 83243 62674 77261 9460 18622 120120 11882 119572 11102 85533 11261 9766 119996 43962 12092 120150 11018 9612 71013 28143 10459 58088 9322 59724 119723 16323 119664 19789 16204 12638 13810 12804 110873 24747 110875 11018 30085 119652 10459 8889 20595 10622 119615 80174 13374 9186 10739 118744 24891 9460 11513 10709 110862 77802 11467 120112 17594 119564 11102 10003 9449 12092 120150 110862 9590 46520 9316 9460 28143 119053 31503 119568 28697 9978 33654 9460 18622 120120 17022 8888 99118 13374 103995 9323 89851 13441 8984 46520 120118 10892 8889 20595 31531 46520 92515 9707 20595 41521 26344 10533 76036 66982 10739 119629 32679 11664 119835 119563 41845 16497 12638 22070 10230 110873 45389 110875 9632 9562 30005 122 21789 12638 19709 102\n",
      "I1125 11:12:38.430262 47903194205696 run_squad.py:410] input_ids: 101 8889 20595 31605 10459 9625 18778 120120 10892 55910 119787 119820 11489 9636 96404 120015 11287 110871 102 119569 11882 29551 11490 120120 10622 119834 9766 119996 43962 12092 120150 9316 123 23466 42815 18778 10530 18154 9625 18778 120305 8888 99118 119654 11239 9121 110873 11166 110875 11018 9670 12945 66540 27506 9059 14867 13912 8889 20595 118782 15184 10459 9645 17196 120118 11489 149 11490 11779 119821 10622 119593 8889 20595 11489 119569 9664 11467 8922 16758 22440 19905 9746 121040 18778 10459 9766 119996 9449 12092 120150 12638 123 23466 14279 42815 18778 33727 8887 119281 13374 9625 29683 23160 87503 8934 66623 9654 119591 119654 30120 10240 11882 50690 110873 11211 110875 10892 9670 42337 27506 13912 8889 20595 31605 11489 8896 12310 42815 18778 120682 9612 71013 28143 10530 119610 58088 119569 9316 119700 17022 8888 99118 13374 9766 119996 43962 12092 120150 11018 9612 71013 28143 10530 9835 58088 9322 24098 8889 20595 13912 8926 42337 11489 9686 27355 14423 52094 10459 9449 30005 120150 11513 119978 23289 64200 11882 89009 110873 11305 110875 10892 9670 12945 66540 27506 9075 15184 10459 9768 17196 120118 11489 9449 12092 120150 10530 18154 9625 18778 120305 8888 99118 22440 19905 119569 119712 12638 119572 11102 85533 11261 71327 11447 179 110863 119615 10739 119727 179 110863 119615 80001 79633 119639 119965 118726 119579 18837 11882 52651 110873 11396 110875 10892 9670 12945 66540 27506 24989 14867 10622 120021 13912 8889 20595 31605 10459 9569 16617 89851 120120 10622 68010 8984 46520 9569 42815 43962 10459 119736 10622 119564 13374 28336 49235 10123 15891 9316 9294 23466 14279 37093 54469 119772 13241 110873 11373 110875 10459 119569 119712 12638 119572 13374 9460 18622 120120 10459 119759 10622 119978 12006 9121 110873 20305 110875 10892 9670 12945 66540 27506 9059 14867 13912 8889 20595 9075 15184 11261 119571 13441 9075 15184 58303 17196 120118 11489 149 11490 11779 11513 119593 9766 119996 9316 10001 119996 10459 119656 120121 10530 110463 9766 119996 10459 9449 12092 120150 12638 9625 18778 120305 8888 99118 119773 30120 10240 11882 50690 110873 37115 110875 10892 9670 42337 27506 13912 8889 20595 118782 15184 31605 11489 8896 12310 42815 18778 120682 9612 71013 28143 10530 119610 58088 119569 17022 8922 16758 22440 19905 149 11490 11779 11261 8887 119281 13374 83243 62674 77261 9460 18622 120120 11882 119572 11102 85533 11261 9766 119996 43962 12092 120150 11018 9612 71013 28143 10459 58088 9322 59724 119723 16323 119664 19789 16204 12638 13810 12804 110873 24747 110875 11018 30085 119652 10459 8889 20595 10622 119615 80174 13374 9186 10739 118744 24891 9460 11513 10709 110862 77802 11467 120112 17594 119564 11102 10003 9449 12092 120150 110862 9590 46520 9316 9460 28143 119053 31503 119568 28697 9978 33654 9460 18622 120120 17022 8888 99118 13374 103995 9323 89851 13441 8984 46520 120118 10892 8889 20595 31531 46520 92515 9707 20595 41521 26344 10533 76036 66982 10739 119629 32679 11664 119835 119563 41845 16497 12638 22070 10230 110873 45389 110875 9632 9562 30005 122 21789 12638 19709 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.431461 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.431608 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.433532 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000018\n",
      "I1125 11:12:38.433617 47903194205696 run_squad.py:400] unique_id: 1000000018\n",
      "INFO:tensorflow:example_index: 14\n",
      "I1125 11:12:38.433675 47903194205696 run_squad.py:401] example_index: 14\n",
      "INFO:tensorflow:doc_span_index: 2\n",
      "I1125 11:12:38.433722 47903194205696 run_squad.py:402] doc_span_index: 2\n",
      "INFO:tensorflow:tokens: [CLS] 곡 ##관 ##내 ##의 유 ##동 ##해석 ##은 어떤 산업 분야 ##에서 응 ##용이 가능한 ##가 ##? [SEP] ##도 ##분포 ##는 원 ##심 ##력 ##에 큰 영향을 받 ##으며 곡 ##관 180 근 ##방 ##에서 좌 ##우 ##대 ##칭 ##의 속 ##보 ##분포 ##를 보였다. 그리고 Lim ##과 Yoo ##[ ##7 ##] ##은 정 ##사 ##각 ##형 덕 ##트 ##의 출 ##구 ##영역 ##에서 속 ##도 ##분포 ##에 대한 유 ##동 ##특성을 고 ##찰 ##하기 위해 실험 ##결과 ##와 비교 ##한 결과 ##로 RN ##G k ##- 모델 ##이 표준 k ##- 모델 ##보다 좋은 결과를 나타 ##냈 ##으며, Yang ##과 Choi ##[ ##8 ##] ##은 정 ##사 ##각 ##형 ##단 ##면 ##을 갖는 180 곡 ##관 ##내 ##의 열 ##전 ##달 ##해석 ##을 위하여 난 ##류 열 ##유 ##속 ##의 모형 ##을 적용 ##하여 Nu ##ssel ##t ##수 및 무 ##차 ##원 ##온 ##도의 특성을 Johnson ##[ ##9 ##] ##의 실험 ##결과 ##와 비교 ##하여 수 ##치 ##해석 ##의 예측 ##을 보였다. Lee 등 ##[ ##10 ##] ##은 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 덕 ##트 ##로 구성 ##된 덕 ##트 ##입 ##구 ##영역 ##에서 L ##D ##V ##를 이용하여 축 ##방향 및 횡 ##방향 ##의 위치 ##변화 ##에 따른 축 ##방향 ##의 속 ##도 ##분포 ##와 유 ##동 ##특성을 고 ##찰 ##하였고, Bon ##g ##과 Cho ##[ ##11 ##] ##은 정 ##방 ##형 180 곡 ##관 ##덕 ##트 ##내 ##에서 공 ##기 ##유 ##동 ##특성이 원 ##심 ##력 ##에 미치는 영향을 실험 ##적으로 규 ##명 ##하기 위해 L ##D ##V ##로 계 ##측 ##하여 FL ##UE ##NT 수 ##치 ##해석 ##과 비교 ##한 결과 ##로 축 ##방향 ##속 ##도 ##분포 ##는 원 ##심 ##력 ##의 영향을 받 ##음을 보여 ##주 ##었다. 또한 Rudolf ##와 Des ##ova ##[ ##12 ##] ##는 여러 형태 ##의 곡 ##관 ##을 모델 ##링 ##하여 레 ##이 ##놀 ##즈 수 ##를 60 ##, ##000 ##으로 동일 ##하게 적용 ##한 후 속 ##도 ##분포 ##, 와 ##류 및 수 ##력 ##손 ##실 발생 등의 현 ##상을 수 ##치 ##해석 ##적으로 고 ##찰 ##하여 완전히 발 ##달 ##된 난 ##류 ##영역 ##은 곡 ##관 ##후 ##류 ##로부터 직 ##관 ##거 ##리는 40 ##배 이상 ##이 필요 ##하다 ##고 하였 ##고, Carla ##nder ##와 Dels ##ing ##[ ##13 ##] 은 엘 ##보 1 ##개 ##와 다른 평 ##면 ##으로 결 ##합 ##된 2 ##개의 엘 ##보 하 ##류 직 ##관 ##거 ##리 L ##/ ##D ##= ##15 ##지 ##점에서 초 ##음 ##파 ##유 ##량 ##계를 사용하여 실험 ##조건 ##을 레 ##이 ##놀 ##즈 ##수 25 110 ##, ##000 ##범위 ##로 설정 ##하여 유 ##량 실험 ##을 한 결과 ##로 레 ##이 ##놀 ##즈 ##수 4 ##, ##000 ##에서 최대 ##오 ##차 ##가 3 4 ##% ##가 발생 ##함을 보여 ##주 ##었다. 본 연구에서는 정 ##사 ##각 ##형 ##단 ##면 ##을 갖는 180 곡 ##관 ##내 유 ##체의 속 ##도 ##분포 ##특성을 고 ##찰 하 ##기 위하여 먼저 Chang 등 ##[ ##14 ##] ##이 수행 ##한 연구 ##결과 ##와 비교 ##를 통해 수 ##치 ##해석 난 ##류 ##모델 ##에 대한 타 ##당 ##성 검증 ##을 [SEP]\n",
      "I1125 11:12:38.433905 47903194205696 run_squad.py:404] tokens: [CLS] 곡 ##관 ##내 ##의 유 ##동 ##해석 ##은 어떤 산업 분야 ##에서 응 ##용이 가능한 ##가 ##? [SEP] ##도 ##분포 ##는 원 ##심 ##력 ##에 큰 영향을 받 ##으며 곡 ##관 180 근 ##방 ##에서 좌 ##우 ##대 ##칭 ##의 속 ##보 ##분포 ##를 보였다. 그리고 Lim ##과 Yoo ##[ ##7 ##] ##은 정 ##사 ##각 ##형 덕 ##트 ##의 출 ##구 ##영역 ##에서 속 ##도 ##분포 ##에 대한 유 ##동 ##특성을 고 ##찰 ##하기 위해 실험 ##결과 ##와 비교 ##한 결과 ##로 RN ##G k ##- 모델 ##이 표준 k ##- 모델 ##보다 좋은 결과를 나타 ##냈 ##으며, Yang ##과 Choi ##[ ##8 ##] ##은 정 ##사 ##각 ##형 ##단 ##면 ##을 갖는 180 곡 ##관 ##내 ##의 열 ##전 ##달 ##해석 ##을 위하여 난 ##류 열 ##유 ##속 ##의 모형 ##을 적용 ##하여 Nu ##ssel ##t ##수 및 무 ##차 ##원 ##온 ##도의 특성을 Johnson ##[ ##9 ##] ##의 실험 ##결과 ##와 비교 ##하여 수 ##치 ##해석 ##의 예측 ##을 보였다. Lee 등 ##[ ##10 ##] ##은 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 덕 ##트 ##로 구성 ##된 덕 ##트 ##입 ##구 ##영역 ##에서 L ##D ##V ##를 이용하여 축 ##방향 및 횡 ##방향 ##의 위치 ##변화 ##에 따른 축 ##방향 ##의 속 ##도 ##분포 ##와 유 ##동 ##특성을 고 ##찰 ##하였고, Bon ##g ##과 Cho ##[ ##11 ##] ##은 정 ##방 ##형 180 곡 ##관 ##덕 ##트 ##내 ##에서 공 ##기 ##유 ##동 ##특성이 원 ##심 ##력 ##에 미치는 영향을 실험 ##적으로 규 ##명 ##하기 위해 L ##D ##V ##로 계 ##측 ##하여 FL ##UE ##NT 수 ##치 ##해석 ##과 비교 ##한 결과 ##로 축 ##방향 ##속 ##도 ##분포 ##는 원 ##심 ##력 ##의 영향을 받 ##음을 보여 ##주 ##었다. 또한 Rudolf ##와 Des ##ova ##[ ##12 ##] ##는 여러 형태 ##의 곡 ##관 ##을 모델 ##링 ##하여 레 ##이 ##놀 ##즈 수 ##를 60 ##, ##000 ##으로 동일 ##하게 적용 ##한 후 속 ##도 ##분포 ##, 와 ##류 및 수 ##력 ##손 ##실 발생 등의 현 ##상을 수 ##치 ##해석 ##적으로 고 ##찰 ##하여 완전히 발 ##달 ##된 난 ##류 ##영역 ##은 곡 ##관 ##후 ##류 ##로부터 직 ##관 ##거 ##리는 40 ##배 이상 ##이 필요 ##하다 ##고 하였 ##고, Carla ##nder ##와 Dels ##ing ##[ ##13 ##] 은 엘 ##보 1 ##개 ##와 다른 평 ##면 ##으로 결 ##합 ##된 2 ##개의 엘 ##보 하 ##류 직 ##관 ##거 ##리 L ##/ ##D ##= ##15 ##지 ##점에서 초 ##음 ##파 ##유 ##량 ##계를 사용하여 실험 ##조건 ##을 레 ##이 ##놀 ##즈 ##수 25 110 ##, ##000 ##범위 ##로 설정 ##하여 유 ##량 실험 ##을 한 결과 ##로 레 ##이 ##놀 ##즈 ##수 4 ##, ##000 ##에서 최대 ##오 ##차 ##가 3 4 ##% ##가 발생 ##함을 보여 ##주 ##었다. 본 연구에서는 정 ##사 ##각 ##형 ##단 ##면 ##을 갖는 180 곡 ##관 ##내 유 ##체의 속 ##도 ##분포 ##특성을 고 ##찰 하 ##기 위하여 먼저 Chang 등 ##[ ##14 ##] ##이 수행 ##한 연구 ##결과 ##와 비교 ##를 통해 수 ##치 ##해석 난 ##류 ##모델 ##에 대한 타 ##당 ##성 검증 ##을 [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 19:84 20:84 21:84 22:85 23:85 24:85 25:85 26:86 27:87 28:88 29:88 30:89 31:89 32:90 33:91 34:91 35:91 36:92 37:92 38:92 39:92 40:92 41:93 42:93 43:93 44:93 45:94 46:95 47:96 48:96 49:97 50:97 51:97 52:97 53:97 54:98 55:98 56:98 57:98 58:99 59:99 60:99 61:100 62:100 63:100 64:100 65:101 66:101 67:101 68:101 69:102 70:103 71:103 72:103 73:104 74:104 75:104 76:105 77:106 78:106 79:106 80:107 81:107 82:108 83:108 84:109 85:109 86:110 87:110 88:111 89:111 90:112 91:113 92:113 93:114 94:114 95:115 96:116 97:117 98:117 99:117 100:118 101:118 102:119 103:119 104:119 105:119 106:119 107:120 108:120 109:120 110:120 111:120 112:120 113:120 114:121 115:122 116:123 117:123 118:123 119:123 120:124 121:124 122:124 123:124 124:124 125:125 126:126 127:126 128:127 129:127 130:127 131:127 132:128 133:128 134:129 135:129 136:130 137:130 138:130 139:130 140:131 141:132 142:132 143:132 144:132 145:132 146:133 147:134 148:134 149:134 150:134 151:134 152:135 153:135 154:135 155:136 156:136 157:137 158:137 159:137 160:137 161:138 162:138 163:139 164:140 165:141 166:141 167:141 168:141 169:141 170:142 171:142 172:142 173:142 174:143 175:143 176:144 177:145 178:145 179:146 180:146 181:146 182:147 183:147 184:148 185:148 186:148 187:148 188:148 189:148 190:149 191:149 192:149 193:149 194:150 195:151 196:151 197:152 198:153 199:153 200:153 201:154 202:154 203:154 204:155 205:156 206:156 207:156 208:157 209:157 210:157 211:157 212:158 213:158 214:158 215:159 216:159 217:159 218:160 219:160 220:160 221:161 222:161 223:161 224:161 225:161 226:162 227:162 228:162 229:163 230:164 231:164 232:164 233:164 234:164 235:164 236:165 237:165 238:165 239:165 240:165 241:166 242:166 243:166 244:166 245:167 246:168 247:169 248:169 249:170 250:170 251:170 252:171 253:172 254:172 255:172 256:172 257:173 258:173 259:173 260:174 261:174 262:174 263:175 264:175 265:175 266:175 267:176 268:176 269:177 270:177 271:178 272:178 273:178 274:178 275:178 276:178 277:179 278:179 279:179 280:179 281:180 282:181 283:181 284:182 285:182 286:182 287:183 288:184 289:184 290:185 291:185 292:185 293:185 294:185 295:185 296:186 297:187 298:187 299:188 300:188 301:188 302:189 303:189 304:189 305:190 306:190 307:190 308:190 309:191 310:191 311:192 312:192 313:192 314:192 315:193 316:193 317:194 318:194 319:195 320:196 321:196 322:196 323:196 324:197 325:197 326:198 327:199 328:199 329:199 330:199 331:200 332:201 333:202 334:202 335:203 336:203 337:203 338:203 339:204 340:204 341:204 342:205 343:206 344:206 345:206 346:207 347:207 348:207 349:207 350:208 351:208 352:208 353:208 354:208 355:209 356:209 357:209 358:209 359:210 360:210 361:211 362:211 363:212 364:212 365:212 366:213 367:213 368:214 369:214 370:214 371:215 372:215 373:215 374:215 375:215 376:216 377:217 378:217 379:218 380:218 381:218 382:219 383:220 384:220 385:220 386:221 387:221 388:221 389:222 390:222 391:223 392:223 393:224 394:224 395:225 396:225 397:225 398:225 399:226 400:226 401:226 402:226 403:226 404:226 405:226 406:227 407:227 408:227 409:227 410:227 411:227 412:228 413:229 414:229 415:229 416:230 417:230 418:230 419:230 420:230 421:231 422:232 423:232 424:232 425:232 426:232 427:233 428:233 429:234 430:234 431:235 432:235 433:236 434:237 435:237 436:238 437:238 438:238 439:238 440:238 441:239 442:239 443:239 444:239 445:240 446:240 447:240 448:240 449:241 450:242 451:242 452:242 453:243 454:243 455:244 456:244 457:244 458:245 459:246 460:247 461:247 462:247 463:247 464:247 465:247 466:247 467:248 468:249 469:250 470:250 471:250 472:251 473:251 474:252 475:252 476:252 477:252 478:253 479:253 480:254 481:254 482:255 483:256 484:257 485:258 486:258 487:258 488:258 489:258 490:259 491:259 492:260 493:260 494:260 495:261 496:261 497:262 498:263 499:263 500:263 501:264 502:264 503:264 504:264 505:265 506:266 507:266 508:266 509:267 510:267\n",
      "I1125 11:12:38.434133 47903194205696 run_squad.py:406] token_to_orig_map: 19:84 20:84 21:84 22:85 23:85 24:85 25:85 26:86 27:87 28:88 29:88 30:89 31:89 32:90 33:91 34:91 35:91 36:92 37:92 38:92 39:92 40:92 41:93 42:93 43:93 44:93 45:94 46:95 47:96 48:96 49:97 50:97 51:97 52:97 53:97 54:98 55:98 56:98 57:98 58:99 59:99 60:99 61:100 62:100 63:100 64:100 65:101 66:101 67:101 68:101 69:102 70:103 71:103 72:103 73:104 74:104 75:104 76:105 77:106 78:106 79:106 80:107 81:107 82:108 83:108 84:109 85:109 86:110 87:110 88:111 89:111 90:112 91:113 92:113 93:114 94:114 95:115 96:116 97:117 98:117 99:117 100:118 101:118 102:119 103:119 104:119 105:119 106:119 107:120 108:120 109:120 110:120 111:120 112:120 113:120 114:121 115:122 116:123 117:123 118:123 119:123 120:124 121:124 122:124 123:124 124:124 125:125 126:126 127:126 128:127 129:127 130:127 131:127 132:128 133:128 134:129 135:129 136:130 137:130 138:130 139:130 140:131 141:132 142:132 143:132 144:132 145:132 146:133 147:134 148:134 149:134 150:134 151:134 152:135 153:135 154:135 155:136 156:136 157:137 158:137 159:137 160:137 161:138 162:138 163:139 164:140 165:141 166:141 167:141 168:141 169:141 170:142 171:142 172:142 173:142 174:143 175:143 176:144 177:145 178:145 179:146 180:146 181:146 182:147 183:147 184:148 185:148 186:148 187:148 188:148 189:148 190:149 191:149 192:149 193:149 194:150 195:151 196:151 197:152 198:153 199:153 200:153 201:154 202:154 203:154 204:155 205:156 206:156 207:156 208:157 209:157 210:157 211:157 212:158 213:158 214:158 215:159 216:159 217:159 218:160 219:160 220:160 221:161 222:161 223:161 224:161 225:161 226:162 227:162 228:162 229:163 230:164 231:164 232:164 233:164 234:164 235:164 236:165 237:165 238:165 239:165 240:165 241:166 242:166 243:166 244:166 245:167 246:168 247:169 248:169 249:170 250:170 251:170 252:171 253:172 254:172 255:172 256:172 257:173 258:173 259:173 260:174 261:174 262:174 263:175 264:175 265:175 266:175 267:176 268:176 269:177 270:177 271:178 272:178 273:178 274:178 275:178 276:178 277:179 278:179 279:179 280:179 281:180 282:181 283:181 284:182 285:182 286:182 287:183 288:184 289:184 290:185 291:185 292:185 293:185 294:185 295:185 296:186 297:187 298:187 299:188 300:188 301:188 302:189 303:189 304:189 305:190 306:190 307:190 308:190 309:191 310:191 311:192 312:192 313:192 314:192 315:193 316:193 317:194 318:194 319:195 320:196 321:196 322:196 323:196 324:197 325:197 326:198 327:199 328:199 329:199 330:199 331:200 332:201 333:202 334:202 335:203 336:203 337:203 338:203 339:204 340:204 341:204 342:205 343:206 344:206 345:206 346:207 347:207 348:207 349:207 350:208 351:208 352:208 353:208 354:208 355:209 356:209 357:209 358:209 359:210 360:210 361:211 362:211 363:212 364:212 365:212 366:213 367:213 368:214 369:214 370:214 371:215 372:215 373:215 374:215 375:215 376:216 377:217 378:217 379:218 380:218 381:218 382:219 383:220 384:220 385:220 386:221 387:221 388:221 389:222 390:222 391:223 392:223 393:224 394:224 395:225 396:225 397:225 398:225 399:226 400:226 401:226 402:226 403:226 404:226 405:226 406:227 407:227 408:227 409:227 410:227 411:227 412:228 413:229 414:229 415:229 416:230 417:230 418:230 419:230 420:230 421:231 422:232 423:232 424:232 425:232 426:232 427:233 428:233 429:234 430:234 431:235 432:235 433:236 434:237 435:237 436:238 437:238 438:238 439:238 440:238 441:239 442:239 443:239 444:239 445:240 446:240 447:240 448:240 449:241 450:242 451:242 452:242 453:243 454:243 455:244 456:244 457:244 458:245 459:246 460:247 461:247 462:247 463:247 464:247 465:247 466:247 467:248 468:249 469:250 470:250 471:250 472:251 473:251 474:252 475:252 476:252 477:252 478:253 479:253 480:254 481:254 482:255 483:256 484:257 485:258 486:258 487:258 488:258 489:258 490:259 491:259 492:260 493:260 494:260 495:261 496:261 497:262 498:263 499:263 500:263 501:264 502:264 503:264 504:264 505:265 506:266 507:266 508:266 509:267 510:267\n",
      "INFO:tensorflow:token_is_max_context: 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "I1125 11:12:38.435398 47903194205696 run_squad.py:408] token_is_max_context: 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "INFO:tensorflow:input_ids: 101 8889 20595 31605 10459 9625 18778 120120 10892 55910 119787 119820 11489 9636 96404 120015 11287 110871 102 12092 120150 11018 9612 71013 28143 10530 9835 58088 9322 24098 8889 20595 13912 8926 42337 11489 9686 27355 14423 52094 10459 9449 30005 120150 11513 119978 23289 64200 11882 89009 110873 11305 110875 10892 9670 12945 66540 27506 9075 15184 10459 9768 17196 120118 11489 9449 12092 120150 10530 18154 9625 18778 120305 8888 99118 22440 19905 119569 119712 12638 119572 11102 85533 11261 71327 11447 179 110863 119615 10739 119727 179 110863 119615 80001 79633 119639 119965 118726 119579 18837 11882 52651 110873 11396 110875 10892 9670 12945 66540 27506 24989 14867 10622 120021 13912 8889 20595 31605 10459 9569 16617 89851 120120 10622 68010 8984 46520 9569 42815 43962 10459 119736 10622 119564 13374 28336 49235 10123 15891 9316 9294 23466 14279 37093 54469 119772 13241 110873 11373 110875 10459 119569 119712 12638 119572 13374 9460 18622 120120 10459 119759 10622 119978 12006 9121 110873 20305 110875 10892 9670 12945 66540 27506 9059 14867 13912 8889 20595 9075 15184 11261 119571 13441 9075 15184 58303 17196 120118 11489 149 11490 11779 11513 119593 9766 119996 9316 10001 119996 10459 119656 120121 10530 110463 9766 119996 10459 9449 12092 120150 12638 9625 18778 120305 8888 99118 119773 30120 10240 11882 50690 110873 37115 110875 10892 9670 42337 27506 13912 8889 20595 118782 15184 31605 11489 8896 12310 42815 18778 120682 9612 71013 28143 10530 119610 58088 119569 17022 8922 16758 22440 19905 149 11490 11779 11261 8887 119281 13374 83243 62674 77261 9460 18622 120120 11882 119572 11102 85533 11261 9766 119996 43962 12092 120150 11018 9612 71013 28143 10459 58088 9322 59724 119723 16323 119664 19789 16204 12638 13810 12804 110873 24747 110875 11018 30085 119652 10459 8889 20595 10622 119615 80174 13374 9186 10739 118744 24891 9460 11513 10709 110862 77802 11467 120112 17594 119564 11102 10003 9449 12092 120150 110862 9590 46520 9316 9460 28143 119053 31503 119568 28697 9978 33654 9460 18622 120120 17022 8888 99118 13374 103995 9323 89851 13441 8984 46520 120118 10892 8889 20595 31531 46520 92515 9707 20595 41521 26344 10533 76036 66982 10739 119629 32679 11664 119835 119563 41845 16497 12638 22070 10230 110873 45389 110875 9632 9562 30005 122 21789 12638 19709 9926 14867 11467 8881 33188 13441 123 32501 9562 30005 9952 46520 9707 20595 41521 12692 149 110865 11490 110869 37462 12508 120102 9757 32158 46150 42815 44321 54163 119843 119569 119956 10622 9186 10739 118744 24891 15891 10258 13057 110862 77802 120178 11261 119734 13374 9625 44321 119569 10622 9954 85533 11261 9186 10739 118744 24891 15891 125 110862 77802 11489 99405 28188 23466 11287 124 125 110855 11287 119568 120064 119723 16323 119664 9358 119618 9670 12945 66540 27506 24989 14867 10622 120021 13912 8889 20595 31605 9625 79025 9449 12092 120150 120305 8888 99118 9952 12310 68010 104304 28545 9121 110873 39900 110875 10739 119570 11102 91785 119712 12638 119572 11513 25605 9460 18622 120120 8984 46520 120069 10530 18154 9845 21928 17138 119743 10622 102\n",
      "I1125 11:12:38.435592 47903194205696 run_squad.py:410] input_ids: 101 8889 20595 31605 10459 9625 18778 120120 10892 55910 119787 119820 11489 9636 96404 120015 11287 110871 102 12092 120150 11018 9612 71013 28143 10530 9835 58088 9322 24098 8889 20595 13912 8926 42337 11489 9686 27355 14423 52094 10459 9449 30005 120150 11513 119978 23289 64200 11882 89009 110873 11305 110875 10892 9670 12945 66540 27506 9075 15184 10459 9768 17196 120118 11489 9449 12092 120150 10530 18154 9625 18778 120305 8888 99118 22440 19905 119569 119712 12638 119572 11102 85533 11261 71327 11447 179 110863 119615 10739 119727 179 110863 119615 80001 79633 119639 119965 118726 119579 18837 11882 52651 110873 11396 110875 10892 9670 12945 66540 27506 24989 14867 10622 120021 13912 8889 20595 31605 10459 9569 16617 89851 120120 10622 68010 8984 46520 9569 42815 43962 10459 119736 10622 119564 13374 28336 49235 10123 15891 9316 9294 23466 14279 37093 54469 119772 13241 110873 11373 110875 10459 119569 119712 12638 119572 13374 9460 18622 120120 10459 119759 10622 119978 12006 9121 110873 20305 110875 10892 9670 12945 66540 27506 9059 14867 13912 8889 20595 9075 15184 11261 119571 13441 9075 15184 58303 17196 120118 11489 149 11490 11779 11513 119593 9766 119996 9316 10001 119996 10459 119656 120121 10530 110463 9766 119996 10459 9449 12092 120150 12638 9625 18778 120305 8888 99118 119773 30120 10240 11882 50690 110873 37115 110875 10892 9670 42337 27506 13912 8889 20595 118782 15184 31605 11489 8896 12310 42815 18778 120682 9612 71013 28143 10530 119610 58088 119569 17022 8922 16758 22440 19905 149 11490 11779 11261 8887 119281 13374 83243 62674 77261 9460 18622 120120 11882 119572 11102 85533 11261 9766 119996 43962 12092 120150 11018 9612 71013 28143 10459 58088 9322 59724 119723 16323 119664 19789 16204 12638 13810 12804 110873 24747 110875 11018 30085 119652 10459 8889 20595 10622 119615 80174 13374 9186 10739 118744 24891 9460 11513 10709 110862 77802 11467 120112 17594 119564 11102 10003 9449 12092 120150 110862 9590 46520 9316 9460 28143 119053 31503 119568 28697 9978 33654 9460 18622 120120 17022 8888 99118 13374 103995 9323 89851 13441 8984 46520 120118 10892 8889 20595 31531 46520 92515 9707 20595 41521 26344 10533 76036 66982 10739 119629 32679 11664 119835 119563 41845 16497 12638 22070 10230 110873 45389 110875 9632 9562 30005 122 21789 12638 19709 9926 14867 11467 8881 33188 13441 123 32501 9562 30005 9952 46520 9707 20595 41521 12692 149 110865 11490 110869 37462 12508 120102 9757 32158 46150 42815 44321 54163 119843 119569 119956 10622 9186 10739 118744 24891 15891 10258 13057 110862 77802 120178 11261 119734 13374 9625 44321 119569 10622 9954 85533 11261 9186 10739 118744 24891 15891 125 110862 77802 11489 99405 28188 23466 11287 124 125 110855 11287 119568 120064 119723 16323 119664 9358 119618 9670 12945 66540 27506 24989 14867 10622 120021 13912 8889 20595 31605 9625 79025 9449 12092 120150 120305 8888 99118 9952 12310 68010 104304 28545 9121 110873 39900 110875 10739 119570 11102 91785 119712 12638 119572 11513 25605 9460 18622 120120 8984 46520 120069 10530 18154 9845 21928 17138 119743 10622 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.437042 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.437255 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.438994 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000019\n",
      "I1125 11:12:38.439076 47903194205696 run_squad.py:400] unique_id: 1000000019\n",
      "INFO:tensorflow:example_index: 14\n",
      "I1125 11:12:38.439128 47903194205696 run_squad.py:401] example_index: 14\n",
      "INFO:tensorflow:doc_span_index: 3\n",
      "I1125 11:12:38.439174 47903194205696 run_squad.py:402] doc_span_index: 3\n",
      "INFO:tensorflow:tokens: [CLS] 곡 ##관 ##내 ##의 유 ##동 ##해석 ##은 어떤 산업 분야 ##에서 응 ##용이 가능한 ##가 ##? [SEP] Johnson ##[ ##9 ##] ##의 실험 ##결과 ##와 비교 ##하여 수 ##치 ##해석 ##의 예측 ##을 보였다. Lee 등 ##[ ##10 ##] ##은 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 덕 ##트 ##로 구성 ##된 덕 ##트 ##입 ##구 ##영역 ##에서 L ##D ##V ##를 이용하여 축 ##방향 및 횡 ##방향 ##의 위치 ##변화 ##에 따른 축 ##방향 ##의 속 ##도 ##분포 ##와 유 ##동 ##특성을 고 ##찰 ##하였고, Bon ##g ##과 Cho ##[ ##11 ##] ##은 정 ##방 ##형 180 곡 ##관 ##덕 ##트 ##내 ##에서 공 ##기 ##유 ##동 ##특성이 원 ##심 ##력 ##에 미치는 영향을 실험 ##적으로 규 ##명 ##하기 위해 L ##D ##V ##로 계 ##측 ##하여 FL ##UE ##NT 수 ##치 ##해석 ##과 비교 ##한 결과 ##로 축 ##방향 ##속 ##도 ##분포 ##는 원 ##심 ##력 ##의 영향을 받 ##음을 보여 ##주 ##었다. 또한 Rudolf ##와 Des ##ova ##[ ##12 ##] ##는 여러 형태 ##의 곡 ##관 ##을 모델 ##링 ##하여 레 ##이 ##놀 ##즈 수 ##를 60 ##, ##000 ##으로 동일 ##하게 적용 ##한 후 속 ##도 ##분포 ##, 와 ##류 및 수 ##력 ##손 ##실 발생 등의 현 ##상을 수 ##치 ##해석 ##적으로 고 ##찰 ##하여 완전히 발 ##달 ##된 난 ##류 ##영역 ##은 곡 ##관 ##후 ##류 ##로부터 직 ##관 ##거 ##리는 40 ##배 이상 ##이 필요 ##하다 ##고 하였 ##고, Carla ##nder ##와 Dels ##ing ##[ ##13 ##] 은 엘 ##보 1 ##개 ##와 다른 평 ##면 ##으로 결 ##합 ##된 2 ##개의 엘 ##보 하 ##류 직 ##관 ##거 ##리 L ##/ ##D ##= ##15 ##지 ##점에서 초 ##음 ##파 ##유 ##량 ##계를 사용하여 실험 ##조건 ##을 레 ##이 ##놀 ##즈 ##수 25 110 ##, ##000 ##범위 ##로 설정 ##하여 유 ##량 실험 ##을 한 결과 ##로 레 ##이 ##놀 ##즈 ##수 4 ##, ##000 ##에서 최대 ##오 ##차 ##가 3 4 ##% ##가 발생 ##함을 보여 ##주 ##었다. 본 연구에서는 정 ##사 ##각 ##형 ##단 ##면 ##을 갖는 180 곡 ##관 ##내 유 ##체의 속 ##도 ##분포 ##특성을 고 ##찰 하 ##기 위하여 먼저 Chang 등 ##[ ##14 ##] ##이 수행 ##한 연구 ##결과 ##와 비교 ##를 통해 수 ##치 ##해석 난 ##류 ##모델 ##에 대한 타 ##당 ##성 검증 ##을 수행 ##한 후 곡 ##관 ##내 ##의 작 ##동 ##유 ##체 ##, 입 ##구 ##속 ##도, 표면 ##조 ##도, 곡 ##률 반 ##경 ##, 수 ##력 ##직 ##경 등의 유 ##동 ##인 ##자 ##에 따른 속 ##도 ##분포 ##특성을 분석 ##하고, 곡 ##관 ##후 ##류 ##에 연결 ##된 직 ##관 ##내 ##의 유 ##체 ##속 ##도 ##특성 ##의 결과를 토 ##대로 유 ##량 ##계 ##측 ##에 유 ##효 ##한 직 ##관 ##거 ##리의 위치 ##를 제시 ##하는데 있다. [SEP]\n",
      "I1125 11:12:38.439347 47903194205696 run_squad.py:404] tokens: [CLS] 곡 ##관 ##내 ##의 유 ##동 ##해석 ##은 어떤 산업 분야 ##에서 응 ##용이 가능한 ##가 ##? [SEP] Johnson ##[ ##9 ##] ##의 실험 ##결과 ##와 비교 ##하여 수 ##치 ##해석 ##의 예측 ##을 보였다. Lee 등 ##[ ##10 ##] ##은 정 ##사 ##각 ##형 단 ##면 180 곡 ##관 덕 ##트 ##로 구성 ##된 덕 ##트 ##입 ##구 ##영역 ##에서 L ##D ##V ##를 이용하여 축 ##방향 및 횡 ##방향 ##의 위치 ##변화 ##에 따른 축 ##방향 ##의 속 ##도 ##분포 ##와 유 ##동 ##특성을 고 ##찰 ##하였고, Bon ##g ##과 Cho ##[ ##11 ##] ##은 정 ##방 ##형 180 곡 ##관 ##덕 ##트 ##내 ##에서 공 ##기 ##유 ##동 ##특성이 원 ##심 ##력 ##에 미치는 영향을 실험 ##적으로 규 ##명 ##하기 위해 L ##D ##V ##로 계 ##측 ##하여 FL ##UE ##NT 수 ##치 ##해석 ##과 비교 ##한 결과 ##로 축 ##방향 ##속 ##도 ##분포 ##는 원 ##심 ##력 ##의 영향을 받 ##음을 보여 ##주 ##었다. 또한 Rudolf ##와 Des ##ova ##[ ##12 ##] ##는 여러 형태 ##의 곡 ##관 ##을 모델 ##링 ##하여 레 ##이 ##놀 ##즈 수 ##를 60 ##, ##000 ##으로 동일 ##하게 적용 ##한 후 속 ##도 ##분포 ##, 와 ##류 및 수 ##력 ##손 ##실 발생 등의 현 ##상을 수 ##치 ##해석 ##적으로 고 ##찰 ##하여 완전히 발 ##달 ##된 난 ##류 ##영역 ##은 곡 ##관 ##후 ##류 ##로부터 직 ##관 ##거 ##리는 40 ##배 이상 ##이 필요 ##하다 ##고 하였 ##고, Carla ##nder ##와 Dels ##ing ##[ ##13 ##] 은 엘 ##보 1 ##개 ##와 다른 평 ##면 ##으로 결 ##합 ##된 2 ##개의 엘 ##보 하 ##류 직 ##관 ##거 ##리 L ##/ ##D ##= ##15 ##지 ##점에서 초 ##음 ##파 ##유 ##량 ##계를 사용하여 실험 ##조건 ##을 레 ##이 ##놀 ##즈 ##수 25 110 ##, ##000 ##범위 ##로 설정 ##하여 유 ##량 실험 ##을 한 결과 ##로 레 ##이 ##놀 ##즈 ##수 4 ##, ##000 ##에서 최대 ##오 ##차 ##가 3 4 ##% ##가 발생 ##함을 보여 ##주 ##었다. 본 연구에서는 정 ##사 ##각 ##형 ##단 ##면 ##을 갖는 180 곡 ##관 ##내 유 ##체의 속 ##도 ##분포 ##특성을 고 ##찰 하 ##기 위하여 먼저 Chang 등 ##[ ##14 ##] ##이 수행 ##한 연구 ##결과 ##와 비교 ##를 통해 수 ##치 ##해석 난 ##류 ##모델 ##에 대한 타 ##당 ##성 검증 ##을 수행 ##한 후 곡 ##관 ##내 ##의 작 ##동 ##유 ##체 ##, 입 ##구 ##속 ##도, 표면 ##조 ##도, 곡 ##률 반 ##경 ##, 수 ##력 ##직 ##경 등의 유 ##동 ##인 ##자 ##에 따른 속 ##도 ##분포 ##특성을 분석 ##하고, 곡 ##관 ##후 ##류 ##에 연결 ##된 직 ##관 ##내 ##의 유 ##체 ##속 ##도 ##특성 ##의 결과를 토 ##대로 유 ##량 ##계 ##측 ##에 유 ##효 ##한 직 ##관 ##거 ##리의 위치 ##를 제시 ##하는데 있다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 19:134 20:134 21:134 22:134 23:134 24:135 25:135 26:135 27:136 28:136 29:137 30:137 31:137 32:137 33:138 34:138 35:139 36:140 37:141 38:141 39:141 40:141 41:141 42:142 43:142 44:142 45:142 46:143 47:143 48:144 49:145 50:145 51:146 52:146 53:146 54:147 55:147 56:148 57:148 58:148 59:148 60:148 61:148 62:149 63:149 64:149 65:149 66:150 67:151 68:151 69:152 70:153 71:153 72:153 73:154 74:154 75:154 76:155 77:156 78:156 79:156 80:157 81:157 82:157 83:157 84:158 85:158 86:158 87:159 88:159 89:159 90:160 91:160 92:160 93:161 94:161 95:161 96:161 97:161 98:162 99:162 100:162 101:163 102:164 103:164 104:164 105:164 106:164 107:164 108:165 109:165 110:165 111:165 112:165 113:166 114:166 115:166 116:166 117:167 118:168 119:169 120:169 121:170 122:170 123:170 124:171 125:172 126:172 127:172 128:172 129:173 130:173 131:173 132:174 133:174 134:174 135:175 136:175 137:175 138:175 139:176 140:176 141:177 142:177 143:178 144:178 145:178 146:178 147:178 148:178 149:179 150:179 151:179 152:179 153:180 154:181 155:181 156:182 157:182 158:182 159:183 160:184 161:184 162:185 163:185 164:185 165:185 166:185 167:185 168:186 169:187 170:187 171:188 172:188 173:188 174:189 175:189 176:189 177:190 178:190 179:190 180:190 181:191 182:191 183:192 184:192 185:192 186:192 187:193 188:193 189:194 190:194 191:195 192:196 193:196 194:196 195:196 196:197 197:197 198:198 199:199 200:199 201:199 202:199 203:200 204:201 205:202 206:202 207:203 208:203 209:203 210:203 211:204 212:204 213:204 214:205 215:206 216:206 217:206 218:207 219:207 220:207 221:207 222:208 223:208 224:208 225:208 226:208 227:209 228:209 229:209 230:209 231:210 232:210 233:211 234:211 235:212 236:212 237:212 238:213 239:213 240:214 241:214 242:214 243:215 244:215 245:215 246:215 247:215 248:216 249:217 250:217 251:218 252:218 253:218 254:219 255:220 256:220 257:220 258:221 259:221 260:221 261:222 262:222 263:223 264:223 265:224 266:224 267:225 268:225 269:225 270:225 271:226 272:226 273:226 274:226 275:226 276:226 277:226 278:227 279:227 280:227 281:227 282:227 283:227 284:228 285:229 286:229 287:229 288:230 289:230 290:230 291:230 292:230 293:231 294:232 295:232 296:232 297:232 298:232 299:233 300:233 301:234 302:234 303:235 304:235 305:236 306:237 307:237 308:238 309:238 310:238 311:238 312:238 313:239 314:239 315:239 316:239 317:240 318:240 319:240 320:240 321:241 322:242 323:242 324:242 325:243 326:243 327:244 328:244 329:244 330:245 331:246 332:247 333:247 334:247 335:247 336:247 337:247 338:247 339:248 340:249 341:250 342:250 343:250 344:251 345:251 346:252 347:252 348:252 349:252 350:253 351:253 352:254 353:254 354:255 355:256 356:257 357:258 358:258 359:258 360:258 361:258 362:259 363:259 364:260 365:260 366:260 367:261 368:261 369:262 370:263 371:263 372:263 373:264 374:264 375:264 376:264 377:265 378:266 379:266 380:266 381:267 382:267 383:268 384:268 385:269 386:270 387:270 388:270 389:270 390:271 391:271 392:271 393:271 394:271 395:272 396:272 397:272 398:272 399:273 400:273 401:273 402:274 403:274 404:275 405:275 406:275 407:276 408:276 409:276 410:276 411:277 412:278 413:278 414:278 415:278 416:278 417:279 418:280 419:280 420:280 421:280 422:281 423:281 424:282 425:282 426:282 427:282 428:282 429:283 430:283 431:284 432:284 433:284 434:284 435:285 436:285 437:285 438:285 439:285 440:285 441:286 442:287 443:287 444:288 445:288 446:288 447:288 448:288 449:289 450:289 451:289 452:290 453:290 454:290 455:290 456:291 457:291 458:292 459:292 460:293\n",
      "I1125 11:12:38.439551 47903194205696 run_squad.py:406] token_to_orig_map: 19:134 20:134 21:134 22:134 23:134 24:135 25:135 26:135 27:136 28:136 29:137 30:137 31:137 32:137 33:138 34:138 35:139 36:140 37:141 38:141 39:141 40:141 41:141 42:142 43:142 44:142 45:142 46:143 47:143 48:144 49:145 50:145 51:146 52:146 53:146 54:147 55:147 56:148 57:148 58:148 59:148 60:148 61:148 62:149 63:149 64:149 65:149 66:150 67:151 68:151 69:152 70:153 71:153 72:153 73:154 74:154 75:154 76:155 77:156 78:156 79:156 80:157 81:157 82:157 83:157 84:158 85:158 86:158 87:159 88:159 89:159 90:160 91:160 92:160 93:161 94:161 95:161 96:161 97:161 98:162 99:162 100:162 101:163 102:164 103:164 104:164 105:164 106:164 107:164 108:165 109:165 110:165 111:165 112:165 113:166 114:166 115:166 116:166 117:167 118:168 119:169 120:169 121:170 122:170 123:170 124:171 125:172 126:172 127:172 128:172 129:173 130:173 131:173 132:174 133:174 134:174 135:175 136:175 137:175 138:175 139:176 140:176 141:177 142:177 143:178 144:178 145:178 146:178 147:178 148:178 149:179 150:179 151:179 152:179 153:180 154:181 155:181 156:182 157:182 158:182 159:183 160:184 161:184 162:185 163:185 164:185 165:185 166:185 167:185 168:186 169:187 170:187 171:188 172:188 173:188 174:189 175:189 176:189 177:190 178:190 179:190 180:190 181:191 182:191 183:192 184:192 185:192 186:192 187:193 188:193 189:194 190:194 191:195 192:196 193:196 194:196 195:196 196:197 197:197 198:198 199:199 200:199 201:199 202:199 203:200 204:201 205:202 206:202 207:203 208:203 209:203 210:203 211:204 212:204 213:204 214:205 215:206 216:206 217:206 218:207 219:207 220:207 221:207 222:208 223:208 224:208 225:208 226:208 227:209 228:209 229:209 230:209 231:210 232:210 233:211 234:211 235:212 236:212 237:212 238:213 239:213 240:214 241:214 242:214 243:215 244:215 245:215 246:215 247:215 248:216 249:217 250:217 251:218 252:218 253:218 254:219 255:220 256:220 257:220 258:221 259:221 260:221 261:222 262:222 263:223 264:223 265:224 266:224 267:225 268:225 269:225 270:225 271:226 272:226 273:226 274:226 275:226 276:226 277:226 278:227 279:227 280:227 281:227 282:227 283:227 284:228 285:229 286:229 287:229 288:230 289:230 290:230 291:230 292:230 293:231 294:232 295:232 296:232 297:232 298:232 299:233 300:233 301:234 302:234 303:235 304:235 305:236 306:237 307:237 308:238 309:238 310:238 311:238 312:238 313:239 314:239 315:239 316:239 317:240 318:240 319:240 320:240 321:241 322:242 323:242 324:242 325:243 326:243 327:244 328:244 329:244 330:245 331:246 332:247 333:247 334:247 335:247 336:247 337:247 338:247 339:248 340:249 341:250 342:250 343:250 344:251 345:251 346:252 347:252 348:252 349:252 350:253 351:253 352:254 353:254 354:255 355:256 356:257 357:258 358:258 359:258 360:258 361:258 362:259 363:259 364:260 365:260 366:260 367:261 368:261 369:262 370:263 371:263 372:263 373:264 374:264 375:264 376:264 377:265 378:266 379:266 380:266 381:267 382:267 383:268 384:268 385:269 386:270 387:270 388:270 389:270 390:271 391:271 392:271 393:271 394:271 395:272 396:272 397:272 398:272 399:273 400:273 401:273 402:274 403:274 404:275 405:275 406:275 407:276 408:276 409:276 410:276 411:277 412:278 413:278 414:278 415:278 416:278 417:279 418:280 419:280 420:280 421:280 422:281 423:281 424:282 425:282 426:282 427:282 428:282 429:283 430:283 431:284 432:284 433:284 434:284 435:285 436:285 437:285 438:285 439:285 440:285 441:286 442:287 443:287 444:288 445:288 446:288 447:288 448:288 449:289 450:289 451:289 452:290 453:290 454:290 455:290 456:291 457:291 458:292 459:292 460:293\n",
      "INFO:tensorflow:token_is_max_context: 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True\n",
      "I1125 11:12:38.439734 47903194205696 run_squad.py:408] token_is_max_context: 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True\n",
      "INFO:tensorflow:input_ids: 101 8889 20595 31605 10459 9625 18778 120120 10892 55910 119787 119820 11489 9636 96404 120015 11287 110871 102 13241 110873 11373 110875 10459 119569 119712 12638 119572 13374 9460 18622 120120 10459 119759 10622 119978 12006 9121 110873 20305 110875 10892 9670 12945 66540 27506 9059 14867 13912 8889 20595 9075 15184 11261 119571 13441 9075 15184 58303 17196 120118 11489 149 11490 11779 11513 119593 9766 119996 9316 10001 119996 10459 119656 120121 10530 110463 9766 119996 10459 9449 12092 120150 12638 9625 18778 120305 8888 99118 119773 30120 10240 11882 50690 110873 37115 110875 10892 9670 42337 27506 13912 8889 20595 118782 15184 31605 11489 8896 12310 42815 18778 120682 9612 71013 28143 10530 119610 58088 119569 17022 8922 16758 22440 19905 149 11490 11779 11261 8887 119281 13374 83243 62674 77261 9460 18622 120120 11882 119572 11102 85533 11261 9766 119996 43962 12092 120150 11018 9612 71013 28143 10459 58088 9322 59724 119723 16323 119664 19789 16204 12638 13810 12804 110873 24747 110875 11018 30085 119652 10459 8889 20595 10622 119615 80174 13374 9186 10739 118744 24891 9460 11513 10709 110862 77802 11467 120112 17594 119564 11102 10003 9449 12092 120150 110862 9590 46520 9316 9460 28143 119053 31503 119568 28697 9978 33654 9460 18622 120120 17022 8888 99118 13374 103995 9323 89851 13441 8984 46520 120118 10892 8889 20595 31531 46520 92515 9707 20595 41521 26344 10533 76036 66982 10739 119629 32679 11664 119835 119563 41845 16497 12638 22070 10230 110873 45389 110875 9632 9562 30005 122 21789 12638 19709 9926 14867 11467 8881 33188 13441 123 32501 9562 30005 9952 46520 9707 20595 41521 12692 149 110865 11490 110869 37462 12508 120102 9757 32158 46150 42815 44321 54163 119843 119569 119956 10622 9186 10739 118744 24891 15891 10258 13057 110862 77802 120178 11261 119734 13374 9625 44321 119569 10622 9954 85533 11261 9186 10739 118744 24891 15891 125 110862 77802 11489 99405 28188 23466 11287 124 125 110855 11287 119568 120064 119723 16323 119664 9358 119618 9670 12945 66540 27506 24989 14867 10622 120021 13912 8889 20595 31605 9625 79025 9449 12092 120150 120305 8888 99118 9952 12310 68010 104304 28545 9121 110873 39900 110875 10739 119570 11102 91785 119712 12638 119572 11513 25605 9460 18622 120120 8984 46520 120069 10530 18154 9845 21928 17138 119743 10622 119570 11102 10003 8889 20595 31605 10459 9652 18778 42815 29683 110862 9645 17196 43962 119768 119867 20626 119768 8889 88350 9321 31720 110862 9460 28143 33077 31720 28697 9625 18778 12030 13764 10530 110463 9449 12092 120150 120305 119552 119604 8889 20595 31531 46520 10530 119830 13441 9707 20595 31605 10459 9625 29683 43962 12092 120132 10459 119639 9873 37601 9625 44321 21611 119281 10530 9625 119449 11102 9707 20595 41521 50053 119656 11513 119591 119885 119547 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.441047 47903194205696 run_squad.py:410] input_ids: 101 8889 20595 31605 10459 9625 18778 120120 10892 55910 119787 119820 11489 9636 96404 120015 11287 110871 102 13241 110873 11373 110875 10459 119569 119712 12638 119572 13374 9460 18622 120120 10459 119759 10622 119978 12006 9121 110873 20305 110875 10892 9670 12945 66540 27506 9059 14867 13912 8889 20595 9075 15184 11261 119571 13441 9075 15184 58303 17196 120118 11489 149 11490 11779 11513 119593 9766 119996 9316 10001 119996 10459 119656 120121 10530 110463 9766 119996 10459 9449 12092 120150 12638 9625 18778 120305 8888 99118 119773 30120 10240 11882 50690 110873 37115 110875 10892 9670 42337 27506 13912 8889 20595 118782 15184 31605 11489 8896 12310 42815 18778 120682 9612 71013 28143 10530 119610 58088 119569 17022 8922 16758 22440 19905 149 11490 11779 11261 8887 119281 13374 83243 62674 77261 9460 18622 120120 11882 119572 11102 85533 11261 9766 119996 43962 12092 120150 11018 9612 71013 28143 10459 58088 9322 59724 119723 16323 119664 19789 16204 12638 13810 12804 110873 24747 110875 11018 30085 119652 10459 8889 20595 10622 119615 80174 13374 9186 10739 118744 24891 9460 11513 10709 110862 77802 11467 120112 17594 119564 11102 10003 9449 12092 120150 110862 9590 46520 9316 9460 28143 119053 31503 119568 28697 9978 33654 9460 18622 120120 17022 8888 99118 13374 103995 9323 89851 13441 8984 46520 120118 10892 8889 20595 31531 46520 92515 9707 20595 41521 26344 10533 76036 66982 10739 119629 32679 11664 119835 119563 41845 16497 12638 22070 10230 110873 45389 110875 9632 9562 30005 122 21789 12638 19709 9926 14867 11467 8881 33188 13441 123 32501 9562 30005 9952 46520 9707 20595 41521 12692 149 110865 11490 110869 37462 12508 120102 9757 32158 46150 42815 44321 54163 119843 119569 119956 10622 9186 10739 118744 24891 15891 10258 13057 110862 77802 120178 11261 119734 13374 9625 44321 119569 10622 9954 85533 11261 9186 10739 118744 24891 15891 125 110862 77802 11489 99405 28188 23466 11287 124 125 110855 11287 119568 120064 119723 16323 119664 9358 119618 9670 12945 66540 27506 24989 14867 10622 120021 13912 8889 20595 31605 9625 79025 9449 12092 120150 120305 8888 99118 9952 12310 68010 104304 28545 9121 110873 39900 110875 10739 119570 11102 91785 119712 12638 119572 11513 25605 9460 18622 120120 8984 46520 120069 10530 18154 9845 21928 17138 119743 10622 119570 11102 10003 8889 20595 31605 10459 9652 18778 42815 29683 110862 9645 17196 43962 119768 119867 20626 119768 8889 88350 9321 31720 110862 9460 28143 33077 31720 28697 9625 18778 12030 13764 10530 110463 9449 12092 120150 120305 119552 119604 8889 20595 31531 46520 10530 119830 13441 9707 20595 31605 10459 9625 29683 43962 12092 120132 10459 119639 9873 37601 9625 44321 21611 119281 10530 9625 119449 11102 9707 20595 41521 50053 119656 11513 119591 119885 119547 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.441214 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.441361 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.446781 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000020\n",
      "I1125 11:12:38.446896 47903194205696 run_squad.py:400] unique_id: 1000000020\n",
      "INFO:tensorflow:example_index: 15\n",
      "I1125 11:12:38.446962 47903194205696 run_squad.py:401] example_index: 15\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.447014 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 곡 ##관 내 ##의 유 ##동 ##특성을 파악 ##하기 위해서는 어떤 파 ##라 ##미 ##터 ##가 필요한 ##가 ##? [SEP] 본 연구는 정 ##사 ##각 ##형 단 ##면 $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ 곡 ##관 내 ##의 유 ##동 ##특성을 파악 ##하기 위해 RS ##M 난 ##류 ##모델 ##을 이용하여 작 ##동 ##유 ##체 ##, 입 ##구의 공 ##기 ##속 ##도, 관 ##내 ##의 표면 ##조 ##도, 곡 ##률 ##반 ##경 및 수 ##력 ##직 ##경 등의 다양한 유 ##동 ##인 ##자를 변경 ##하여 각 ##도 위치 ##별 속 ##도 ##분포 ##특성을 수 ##치 ##해석 ##을 통하여 고 ##찰 ##하였다. CF ##D 해석 ##시 경 ##계 ##조건 ##은 공 ##기 ##와 물 ##의 입 ##구 ##온 ##도를 288 K ##, 293 K ##로 설정 ##하였고, 입 ##구의 공 ##기 ##속 ##도, 관 ##내 ##의 표면 ##조 ##도, 곡 ##률 ##반 ##경 및 수 ##력 ##직 ##경 ##은 각각 3 ##~ ##15 m ##/ ##s, 0 ##~ ##0. ##00 ##1 mm ##, 2. ##5 ##~ ##4. ##5 ##D ##, 70 ##~ ##100 mm ##로 적용 ##하여 해석 ##을 수행 ##하였다. 그 결과를 정 ##리 ##하면 ##, 작 ##동 ##유 ##체의 유 ##동 ##특성 ##은 유 ##체의 점 ##성 ##력 차이 ##로 속 ##도 ##분포 ##가 크게 달 ##라 ##짐 ##을 알 수 있었 ##고, 곡 ##관 ##부 내 ##에서의 최대 속 ##도 ##프로 ##파 ##일 ##은 $ ##90 ##^ ##{ ##\\ ##cir ##c ##} ##$ 단 ##면 ##위치 ##에서 X ##/ ##D ##= ##0. ##8 영역 ##으로 나타났 ##으며, $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ 단 ##면 ##위치 ##에서는 Y ##/ ##D ##= ##0. ##8 영역 ##으로 나타났다. 그리고 관 ##내 ##의 표면 ##조 ##도가 낮 ##고, 곡 ##률 ##반 ##경 ##이 클 ##수록 속 ##도 ##변화 ##율 ##은 크게 변 ##하여 나타 ##냈다 ##. 또한 곡 ##관 ##후 ##류의 직 ##관 ##부에 ##서 유 ##동 ##편 ##차 ##가 안정 ##화 ##되는 직 ##관 ##거 ##리는 L ##/ ##D ##= ##30 영역 ##에서 나타내 ##어 유 ##량 계 ##측 ##시 유 ##효 ##한 측정 ##위치 ##로 잘 제시 ##할 수 있었 ##으며, 수 ##력 ##직 ##경 ##에 따라 곡 ##관 ##후 ##류 직 ##관 ##부의 표준 ##편 ##차 ##특성 ##은 동일한 유 ##속 ##일 때 최소 ##의 편 ##차 ##영역 ##은 대 ##체 ##로 직 ##관 ##거 ##리 L ##/ ##D ##= ##15 ##~ ##30 범위 ##로 나타났다. This study numeri ##cally analy ##zes the characteristics of the velocity distribution for each location of a square ##- ##sect ##ional $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ bent duc ##t using a Reynolds St ##ress Tur ##bul ##ent model ##. The flow parameters were varied ##, including the working fluid ##s, in ##let velocity ##, surface rough ##ness ##, radius of curva ##ture ##, and hyd ##rau ##lic diameter ##. The boundary conditions for comp ##utati ##onal fluid dynamics analysis were in ##let temperatures of air and water of 288 K and 293 K ##, in ##let air velocity of 3 ##-15 m ##/ ##s, inner surface rough ##ness of [SEP]\n",
      "I1125 11:12:38.447191 47903194205696 run_squad.py:404] tokens: [CLS] 곡 ##관 내 ##의 유 ##동 ##특성을 파악 ##하기 위해서는 어떤 파 ##라 ##미 ##터 ##가 필요한 ##가 ##? [SEP] 본 연구는 정 ##사 ##각 ##형 단 ##면 $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ 곡 ##관 내 ##의 유 ##동 ##특성을 파악 ##하기 위해 RS ##M 난 ##류 ##모델 ##을 이용하여 작 ##동 ##유 ##체 ##, 입 ##구의 공 ##기 ##속 ##도, 관 ##내 ##의 표면 ##조 ##도, 곡 ##률 ##반 ##경 및 수 ##력 ##직 ##경 등의 다양한 유 ##동 ##인 ##자를 변경 ##하여 각 ##도 위치 ##별 속 ##도 ##분포 ##특성을 수 ##치 ##해석 ##을 통하여 고 ##찰 ##하였다. CF ##D 해석 ##시 경 ##계 ##조건 ##은 공 ##기 ##와 물 ##의 입 ##구 ##온 ##도를 288 K ##, 293 K ##로 설정 ##하였고, 입 ##구의 공 ##기 ##속 ##도, 관 ##내 ##의 표면 ##조 ##도, 곡 ##률 ##반 ##경 및 수 ##력 ##직 ##경 ##은 각각 3 ##~ ##15 m ##/ ##s, 0 ##~ ##0. ##00 ##1 mm ##, 2. ##5 ##~ ##4. ##5 ##D ##, 70 ##~ ##100 mm ##로 적용 ##하여 해석 ##을 수행 ##하였다. 그 결과를 정 ##리 ##하면 ##, 작 ##동 ##유 ##체의 유 ##동 ##특성 ##은 유 ##체의 점 ##성 ##력 차이 ##로 속 ##도 ##분포 ##가 크게 달 ##라 ##짐 ##을 알 수 있었 ##고, 곡 ##관 ##부 내 ##에서의 최대 속 ##도 ##프로 ##파 ##일 ##은 $ ##90 ##^ ##{ ##\\ ##cir ##c ##} ##$ 단 ##면 ##위치 ##에서 X ##/ ##D ##= ##0. ##8 영역 ##으로 나타났 ##으며, $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ 단 ##면 ##위치 ##에서는 Y ##/ ##D ##= ##0. ##8 영역 ##으로 나타났다. 그리고 관 ##내 ##의 표면 ##조 ##도가 낮 ##고, 곡 ##률 ##반 ##경 ##이 클 ##수록 속 ##도 ##변화 ##율 ##은 크게 변 ##하여 나타 ##냈다 ##. 또한 곡 ##관 ##후 ##류의 직 ##관 ##부에 ##서 유 ##동 ##편 ##차 ##가 안정 ##화 ##되는 직 ##관 ##거 ##리는 L ##/ ##D ##= ##30 영역 ##에서 나타내 ##어 유 ##량 계 ##측 ##시 유 ##효 ##한 측정 ##위치 ##로 잘 제시 ##할 수 있었 ##으며, 수 ##력 ##직 ##경 ##에 따라 곡 ##관 ##후 ##류 직 ##관 ##부의 표준 ##편 ##차 ##특성 ##은 동일한 유 ##속 ##일 때 최소 ##의 편 ##차 ##영역 ##은 대 ##체 ##로 직 ##관 ##거 ##리 L ##/ ##D ##= ##15 ##~ ##30 범위 ##로 나타났다. This study numeri ##cally analy ##zes the characteristics of the velocity distribution for each location of a square ##- ##sect ##ional $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ bent duc ##t using a Reynolds St ##ress Tur ##bul ##ent model ##. The flow parameters were varied ##, including the working fluid ##s, in ##let velocity ##, surface rough ##ness ##, radius of curva ##ture ##, and hyd ##rau ##lic diameter ##. The boundary conditions for comp ##utati ##onal fluid dynamics analysis were in ##let temperatures of air and water of 288 K and 293 K ##, in ##let air velocity of 3 ##-15 m ##/ ##s, inner surface rough ##ness of [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 21:0 22:1 23:2 24:2 25:2 26:2 27:3 28:3 29:4 30:4 31:4 32:4 33:4 34:4 35:4 36:4 37:4 38:4 39:5 40:5 41:6 42:6 43:7 44:7 45:7 46:8 47:8 48:9 49:10 50:10 51:11 52:11 53:11 54:11 55:12 56:13 57:13 58:13 59:13 60:13 61:14 62:14 63:15 64:15 65:15 66:15 67:16 68:16 69:16 70:17 71:17 72:17 73:18 74:18 75:18 76:18 77:19 78:20 79:20 80:20 81:20 82:21 83:22 84:23 85:23 86:23 87:23 88:24 89:24 90:25 91:25 92:26 93:26 94:27 95:27 96:27 97:27 98:28 99:28 100:28 101:28 102:29 103:30 104:30 105:30 106:31 107:31 108:32 109:32 110:33 111:33 112:33 113:33 114:34 115:34 116:34 117:35 118:35 119:36 120:36 121:36 122:36 123:37 124:38 125:38 126:39 127:40 128:40 129:41 130:41 131:42 132:42 133:43 134:43 135:43 136:43 137:44 138:44 139:44 140:45 141:45 142:45 143:46 144:46 145:46 146:46 147:47 148:48 149:48 150:48 151:48 152:48 153:49 154:50 155:50 156:50 157:51 158:51 159:51 160:52 161:52 162:52 163:52 164:52 165:53 166:53 167:54 168:54 169:54 170:54 171:54 172:54 173:54 174:55 175:55 176:55 177:56 178:56 179:57 180:57 181:58 182:58 183:59 184:59 185:60 186:61 187:62 188:62 189:62 190:62 191:63 192:63 193:63 194:63 195:64 196:64 197:64 198:64 199:65 200:65 201:66 202:66 203:66 204:67 205:67 206:68 207:68 208:68 209:68 210:69 211:70 212:70 213:70 214:70 215:71 216:72 217:73 218:73 219:74 220:74 221:74 222:75 223:75 224:76 225:77 226:77 227:77 228:77 229:77 230:77 231:78 232:78 233:78 234:78 235:78 236:78 237:78 238:78 239:78 240:79 241:79 242:79 243:79 244:80 245:80 246:80 247:80 248:80 249:80 250:81 251:81 252:82 253:82 254:83 255:83 256:83 257:83 258:83 259:83 260:83 261:83 262:83 263:83 264:84 265:84 266:84 267:84 268:85 269:85 270:85 271:85 272:85 273:85 274:86 275:86 276:87 277:88 278:89 279:89 280:89 281:90 282:90 283:90 284:91 285:91 286:92 287:92 288:92 289:92 290:92 291:93 292:93 293:94 294:94 295:94 296:94 297:94 298:95 299:96 300:96 301:97 302:97 303:97 304:98 305:99 306:99 307:99 308:99 309:100 310:100 311:100 312:100 313:101 314:101 315:101 316:101 317:101 318:102 319:102 320:102 321:103 322:103 323:103 324:103 325:104 326:104 327:104 328:104 329:104 330:105 331:105 332:106 333:106 334:107 335:107 336:108 337:108 338:108 339:109 340:109 341:109 342:110 343:110 344:110 345:111 346:112 347:112 348:113 349:114 350:114 351:115 352:115 353:115 354:115 355:115 356:116 357:117 358:117 359:117 360:117 361:118 362:118 363:118 364:119 365:119 366:119 367:119 368:119 369:120 370:121 371:121 372:121 373:122 374:123 375:123 376:124 377:124 378:124 379:124 380:125 381:125 382:125 383:126 384:126 385:126 386:126 387:127 388:127 389:127 390:127 391:127 392:127 393:127 394:128 395:128 396:129 397:130 398:131 399:132 400:132 401:133 402:133 403:134 404:135 405:136 406:137 407:138 408:139 409:140 410:141 411:142 412:143 413:144 414:145 415:145 416:145 417:145 418:146 419:146 420:146 421:146 422:146 423:146 424:146 425:146 426:146 427:146 428:147 429:148 430:148 431:149 432:150 433:151 434:152 435:152 436:153 437:153 438:153 439:154 440:154 441:155 442:156 443:157 444:158 445:159 446:159 447:160 448:161 449:162 450:163 451:163 452:164 453:164 454:165 455:165 456:166 457:167 458:167 459:167 460:168 461:169 462:170 463:170 464:170 465:171 466:172 467:172 468:172 469:173 470:173 471:174 472:175 473:176 474:177 475:178 476:178 477:178 478:179 479:180 480:181 481:182 482:183 483:183 484:184 485:185 486:186 487:187 488:188 489:189 490:190 491:191 492:192 493:193 494:194 495:194 496:195 497:195 498:196 499:197 500:198 501:199 502:199 503:200 504:200 505:200 506:201 507:202 508:203 509:203 510:204\n",
      "I1125 11:12:38.447419 47903194205696 run_squad.py:406] token_to_orig_map: 21:0 22:1 23:2 24:2 25:2 26:2 27:3 28:3 29:4 30:4 31:4 32:4 33:4 34:4 35:4 36:4 37:4 38:4 39:5 40:5 41:6 42:6 43:7 44:7 45:7 46:8 47:8 48:9 49:10 50:10 51:11 52:11 53:11 54:11 55:12 56:13 57:13 58:13 59:13 60:13 61:14 62:14 63:15 64:15 65:15 66:15 67:16 68:16 69:16 70:17 71:17 72:17 73:18 74:18 75:18 76:18 77:19 78:20 79:20 80:20 81:20 82:21 83:22 84:23 85:23 86:23 87:23 88:24 89:24 90:25 91:25 92:26 93:26 94:27 95:27 96:27 97:27 98:28 99:28 100:28 101:28 102:29 103:30 104:30 105:30 106:31 107:31 108:32 109:32 110:33 111:33 112:33 113:33 114:34 115:34 116:34 117:35 118:35 119:36 120:36 121:36 122:36 123:37 124:38 125:38 126:39 127:40 128:40 129:41 130:41 131:42 132:42 133:43 134:43 135:43 136:43 137:44 138:44 139:44 140:45 141:45 142:45 143:46 144:46 145:46 146:46 147:47 148:48 149:48 150:48 151:48 152:48 153:49 154:50 155:50 156:50 157:51 158:51 159:51 160:52 161:52 162:52 163:52 164:52 165:53 166:53 167:54 168:54 169:54 170:54 171:54 172:54 173:54 174:55 175:55 176:55 177:56 178:56 179:57 180:57 181:58 182:58 183:59 184:59 185:60 186:61 187:62 188:62 189:62 190:62 191:63 192:63 193:63 194:63 195:64 196:64 197:64 198:64 199:65 200:65 201:66 202:66 203:66 204:67 205:67 206:68 207:68 208:68 209:68 210:69 211:70 212:70 213:70 214:70 215:71 216:72 217:73 218:73 219:74 220:74 221:74 222:75 223:75 224:76 225:77 226:77 227:77 228:77 229:77 230:77 231:78 232:78 233:78 234:78 235:78 236:78 237:78 238:78 239:78 240:79 241:79 242:79 243:79 244:80 245:80 246:80 247:80 248:80 249:80 250:81 251:81 252:82 253:82 254:83 255:83 256:83 257:83 258:83 259:83 260:83 261:83 262:83 263:83 264:84 265:84 266:84 267:84 268:85 269:85 270:85 271:85 272:85 273:85 274:86 275:86 276:87 277:88 278:89 279:89 280:89 281:90 282:90 283:90 284:91 285:91 286:92 287:92 288:92 289:92 290:92 291:93 292:93 293:94 294:94 295:94 296:94 297:94 298:95 299:96 300:96 301:97 302:97 303:97 304:98 305:99 306:99 307:99 308:99 309:100 310:100 311:100 312:100 313:101 314:101 315:101 316:101 317:101 318:102 319:102 320:102 321:103 322:103 323:103 324:103 325:104 326:104 327:104 328:104 329:104 330:105 331:105 332:106 333:106 334:107 335:107 336:108 337:108 338:108 339:109 340:109 341:109 342:110 343:110 344:110 345:111 346:112 347:112 348:113 349:114 350:114 351:115 352:115 353:115 354:115 355:115 356:116 357:117 358:117 359:117 360:117 361:118 362:118 363:118 364:119 365:119 366:119 367:119 368:119 369:120 370:121 371:121 372:121 373:122 374:123 375:123 376:124 377:124 378:124 379:124 380:125 381:125 382:125 383:126 384:126 385:126 386:126 387:127 388:127 389:127 390:127 391:127 392:127 393:127 394:128 395:128 396:129 397:130 398:131 399:132 400:132 401:133 402:133 403:134 404:135 405:136 406:137 407:138 408:139 409:140 410:141 411:142 412:143 413:144 414:145 415:145 416:145 417:145 418:146 419:146 420:146 421:146 422:146 423:146 424:146 425:146 426:146 427:146 428:147 429:148 430:148 431:149 432:150 433:151 434:152 435:152 436:153 437:153 438:153 439:154 440:154 441:155 442:156 443:157 444:158 445:159 446:159 447:160 448:161 449:162 450:163 451:163 452:164 453:164 454:165 455:165 456:166 457:167 458:167 459:167 460:168 461:169 462:170 463:170 464:170 465:171 466:172 467:172 468:172 469:173 470:173 471:174 472:175 473:176 474:177 475:178 476:178 477:178 478:179 479:180 480:181 481:182 482:183 483:183 484:184 485:185 486:186 487:187 488:188 489:189 490:190 491:191 492:192 493:193 494:194 495:194 496:195 497:195 498:196 499:197 500:198 501:199 502:199 503:200 504:200 505:200 506:201 507:202 508:203 509:203 510:204\n",
      "INFO:tensorflow:token_is_max_context: 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "I1125 11:12:38.447621 47903194205696 run_squad.py:408] token_is_max_context: 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "INFO:tensorflow:input_ids: 101 8889 20595 8996 10459 9625 18778 120305 119720 22440 119770 55910 9901 17342 22458 21876 11287 119873 11287 110871 102 9358 119634 9670 12945 66540 27506 9059 14867 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 8889 20595 8996 10459 9625 18778 120305 119720 22440 19905 33000 11517 8984 46520 120069 10622 119593 9652 18778 42815 29683 110862 9645 86145 8896 12310 43962 119768 8900 31605 10459 119867 20626 119768 8889 88350 30134 31720 9316 9460 28143 33077 31720 28697 53645 9625 18778 12030 48959 60839 13374 8844 12092 119656 61844 9449 12092 120150 120305 9460 18622 120120 10622 119834 8888 99118 119548 29551 11490 119700 14040 8885 21611 119956 10892 8896 12310 12638 9299 10459 9645 17196 37093 52602 27401 148 110862 30435 148 11261 119734 119773 9645 86145 8896 12310 43962 119768 8900 31605 10459 119867 20626 119768 8889 88350 30134 31720 9316 9460 28143 33077 31720 10892 63042 124 110881 37462 181 110865 119839 121 110881 119677 21069 10759 10366 110862 119616 11166 110881 119619 11166 11490 110862 10923 110881 49025 10366 11261 119564 13374 119700 10622 119570 119548 8924 119639 9670 12692 38378 110862 9652 18778 42815 79025 9625 18778 120132 10892 9625 79025 9668 17138 28143 120133 11261 9449 12092 120150 11287 62548 9061 17342 119231 10622 9524 9460 119815 119563 8889 20595 14646 8996 119650 99405 9449 12092 120281 46150 18392 10892 109 61400 110876 110878 110874 45455 10350 110880 110854 9059 14867 120245 11489 161 110865 11490 110869 119677 11396 119663 11467 119660 119579 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 9059 14867 120245 23635 162 110865 11490 110869 119677 11396 119663 11467 119588 23289 8900 31605 10459 119867 20626 68516 8992 119563 8889 88350 30134 31720 10739 9836 119766 9449 12092 120121 119183 10892 62548 9352 13374 119965 60209 110864 19789 8889 20595 31531 89267 9707 20595 52961 12424 9625 18778 50450 23466 11287 119877 18227 24683 9707 20595 41521 26344 149 110865 11490 110869 32792 119663 11489 119666 12965 9625 44321 8887 119281 14040 9625 119449 11102 119559 120245 11261 9654 119591 14843 9460 119815 119579 9460 28143 33077 31720 10530 22799 8889 20595 31531 46520 9707 20595 43875 119727 50450 23466 120132 10892 120082 9625 43962 18392 9137 119890 10459 9924 23466 120118 10892 9069 29683 11261 9707 20595 41521 12692 149 110865 11490 110869 37462 110881 32792 119851 11261 119588 10747 14687 67800 72762 119848 19579 10105 40582 10108 10105 84204 18477 10142 11948 18214 10108 169 15163 110863 104380 23748 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 122212 22620 10123 13382 169 30130 10838 30743 105549 50400 11405 13192 110864 10117 30676 88588 10309 79354 110862 11198 10105 14616 59848 119839 10106 12630 84204 110862 16004 87656 14010 110862 20212 10108 60594 16023 110862 10111 56888 40088 25303 31403 110864 10117 42584 17315 10142 119892 48177 21051 59848 95674 19129 10309 10106 12630 45091 10108 12566 10111 12286 10108 27401 148 10111 30435 148 110862 10106 12630 12566 84204 10108 124 120632 181 110865 119839 44615 16004 87656 14010 10108 102\n",
      "I1125 11:12:38.448739 47903194205696 run_squad.py:410] input_ids: 101 8889 20595 8996 10459 9625 18778 120305 119720 22440 119770 55910 9901 17342 22458 21876 11287 119873 11287 110871 102 9358 119634 9670 12945 66540 27506 9059 14867 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 8889 20595 8996 10459 9625 18778 120305 119720 22440 19905 33000 11517 8984 46520 120069 10622 119593 9652 18778 42815 29683 110862 9645 86145 8896 12310 43962 119768 8900 31605 10459 119867 20626 119768 8889 88350 30134 31720 9316 9460 28143 33077 31720 28697 53645 9625 18778 12030 48959 60839 13374 8844 12092 119656 61844 9449 12092 120150 120305 9460 18622 120120 10622 119834 8888 99118 119548 29551 11490 119700 14040 8885 21611 119956 10892 8896 12310 12638 9299 10459 9645 17196 37093 52602 27401 148 110862 30435 148 11261 119734 119773 9645 86145 8896 12310 43962 119768 8900 31605 10459 119867 20626 119768 8889 88350 30134 31720 9316 9460 28143 33077 31720 10892 63042 124 110881 37462 181 110865 119839 121 110881 119677 21069 10759 10366 110862 119616 11166 110881 119619 11166 11490 110862 10923 110881 49025 10366 11261 119564 13374 119700 10622 119570 119548 8924 119639 9670 12692 38378 110862 9652 18778 42815 79025 9625 18778 120132 10892 9625 79025 9668 17138 28143 120133 11261 9449 12092 120150 11287 62548 9061 17342 119231 10622 9524 9460 119815 119563 8889 20595 14646 8996 119650 99405 9449 12092 120281 46150 18392 10892 109 61400 110876 110878 110874 45455 10350 110880 110854 9059 14867 120245 11489 161 110865 11490 110869 119677 11396 119663 11467 119660 119579 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 9059 14867 120245 23635 162 110865 11490 110869 119677 11396 119663 11467 119588 23289 8900 31605 10459 119867 20626 68516 8992 119563 8889 88350 30134 31720 10739 9836 119766 9449 12092 120121 119183 10892 62548 9352 13374 119965 60209 110864 19789 8889 20595 31531 89267 9707 20595 52961 12424 9625 18778 50450 23466 11287 119877 18227 24683 9707 20595 41521 26344 149 110865 11490 110869 32792 119663 11489 119666 12965 9625 44321 8887 119281 14040 9625 119449 11102 119559 120245 11261 9654 119591 14843 9460 119815 119579 9460 28143 33077 31720 10530 22799 8889 20595 31531 46520 9707 20595 43875 119727 50450 23466 120132 10892 120082 9625 43962 18392 9137 119890 10459 9924 23466 120118 10892 9069 29683 11261 9707 20595 41521 12692 149 110865 11490 110869 37462 110881 32792 119851 11261 119588 10747 14687 67800 72762 119848 19579 10105 40582 10108 10105 84204 18477 10142 11948 18214 10108 169 15163 110863 104380 23748 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 122212 22620 10123 13382 169 30130 10838 30743 105549 50400 11405 13192 110864 10117 30676 88588 10309 79354 110862 11198 10105 14616 59848 119839 10106 12630 84204 110862 16004 87656 14010 110862 20212 10108 60594 16023 110862 10111 56888 40088 25303 31403 110864 10117 42584 17315 10142 119892 48177 21051 59848 95674 19129 10309 10106 12630 45091 10108 12566 10111 12286 10108 27401 148 10111 30435 148 110862 10106 12630 12566 84204 10108 124 120632 181 110865 119839 44615 16004 87656 14010 10108 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.448908 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.449963 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.451715 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000021\n",
      "I1125 11:12:38.451800 47903194205696 run_squad.py:400] unique_id: 1000000021\n",
      "INFO:tensorflow:example_index: 15\n",
      "I1125 11:12:38.451853 47903194205696 run_squad.py:401] example_index: 15\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "I1125 11:12:38.451900 47903194205696 run_squad.py:402] doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] 곡 ##관 내 ##의 유 ##동 ##특성을 파악 ##하기 위해서는 어떤 파 ##라 ##미 ##터 ##가 필요한 ##가 ##? [SEP] ##력 ##직 ##경 ##은 각각 3 ##~ ##15 m ##/ ##s, 0 ##~ ##0. ##00 ##1 mm ##, 2. ##5 ##~ ##4. ##5 ##D ##, 70 ##~ ##100 mm ##로 적용 ##하여 해석 ##을 수행 ##하였다. 그 결과를 정 ##리 ##하면 ##, 작 ##동 ##유 ##체의 유 ##동 ##특성 ##은 유 ##체의 점 ##성 ##력 차이 ##로 속 ##도 ##분포 ##가 크게 달 ##라 ##짐 ##을 알 수 있었 ##고, 곡 ##관 ##부 내 ##에서의 최대 속 ##도 ##프로 ##파 ##일 ##은 $ ##90 ##^ ##{ ##\\ ##cir ##c ##} ##$ 단 ##면 ##위치 ##에서 X ##/ ##D ##= ##0. ##8 영역 ##으로 나타났 ##으며, $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ 단 ##면 ##위치 ##에서는 Y ##/ ##D ##= ##0. ##8 영역 ##으로 나타났다. 그리고 관 ##내 ##의 표면 ##조 ##도가 낮 ##고, 곡 ##률 ##반 ##경 ##이 클 ##수록 속 ##도 ##변화 ##율 ##은 크게 변 ##하여 나타 ##냈다 ##. 또한 곡 ##관 ##후 ##류의 직 ##관 ##부에 ##서 유 ##동 ##편 ##차 ##가 안정 ##화 ##되는 직 ##관 ##거 ##리는 L ##/ ##D ##= ##30 영역 ##에서 나타내 ##어 유 ##량 계 ##측 ##시 유 ##효 ##한 측정 ##위치 ##로 잘 제시 ##할 수 있었 ##으며, 수 ##력 ##직 ##경 ##에 따라 곡 ##관 ##후 ##류 직 ##관 ##부의 표준 ##편 ##차 ##특성 ##은 동일한 유 ##속 ##일 때 최소 ##의 편 ##차 ##영역 ##은 대 ##체 ##로 직 ##관 ##거 ##리 L ##/ ##D ##= ##15 ##~ ##30 범위 ##로 나타났다. This study numeri ##cally analy ##zes the characteristics of the velocity distribution for each location of a square ##- ##sect ##ional $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ bent duc ##t using a Reynolds St ##ress Tur ##bul ##ent model ##. The flow parameters were varied ##, including the working fluid ##s, in ##let velocity ##, surface rough ##ness ##, radius of curva ##ture ##, and hyd ##rau ##lic diameter ##. The boundary conditions for comp ##utati ##onal fluid dynamics analysis were in ##let temperatures of air and water of 288 K and 293 K ##, in ##let air velocity of 3 ##-15 m ##/ ##s, inner surface rough ##ness of 0 ##- ##0. ##00 ##1 mm ##, radius of curva ##ture of 2. ##5 ##- ##4. ##5 D ##, and hyd ##rau ##lic diameter of 70 ##-100 mm ##. The working fluid characteristics were highly affected by changes in the vis ##cous force ##. The maximum velocity profile ##s in the bent duc ##t were indicated when the $ ##90 ##^ ##{ ##\\ ##cir ##c ##} ##$ section was in the region of X ##/ ##D ##= ##0. ##8 and the $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ section was in the region of Y ##/ ##D ##= ##0. ##8. Lower surface rough ##ness and higher radius of curva ##ture resulted in a higher rate of velocity change ##. Also ##, an efficient measuring location [SEP]\n",
      "I1125 11:12:38.452086 47903194205696 run_squad.py:404] tokens: [CLS] 곡 ##관 내 ##의 유 ##동 ##특성을 파악 ##하기 위해서는 어떤 파 ##라 ##미 ##터 ##가 필요한 ##가 ##? [SEP] ##력 ##직 ##경 ##은 각각 3 ##~ ##15 m ##/ ##s, 0 ##~ ##0. ##00 ##1 mm ##, 2. ##5 ##~ ##4. ##5 ##D ##, 70 ##~ ##100 mm ##로 적용 ##하여 해석 ##을 수행 ##하였다. 그 결과를 정 ##리 ##하면 ##, 작 ##동 ##유 ##체의 유 ##동 ##특성 ##은 유 ##체의 점 ##성 ##력 차이 ##로 속 ##도 ##분포 ##가 크게 달 ##라 ##짐 ##을 알 수 있었 ##고, 곡 ##관 ##부 내 ##에서의 최대 속 ##도 ##프로 ##파 ##일 ##은 $ ##90 ##^ ##{ ##\\ ##cir ##c ##} ##$ 단 ##면 ##위치 ##에서 X ##/ ##D ##= ##0. ##8 영역 ##으로 나타났 ##으며, $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ 단 ##면 ##위치 ##에서는 Y ##/ ##D ##= ##0. ##8 영역 ##으로 나타났다. 그리고 관 ##내 ##의 표면 ##조 ##도가 낮 ##고, 곡 ##률 ##반 ##경 ##이 클 ##수록 속 ##도 ##변화 ##율 ##은 크게 변 ##하여 나타 ##냈다 ##. 또한 곡 ##관 ##후 ##류의 직 ##관 ##부에 ##서 유 ##동 ##편 ##차 ##가 안정 ##화 ##되는 직 ##관 ##거 ##리는 L ##/ ##D ##= ##30 영역 ##에서 나타내 ##어 유 ##량 계 ##측 ##시 유 ##효 ##한 측정 ##위치 ##로 잘 제시 ##할 수 있었 ##으며, 수 ##력 ##직 ##경 ##에 따라 곡 ##관 ##후 ##류 직 ##관 ##부의 표준 ##편 ##차 ##특성 ##은 동일한 유 ##속 ##일 때 최소 ##의 편 ##차 ##영역 ##은 대 ##체 ##로 직 ##관 ##거 ##리 L ##/ ##D ##= ##15 ##~ ##30 범위 ##로 나타났다. This study numeri ##cally analy ##zes the characteristics of the velocity distribution for each location of a square ##- ##sect ##ional $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ bent duc ##t using a Reynolds St ##ress Tur ##bul ##ent model ##. The flow parameters were varied ##, including the working fluid ##s, in ##let velocity ##, surface rough ##ness ##, radius of curva ##ture ##, and hyd ##rau ##lic diameter ##. The boundary conditions for comp ##utati ##onal fluid dynamics analysis were in ##let temperatures of air and water of 288 K and 293 K ##, in ##let air velocity of 3 ##-15 m ##/ ##s, inner surface rough ##ness of 0 ##- ##0. ##00 ##1 mm ##, radius of curva ##ture of 2. ##5 ##- ##4. ##5 D ##, and hyd ##rau ##lic diameter of 70 ##-100 mm ##. The working fluid characteristics were highly affected by changes in the vis ##cous force ##. The maximum velocity profile ##s in the bent duc ##t were indicated when the $ ##90 ##^ ##{ ##\\ ##cir ##c ##} ##$ section was in the region of X ##/ ##D ##= ##0. ##8 and the $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ section was in the region of Y ##/ ##D ##= ##0. ##8. Lower surface rough ##ness and higher radius of curva ##ture resulted in a higher rate of velocity change ##. Also ##, an efficient measuring location [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 21:48 22:48 23:48 24:48 25:49 26:50 27:50 28:50 29:51 30:51 31:51 32:52 33:52 34:52 35:52 36:52 37:53 38:53 39:54 40:54 41:54 42:54 43:54 44:54 45:54 46:55 47:55 48:55 49:56 50:56 51:57 52:57 53:58 54:58 55:59 56:59 57:60 58:61 59:62 60:62 61:62 62:62 63:63 64:63 65:63 66:63 67:64 68:64 69:64 70:64 71:65 72:65 73:66 74:66 75:66 76:67 77:67 78:68 79:68 80:68 81:68 82:69 83:70 84:70 85:70 86:70 87:71 88:72 89:73 90:73 91:74 92:74 93:74 94:75 95:75 96:76 97:77 98:77 99:77 100:77 101:77 102:77 103:78 104:78 105:78 106:78 107:78 108:78 109:78 110:78 111:78 112:79 113:79 114:79 115:79 116:80 117:80 118:80 119:80 120:80 121:80 122:81 123:81 124:82 125:82 126:83 127:83 128:83 129:83 130:83 131:83 132:83 133:83 134:83 135:83 136:84 137:84 138:84 139:84 140:85 141:85 142:85 143:85 144:85 145:85 146:86 147:86 148:87 149:88 150:89 151:89 152:89 153:90 154:90 155:90 156:91 157:91 158:92 159:92 160:92 161:92 162:92 163:93 164:93 165:94 166:94 167:94 168:94 169:94 170:95 171:96 172:96 173:97 174:97 175:97 176:98 177:99 178:99 179:99 180:99 181:100 182:100 183:100 184:100 185:101 186:101 187:101 188:101 189:101 190:102 191:102 192:102 193:103 194:103 195:103 196:103 197:104 198:104 199:104 200:104 201:104 202:105 203:105 204:106 205:106 206:107 207:107 208:108 209:108 210:108 211:109 212:109 213:109 214:110 215:110 216:110 217:111 218:112 219:112 220:113 221:114 222:114 223:115 224:115 225:115 226:115 227:115 228:116 229:117 230:117 231:117 232:117 233:118 234:118 235:118 236:119 237:119 238:119 239:119 240:119 241:120 242:121 243:121 244:121 245:122 246:123 247:123 248:124 249:124 250:124 251:124 252:125 253:125 254:125 255:126 256:126 257:126 258:126 259:127 260:127 261:127 262:127 263:127 264:127 265:127 266:128 267:128 268:129 269:130 270:131 271:132 272:132 273:133 274:133 275:134 276:135 277:136 278:137 279:138 280:139 281:140 282:141 283:142 284:143 285:144 286:145 287:145 288:145 289:145 290:146 291:146 292:146 293:146 294:146 295:146 296:146 297:146 298:146 299:146 300:147 301:148 302:148 303:149 304:150 305:151 306:152 307:152 308:153 309:153 310:153 311:154 312:154 313:155 314:156 315:157 316:158 317:159 318:159 319:160 320:161 321:162 322:163 323:163 324:164 325:164 326:165 327:165 328:166 329:167 330:167 331:167 332:168 333:169 334:170 335:170 336:170 337:171 338:172 339:172 340:172 341:173 342:173 343:174 344:175 345:176 346:177 347:178 348:178 349:178 350:179 351:180 352:181 353:182 354:183 355:183 356:184 357:185 358:186 359:187 360:188 361:189 362:190 363:191 364:192 365:193 366:194 367:194 368:195 369:195 370:196 371:197 372:198 373:199 374:199 375:200 376:200 377:200 378:201 379:202 380:203 381:203 382:204 383:205 384:205 385:205 386:205 387:205 388:206 389:206 390:207 391:208 392:209 393:209 394:210 395:211 396:211 397:211 398:211 399:211 400:212 401:212 402:213 403:214 404:214 405:214 406:215 407:216 408:217 409:217 410:218 411:218 412:219 413:220 414:221 415:222 416:223 417:224 418:225 419:226 420:227 421:228 422:229 423:230 424:230 425:231 426:231 427:232 428:233 429:234 430:235 431:235 432:236 433:237 434:238 435:239 436:239 437:240 438:241 439:242 440:243 441:244 442:244 443:244 444:244 445:244 446:244 447:244 448:244 449:244 450:245 451:246 452:247 453:248 454:249 455:250 456:251 457:251 458:251 459:251 460:251 461:251 462:252 463:253 464:254 465:254 466:254 467:254 468:254 469:254 470:254 471:254 472:254 473:254 474:255 475:256 476:257 477:258 478:259 479:260 480:261 481:261 482:261 483:261 484:261 485:261 486:262 487:263 488:264 489:264 490:265 491:266 492:267 493:268 494:269 495:269 496:270 497:271 498:272 499:273 500:274 501:275 502:276 503:277 504:277 505:278 506:278 507:279 508:280 509:281 510:282\n",
      "I1125 11:12:38.452303 47903194205696 run_squad.py:406] token_to_orig_map: 21:48 22:48 23:48 24:48 25:49 26:50 27:50 28:50 29:51 30:51 31:51 32:52 33:52 34:52 35:52 36:52 37:53 38:53 39:54 40:54 41:54 42:54 43:54 44:54 45:54 46:55 47:55 48:55 49:56 50:56 51:57 52:57 53:58 54:58 55:59 56:59 57:60 58:61 59:62 60:62 61:62 62:62 63:63 64:63 65:63 66:63 67:64 68:64 69:64 70:64 71:65 72:65 73:66 74:66 75:66 76:67 77:67 78:68 79:68 80:68 81:68 82:69 83:70 84:70 85:70 86:70 87:71 88:72 89:73 90:73 91:74 92:74 93:74 94:75 95:75 96:76 97:77 98:77 99:77 100:77 101:77 102:77 103:78 104:78 105:78 106:78 107:78 108:78 109:78 110:78 111:78 112:79 113:79 114:79 115:79 116:80 117:80 118:80 119:80 120:80 121:80 122:81 123:81 124:82 125:82 126:83 127:83 128:83 129:83 130:83 131:83 132:83 133:83 134:83 135:83 136:84 137:84 138:84 139:84 140:85 141:85 142:85 143:85 144:85 145:85 146:86 147:86 148:87 149:88 150:89 151:89 152:89 153:90 154:90 155:90 156:91 157:91 158:92 159:92 160:92 161:92 162:92 163:93 164:93 165:94 166:94 167:94 168:94 169:94 170:95 171:96 172:96 173:97 174:97 175:97 176:98 177:99 178:99 179:99 180:99 181:100 182:100 183:100 184:100 185:101 186:101 187:101 188:101 189:101 190:102 191:102 192:102 193:103 194:103 195:103 196:103 197:104 198:104 199:104 200:104 201:104 202:105 203:105 204:106 205:106 206:107 207:107 208:108 209:108 210:108 211:109 212:109 213:109 214:110 215:110 216:110 217:111 218:112 219:112 220:113 221:114 222:114 223:115 224:115 225:115 226:115 227:115 228:116 229:117 230:117 231:117 232:117 233:118 234:118 235:118 236:119 237:119 238:119 239:119 240:119 241:120 242:121 243:121 244:121 245:122 246:123 247:123 248:124 249:124 250:124 251:124 252:125 253:125 254:125 255:126 256:126 257:126 258:126 259:127 260:127 261:127 262:127 263:127 264:127 265:127 266:128 267:128 268:129 269:130 270:131 271:132 272:132 273:133 274:133 275:134 276:135 277:136 278:137 279:138 280:139 281:140 282:141 283:142 284:143 285:144 286:145 287:145 288:145 289:145 290:146 291:146 292:146 293:146 294:146 295:146 296:146 297:146 298:146 299:146 300:147 301:148 302:148 303:149 304:150 305:151 306:152 307:152 308:153 309:153 310:153 311:154 312:154 313:155 314:156 315:157 316:158 317:159 318:159 319:160 320:161 321:162 322:163 323:163 324:164 325:164 326:165 327:165 328:166 329:167 330:167 331:167 332:168 333:169 334:170 335:170 336:170 337:171 338:172 339:172 340:172 341:173 342:173 343:174 344:175 345:176 346:177 347:178 348:178 349:178 350:179 351:180 352:181 353:182 354:183 355:183 356:184 357:185 358:186 359:187 360:188 361:189 362:190 363:191 364:192 365:193 366:194 367:194 368:195 369:195 370:196 371:197 372:198 373:199 374:199 375:200 376:200 377:200 378:201 379:202 380:203 381:203 382:204 383:205 384:205 385:205 386:205 387:205 388:206 389:206 390:207 391:208 392:209 393:209 394:210 395:211 396:211 397:211 398:211 399:211 400:212 401:212 402:213 403:214 404:214 405:214 406:215 407:216 408:217 409:217 410:218 411:218 412:219 413:220 414:221 415:222 416:223 417:224 418:225 419:226 420:227 421:228 422:229 423:230 424:230 425:231 426:231 427:232 428:233 429:234 430:235 431:235 432:236 433:237 434:238 435:239 436:239 437:240 438:241 439:242 440:243 441:244 442:244 443:244 444:244 445:244 446:244 447:244 448:244 449:244 450:245 451:246 452:247 453:248 454:249 455:250 456:251 457:251 458:251 459:251 460:251 461:251 462:252 463:253 464:254 465:254 466:254 467:254 468:254 469:254 470:254 471:254 472:254 473:254 474:255 475:256 476:257 477:258 478:259 479:260 480:261 481:261 482:261 483:261 484:261 485:261 486:262 487:263 488:264 489:264 490:265 491:266 492:267 493:268 494:269 495:269 496:270 497:271 498:272 499:273 500:274 501:275 502:276 503:277 504:277 505:278 506:278 507:279 508:280 509:281 510:282\n",
      "INFO:tensorflow:token_is_max_context: 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:False 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "I1125 11:12:38.452500 47903194205696 run_squad.py:408] token_is_max_context: 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:False 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False 383:False 384:False 385:False 386:False 387:False 388:False 389:False 390:False 391:False 392:False 393:False 394:False 395:False 396:False 397:False 398:False 399:False 400:False 401:False 402:False 403:False 404:False 405:False 406:False 407:False 408:False 409:False 410:False 411:False 412:False 413:False 414:False 415:False 416:False 417:False 418:False 419:False 420:False 421:False 422:False 423:False 424:False 425:False 426:False 427:False 428:False 429:False 430:False 431:False 432:False 433:False 434:False 435:False 436:False 437:False 438:False 439:False 440:False 441:False 442:False 443:False 444:False 445:False 446:False 447:False 448:False 449:False 450:False 451:False 452:False 453:False 454:False 455:False 456:False 457:False 458:False 459:False 460:False 461:False 462:False 463:False 464:False 465:False 466:False 467:False 468:False 469:False 470:False 471:False 472:False 473:False 474:False 475:False 476:False 477:False 478:False 479:False 480:False 481:False 482:False 483:False 484:False 485:False 486:False 487:False 488:False 489:False 490:False 491:False 492:False 493:False 494:False 495:False 496:False 497:False 498:False 499:False 500:False 501:False 502:False 503:False 504:False 505:False 506:False 507:False 508:False 509:False 510:False\n",
      "INFO:tensorflow:input_ids: 101 8889 20595 8996 10459 9625 18778 120305 119720 22440 119770 55910 9901 17342 22458 21876 11287 119873 11287 110871 102 28143 33077 31720 10892 63042 124 110881 37462 181 110865 119839 121 110881 119677 21069 10759 10366 110862 119616 11166 110881 119619 11166 11490 110862 10923 110881 49025 10366 11261 119564 13374 119700 10622 119570 119548 8924 119639 9670 12692 38378 110862 9652 18778 42815 79025 9625 18778 120132 10892 9625 79025 9668 17138 28143 120133 11261 9449 12092 120150 11287 62548 9061 17342 119231 10622 9524 9460 119815 119563 8889 20595 14646 8996 119650 99405 9449 12092 120281 46150 18392 10892 109 61400 110876 110878 110874 45455 10350 110880 110854 9059 14867 120245 11489 161 110865 11490 110869 119677 11396 119663 11467 119660 119579 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 9059 14867 120245 23635 162 110865 11490 110869 119677 11396 119663 11467 119588 23289 8900 31605 10459 119867 20626 68516 8992 119563 8889 88350 30134 31720 10739 9836 119766 9449 12092 120121 119183 10892 62548 9352 13374 119965 60209 110864 19789 8889 20595 31531 89267 9707 20595 52961 12424 9625 18778 50450 23466 11287 119877 18227 24683 9707 20595 41521 26344 149 110865 11490 110869 32792 119663 11489 119666 12965 9625 44321 8887 119281 14040 9625 119449 11102 119559 120245 11261 9654 119591 14843 9460 119815 119579 9460 28143 33077 31720 10530 22799 8889 20595 31531 46520 9707 20595 43875 119727 50450 23466 120132 10892 120082 9625 43962 18392 9137 119890 10459 9924 23466 120118 10892 9069 29683 11261 9707 20595 41521 12692 149 110865 11490 110869 37462 110881 32792 119851 11261 119588 10747 14687 67800 72762 119848 19579 10105 40582 10108 10105 84204 18477 10142 11948 18214 10108 169 15163 110863 104380 23748 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 122212 22620 10123 13382 169 30130 10838 30743 105549 50400 11405 13192 110864 10117 30676 88588 10309 79354 110862 11198 10105 14616 59848 119839 10106 12630 84204 110862 16004 87656 14010 110862 20212 10108 60594 16023 110862 10111 56888 40088 25303 31403 110864 10117 42584 17315 10142 119892 48177 21051 59848 95674 19129 10309 10106 12630 45091 10108 12566 10111 12286 10108 27401 148 10111 30435 148 110862 10106 12630 12566 84204 10108 124 120632 181 110865 119839 44615 16004 87656 14010 10108 121 110863 119677 21069 10759 10366 110862 20212 10108 60594 16023 10108 119616 11166 110863 119619 11166 141 110862 10111 56888 40088 25303 31403 10108 10923 120726 10366 110864 10117 14616 59848 40582 10309 22625 36276 10155 19010 10106 10105 23447 121880 15031 110864 10117 22393 84204 29549 10107 10106 10105 122212 22620 10123 10309 37944 10841 10105 109 61400 110876 110878 110874 45455 10350 110880 110854 14893 10134 10106 10105 12220 10108 161 110865 11490 110869 119677 11396 10111 10105 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 14893 10134 10106 10105 12220 10108 162 110865 11490 110869 119677 120011 27818 16004 87656 14010 10111 17981 20212 10108 60594 16023 26633 10106 169 17981 18344 10108 84204 15453 110864 20593 110862 10151 65763 92267 18214 102\n",
      "I1125 11:12:38.454000 47903194205696 run_squad.py:410] input_ids: 101 8889 20595 8996 10459 9625 18778 120305 119720 22440 119770 55910 9901 17342 22458 21876 11287 119873 11287 110871 102 28143 33077 31720 10892 63042 124 110881 37462 181 110865 119839 121 110881 119677 21069 10759 10366 110862 119616 11166 110881 119619 11166 11490 110862 10923 110881 49025 10366 11261 119564 13374 119700 10622 119570 119548 8924 119639 9670 12692 38378 110862 9652 18778 42815 79025 9625 18778 120132 10892 9625 79025 9668 17138 28143 120133 11261 9449 12092 120150 11287 62548 9061 17342 119231 10622 9524 9460 119815 119563 8889 20595 14646 8996 119650 99405 9449 12092 120281 46150 18392 10892 109 61400 110876 110878 110874 45455 10350 110880 110854 9059 14867 120245 11489 161 110865 11490 110869 119677 11396 119663 11467 119660 119579 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 9059 14867 120245 23635 162 110865 11490 110869 119677 11396 119663 11467 119588 23289 8900 31605 10459 119867 20626 68516 8992 119563 8889 88350 30134 31720 10739 9836 119766 9449 12092 120121 119183 10892 62548 9352 13374 119965 60209 110864 19789 8889 20595 31531 89267 9707 20595 52961 12424 9625 18778 50450 23466 11287 119877 18227 24683 9707 20595 41521 26344 149 110865 11490 110869 32792 119663 11489 119666 12965 9625 44321 8887 119281 14040 9625 119449 11102 119559 120245 11261 9654 119591 14843 9460 119815 119579 9460 28143 33077 31720 10530 22799 8889 20595 31531 46520 9707 20595 43875 119727 50450 23466 120132 10892 120082 9625 43962 18392 9137 119890 10459 9924 23466 120118 10892 9069 29683 11261 9707 20595 41521 12692 149 110865 11490 110869 37462 110881 32792 119851 11261 119588 10747 14687 67800 72762 119848 19579 10105 40582 10108 10105 84204 18477 10142 11948 18214 10108 169 15163 110863 104380 23748 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 122212 22620 10123 13382 169 30130 10838 30743 105549 50400 11405 13192 110864 10117 30676 88588 10309 79354 110862 11198 10105 14616 59848 119839 10106 12630 84204 110862 16004 87656 14010 110862 20212 10108 60594 16023 110862 10111 56888 40088 25303 31403 110864 10117 42584 17315 10142 119892 48177 21051 59848 95674 19129 10309 10106 12630 45091 10108 12566 10111 12286 10108 27401 148 10111 30435 148 110862 10106 12630 12566 84204 10108 124 120632 181 110865 119839 44615 16004 87656 14010 10108 121 110863 119677 21069 10759 10366 110862 20212 10108 60594 16023 10108 119616 11166 110863 119619 11166 141 110862 10111 56888 40088 25303 31403 10108 10923 120726 10366 110864 10117 14616 59848 40582 10309 22625 36276 10155 19010 10106 10105 23447 121880 15031 110864 10117 22393 84204 29549 10107 10106 10105 122212 22620 10123 10309 37944 10841 10105 109 61400 110876 110878 110874 45455 10350 110880 110854 14893 10134 10106 10105 12220 10108 161 110865 11490 110869 119677 11396 10111 10105 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 14893 10134 10106 10105 12220 10108 162 110865 11490 110869 119677 120011 27818 16004 87656 14010 10111 17981 20212 10108 60594 16023 26633 10106 169 17981 18344 10108 84204 15453 110864 20593 110862 10151 65763 92267 18214 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.454204 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1125 11:12:38.454350 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.455904 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000022\n",
      "I1125 11:12:38.455989 47903194205696 run_squad.py:400] unique_id: 1000000022\n",
      "INFO:tensorflow:example_index: 15\n",
      "I1125 11:12:38.456043 47903194205696 run_squad.py:401] example_index: 15\n",
      "INFO:tensorflow:doc_span_index: 2\n",
      "I1125 11:12:38.456090 47903194205696 run_squad.py:402] doc_span_index: 2\n",
      "INFO:tensorflow:tokens: [CLS] 곡 ##관 내 ##의 유 ##동 ##특성을 파악 ##하기 위해서는 어떤 파 ##라 ##미 ##터 ##가 필요한 ##가 ##? [SEP] 그리고 관 ##내 ##의 표면 ##조 ##도가 낮 ##고, 곡 ##률 ##반 ##경 ##이 클 ##수록 속 ##도 ##변화 ##율 ##은 크게 변 ##하여 나타 ##냈다 ##. 또한 곡 ##관 ##후 ##류의 직 ##관 ##부에 ##서 유 ##동 ##편 ##차 ##가 안정 ##화 ##되는 직 ##관 ##거 ##리는 L ##/ ##D ##= ##30 영역 ##에서 나타내 ##어 유 ##량 계 ##측 ##시 유 ##효 ##한 측정 ##위치 ##로 잘 제시 ##할 수 있었 ##으며, 수 ##력 ##직 ##경 ##에 따라 곡 ##관 ##후 ##류 직 ##관 ##부의 표준 ##편 ##차 ##특성 ##은 동일한 유 ##속 ##일 때 최소 ##의 편 ##차 ##영역 ##은 대 ##체 ##로 직 ##관 ##거 ##리 L ##/ ##D ##= ##15 ##~ ##30 범위 ##로 나타났다. This study numeri ##cally analy ##zes the characteristics of the velocity distribution for each location of a square ##- ##sect ##ional $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ bent duc ##t using a Reynolds St ##ress Tur ##bul ##ent model ##. The flow parameters were varied ##, including the working fluid ##s, in ##let velocity ##, surface rough ##ness ##, radius of curva ##ture ##, and hyd ##rau ##lic diameter ##. The boundary conditions for comp ##utati ##onal fluid dynamics analysis were in ##let temperatures of air and water of 288 K and 293 K ##, in ##let air velocity of 3 ##-15 m ##/ ##s, inner surface rough ##ness of 0 ##- ##0. ##00 ##1 mm ##, radius of curva ##ture of 2. ##5 ##- ##4. ##5 D ##, and hyd ##rau ##lic diameter of 70 ##-100 mm ##. The working fluid characteristics were highly affected by changes in the vis ##cous force ##. The maximum velocity profile ##s in the bent duc ##t were indicated when the $ ##90 ##^ ##{ ##\\ ##cir ##c ##} ##$ section was in the region of X ##/ ##D ##= ##0. ##8 and the $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ section was in the region of Y ##/ ##D ##= ##0. ##8. Lower surface rough ##ness and higher radius of curva ##ture resulted in a higher rate of velocity change ##. Also ##, an efficient measuring location down ##stream of the bent duc ##t is suggested since the flow de ##viation ##s were the most stable when the straight duc ##t length was in the region of L ##/ ##D ##= ##30. The minimum de ##viation ##s at the same velocity conditions according to the hyd ##rau ##lic diameter were mostly indicated in the range of L ##/ ##D ##= ##15 ##- ##30 based on the standard de ##viation characteristics ##. [SEP]\n",
      "I1125 11:12:38.456252 47903194205696 run_squad.py:404] tokens: [CLS] 곡 ##관 내 ##의 유 ##동 ##특성을 파악 ##하기 위해서는 어떤 파 ##라 ##미 ##터 ##가 필요한 ##가 ##? [SEP] 그리고 관 ##내 ##의 표면 ##조 ##도가 낮 ##고, 곡 ##률 ##반 ##경 ##이 클 ##수록 속 ##도 ##변화 ##율 ##은 크게 변 ##하여 나타 ##냈다 ##. 또한 곡 ##관 ##후 ##류의 직 ##관 ##부에 ##서 유 ##동 ##편 ##차 ##가 안정 ##화 ##되는 직 ##관 ##거 ##리는 L ##/ ##D ##= ##30 영역 ##에서 나타내 ##어 유 ##량 계 ##측 ##시 유 ##효 ##한 측정 ##위치 ##로 잘 제시 ##할 수 있었 ##으며, 수 ##력 ##직 ##경 ##에 따라 곡 ##관 ##후 ##류 직 ##관 ##부의 표준 ##편 ##차 ##특성 ##은 동일한 유 ##속 ##일 때 최소 ##의 편 ##차 ##영역 ##은 대 ##체 ##로 직 ##관 ##거 ##리 L ##/ ##D ##= ##15 ##~ ##30 범위 ##로 나타났다. This study numeri ##cally analy ##zes the characteristics of the velocity distribution for each location of a square ##- ##sect ##ional $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ bent duc ##t using a Reynolds St ##ress Tur ##bul ##ent model ##. The flow parameters were varied ##, including the working fluid ##s, in ##let velocity ##, surface rough ##ness ##, radius of curva ##ture ##, and hyd ##rau ##lic diameter ##. The boundary conditions for comp ##utati ##onal fluid dynamics analysis were in ##let temperatures of air and water of 288 K and 293 K ##, in ##let air velocity of 3 ##-15 m ##/ ##s, inner surface rough ##ness of 0 ##- ##0. ##00 ##1 mm ##, radius of curva ##ture of 2. ##5 ##- ##4. ##5 D ##, and hyd ##rau ##lic diameter of 70 ##-100 mm ##. The working fluid characteristics were highly affected by changes in the vis ##cous force ##. The maximum velocity profile ##s in the bent duc ##t were indicated when the $ ##90 ##^ ##{ ##\\ ##cir ##c ##} ##$ section was in the region of X ##/ ##D ##= ##0. ##8 and the $ ##18 ##0 ##^ ##{ ##\\ ##cir ##c ##} ##$ section was in the region of Y ##/ ##D ##= ##0. ##8. Lower surface rough ##ness and higher radius of curva ##ture resulted in a higher rate of velocity change ##. Also ##, an efficient measuring location down ##stream of the bent duc ##t is suggested since the flow de ##viation ##s were the most stable when the straight duc ##t length was in the region of L ##/ ##D ##= ##30. The minimum de ##viation ##s at the same velocity conditions according to the hyd ##rau ##lic diameter were mostly indicated in the range of L ##/ ##D ##= ##15 ##- ##30 based on the standard de ##viation characteristics ##. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 21:88 22:89 23:89 24:89 25:90 26:90 27:90 28:91 29:91 30:92 31:92 32:92 33:92 34:92 35:93 36:93 37:94 38:94 39:94 40:94 41:94 42:95 43:96 44:96 45:97 46:97 47:97 48:98 49:99 50:99 51:99 52:99 53:100 54:100 55:100 56:100 57:101 58:101 59:101 60:101 61:101 62:102 63:102 64:102 65:103 66:103 67:103 68:103 69:104 70:104 71:104 72:104 73:104 74:105 75:105 76:106 77:106 78:107 79:107 80:108 81:108 82:108 83:109 84:109 85:109 86:110 87:110 88:110 89:111 90:112 91:112 92:113 93:114 94:114 95:115 96:115 97:115 98:115 99:115 100:116 101:117 102:117 103:117 104:117 105:118 106:118 107:118 108:119 109:119 110:119 111:119 112:119 113:120 114:121 115:121 116:121 117:122 118:123 119:123 120:124 121:124 122:124 123:124 124:125 125:125 126:125 127:126 128:126 129:126 130:126 131:127 132:127 133:127 134:127 135:127 136:127 137:127 138:128 139:128 140:129 141:130 142:131 143:132 144:132 145:133 146:133 147:134 148:135 149:136 150:137 151:138 152:139 153:140 154:141 155:142 156:143 157:144 158:145 159:145 160:145 161:145 162:146 163:146 164:146 165:146 166:146 167:146 168:146 169:146 170:146 171:146 172:147 173:148 174:148 175:149 176:150 177:151 178:152 179:152 180:153 181:153 182:153 183:154 184:154 185:155 186:156 187:157 188:158 189:159 190:159 191:160 192:161 193:162 194:163 195:163 196:164 197:164 198:165 199:165 200:166 201:167 202:167 203:167 204:168 205:169 206:170 207:170 208:170 209:171 210:172 211:172 212:172 213:173 214:173 215:174 216:175 217:176 218:177 219:178 220:178 221:178 222:179 223:180 224:181 225:182 226:183 227:183 228:184 229:185 230:186 231:187 232:188 233:189 234:190 235:191 236:192 237:193 238:194 239:194 240:195 241:195 242:196 243:197 244:198 245:199 246:199 247:200 248:200 249:200 250:201 251:202 252:203 253:203 254:204 255:205 256:205 257:205 258:205 259:205 260:206 261:206 262:207 263:208 264:209 265:209 266:210 267:211 268:211 269:211 270:211 271:211 272:212 273:212 274:213 275:214 276:214 277:214 278:215 279:216 280:217 281:217 282:218 283:218 284:219 285:220 286:221 287:222 288:223 289:224 290:225 291:226 292:227 293:228 294:229 295:230 296:230 297:231 298:231 299:232 300:233 301:234 302:235 303:235 304:236 305:237 306:238 307:239 308:239 309:240 310:241 311:242 312:243 313:244 314:244 315:244 316:244 317:244 318:244 319:244 320:244 321:244 322:245 323:246 324:247 325:248 326:249 327:250 328:251 329:251 330:251 331:251 332:251 333:251 334:252 335:253 336:254 337:254 338:254 339:254 340:254 341:254 342:254 343:254 344:254 345:254 346:255 347:256 348:257 349:258 350:259 351:260 352:261 353:261 354:261 355:261 356:261 357:261 358:262 359:263 360:264 361:264 362:265 363:266 364:267 365:268 366:269 367:269 368:270 369:271 370:272 371:273 372:274 373:275 374:276 375:277 376:277 377:278 378:278 379:279 380:280 381:281 382:282 383:283 384:283 385:284 386:285 387:286 388:287 389:287 390:288 391:289 392:290 393:291 394:292 395:293 396:293 397:293 398:294 399:295 400:296 401:297 402:298 403:299 404:300 405:301 406:301 407:302 408:303 409:304 410:305 411:306 412:307 413:308 414:308 415:308 416:308 417:308 418:309 419:310 420:311 421:311 422:311 423:312 424:313 425:314 426:315 427:316 428:317 429:318 430:319 431:320 432:320 433:320 434:321 435:322 436:323 437:324 438:325 439:326 440:327 441:328 442:329 443:329 444:329 445:329 446:329 447:329 448:329 449:330 450:331 451:332 452:333 453:334 454:334 455:335 456:335\n",
      "I1125 11:12:38.456457 47903194205696 run_squad.py:406] token_to_orig_map: 21:88 22:89 23:89 24:89 25:90 26:90 27:90 28:91 29:91 30:92 31:92 32:92 33:92 34:92 35:93 36:93 37:94 38:94 39:94 40:94 41:94 42:95 43:96 44:96 45:97 46:97 47:97 48:98 49:99 50:99 51:99 52:99 53:100 54:100 55:100 56:100 57:101 58:101 59:101 60:101 61:101 62:102 63:102 64:102 65:103 66:103 67:103 68:103 69:104 70:104 71:104 72:104 73:104 74:105 75:105 76:106 77:106 78:107 79:107 80:108 81:108 82:108 83:109 84:109 85:109 86:110 87:110 88:110 89:111 90:112 91:112 92:113 93:114 94:114 95:115 96:115 97:115 98:115 99:115 100:116 101:117 102:117 103:117 104:117 105:118 106:118 107:118 108:119 109:119 110:119 111:119 112:119 113:120 114:121 115:121 116:121 117:122 118:123 119:123 120:124 121:124 122:124 123:124 124:125 125:125 126:125 127:126 128:126 129:126 130:126 131:127 132:127 133:127 134:127 135:127 136:127 137:127 138:128 139:128 140:129 141:130 142:131 143:132 144:132 145:133 146:133 147:134 148:135 149:136 150:137 151:138 152:139 153:140 154:141 155:142 156:143 157:144 158:145 159:145 160:145 161:145 162:146 163:146 164:146 165:146 166:146 167:146 168:146 169:146 170:146 171:146 172:147 173:148 174:148 175:149 176:150 177:151 178:152 179:152 180:153 181:153 182:153 183:154 184:154 185:155 186:156 187:157 188:158 189:159 190:159 191:160 192:161 193:162 194:163 195:163 196:164 197:164 198:165 199:165 200:166 201:167 202:167 203:167 204:168 205:169 206:170 207:170 208:170 209:171 210:172 211:172 212:172 213:173 214:173 215:174 216:175 217:176 218:177 219:178 220:178 221:178 222:179 223:180 224:181 225:182 226:183 227:183 228:184 229:185 230:186 231:187 232:188 233:189 234:190 235:191 236:192 237:193 238:194 239:194 240:195 241:195 242:196 243:197 244:198 245:199 246:199 247:200 248:200 249:200 250:201 251:202 252:203 253:203 254:204 255:205 256:205 257:205 258:205 259:205 260:206 261:206 262:207 263:208 264:209 265:209 266:210 267:211 268:211 269:211 270:211 271:211 272:212 273:212 274:213 275:214 276:214 277:214 278:215 279:216 280:217 281:217 282:218 283:218 284:219 285:220 286:221 287:222 288:223 289:224 290:225 291:226 292:227 293:228 294:229 295:230 296:230 297:231 298:231 299:232 300:233 301:234 302:235 303:235 304:236 305:237 306:238 307:239 308:239 309:240 310:241 311:242 312:243 313:244 314:244 315:244 316:244 317:244 318:244 319:244 320:244 321:244 322:245 323:246 324:247 325:248 326:249 327:250 328:251 329:251 330:251 331:251 332:251 333:251 334:252 335:253 336:254 337:254 338:254 339:254 340:254 341:254 342:254 343:254 344:254 345:254 346:255 347:256 348:257 349:258 350:259 351:260 352:261 353:261 354:261 355:261 356:261 357:261 358:262 359:263 360:264 361:264 362:265 363:266 364:267 365:268 366:269 367:269 368:270 369:271 370:272 371:273 372:274 373:275 374:276 375:277 376:277 377:278 378:278 379:279 380:280 381:281 382:282 383:283 384:283 385:284 386:285 387:286 388:287 389:287 390:288 391:289 392:290 393:291 394:292 395:293 396:293 397:293 398:294 399:295 400:296 401:297 402:298 403:299 404:300 405:301 406:301 407:302 408:303 409:304 410:305 411:306 412:307 413:308 414:308 415:308 416:308 417:308 418:309 419:310 420:311 421:311 422:311 423:312 424:313 425:314 426:315 427:316 428:317 429:318 430:319 431:320 432:320 433:320 434:321 435:322 436:323 437:324 438:325 439:326 440:327 441:328 442:329 443:329 444:329 445:329 446:329 447:329 448:329 449:330 450:331 451:332 452:333 453:334 454:334 455:335 456:335\n",
      "INFO:tensorflow:token_is_max_context: 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:False 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True\n",
      "I1125 11:12:38.456634 47903194205696 run_squad.py:408] token_is_max_context: 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:False 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True\n",
      "INFO:tensorflow:input_ids: 101 8889 20595 8996 10459 9625 18778 120305 119720 22440 119770 55910 9901 17342 22458 21876 11287 119873 11287 110871 102 23289 8900 31605 10459 119867 20626 68516 8992 119563 8889 88350 30134 31720 10739 9836 119766 9449 12092 120121 119183 10892 62548 9352 13374 119965 60209 110864 19789 8889 20595 31531 89267 9707 20595 52961 12424 9625 18778 50450 23466 11287 119877 18227 24683 9707 20595 41521 26344 149 110865 11490 110869 32792 119663 11489 119666 12965 9625 44321 8887 119281 14040 9625 119449 11102 119559 120245 11261 9654 119591 14843 9460 119815 119579 9460 28143 33077 31720 10530 22799 8889 20595 31531 46520 9707 20595 43875 119727 50450 23466 120132 10892 120082 9625 43962 18392 9137 119890 10459 9924 23466 120118 10892 9069 29683 11261 9707 20595 41521 12692 149 110865 11490 110869 37462 110881 32792 119851 11261 119588 10747 14687 67800 72762 119848 19579 10105 40582 10108 10105 84204 18477 10142 11948 18214 10108 169 15163 110863 104380 23748 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 122212 22620 10123 13382 169 30130 10838 30743 105549 50400 11405 13192 110864 10117 30676 88588 10309 79354 110862 11198 10105 14616 59848 119839 10106 12630 84204 110862 16004 87656 14010 110862 20212 10108 60594 16023 110862 10111 56888 40088 25303 31403 110864 10117 42584 17315 10142 119892 48177 21051 59848 95674 19129 10309 10106 12630 45091 10108 12566 10111 12286 10108 27401 148 10111 30435 148 110862 10106 12630 12566 84204 10108 124 120632 181 110865 119839 44615 16004 87656 14010 10108 121 110863 119677 21069 10759 10366 110862 20212 10108 60594 16023 10108 119616 11166 110863 119619 11166 141 110862 10111 56888 40088 25303 31403 10108 10923 120726 10366 110864 10117 14616 59848 40582 10309 22625 36276 10155 19010 10106 10105 23447 121880 15031 110864 10117 22393 84204 29549 10107 10106 10105 122212 22620 10123 10309 37944 10841 10105 109 61400 110876 110878 110874 45455 10350 110880 110854 14893 10134 10106 10105 12220 10108 161 110865 11490 110869 119677 11396 10111 10105 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 14893 10134 10106 10105 12220 10108 162 110865 11490 110869 119677 120011 27818 16004 87656 14010 10111 17981 20212 10108 60594 16023 26633 10106 169 17981 18344 10108 84204 15453 110864 20593 110862 10151 65763 92267 18214 12935 69190 10108 10105 122212 22620 10123 10124 27675 11764 10105 30676 10104 99634 10107 10309 10105 10992 38430 10841 10105 31214 22620 10123 17283 10134 10106 10105 12220 10108 149 110865 11490 110869 120766 10117 26503 10104 99634 10107 10160 10105 11561 84204 17315 18071 10114 10105 56888 40088 25303 31403 10309 19774 37944 10106 10105 15601 10108 149 110865 11490 110869 37462 110863 32792 11610 10135 10105 14979 10104 99634 40582 110864 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.457832 47903194205696 run_squad.py:410] input_ids: 101 8889 20595 8996 10459 9625 18778 120305 119720 22440 119770 55910 9901 17342 22458 21876 11287 119873 11287 110871 102 23289 8900 31605 10459 119867 20626 68516 8992 119563 8889 88350 30134 31720 10739 9836 119766 9449 12092 120121 119183 10892 62548 9352 13374 119965 60209 110864 19789 8889 20595 31531 89267 9707 20595 52961 12424 9625 18778 50450 23466 11287 119877 18227 24683 9707 20595 41521 26344 149 110865 11490 110869 32792 119663 11489 119666 12965 9625 44321 8887 119281 14040 9625 119449 11102 119559 120245 11261 9654 119591 14843 9460 119815 119579 9460 28143 33077 31720 10530 22799 8889 20595 31531 46520 9707 20595 43875 119727 50450 23466 120132 10892 120082 9625 43962 18392 9137 119890 10459 9924 23466 120118 10892 9069 29683 11261 9707 20595 41521 12692 149 110865 11490 110869 37462 110881 32792 119851 11261 119588 10747 14687 67800 72762 119848 19579 10105 40582 10108 10105 84204 18477 10142 11948 18214 10108 169 15163 110863 104380 23748 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 122212 22620 10123 13382 169 30130 10838 30743 105549 50400 11405 13192 110864 10117 30676 88588 10309 79354 110862 11198 10105 14616 59848 119839 10106 12630 84204 110862 16004 87656 14010 110862 20212 10108 60594 16023 110862 10111 56888 40088 25303 31403 110864 10117 42584 17315 10142 119892 48177 21051 59848 95674 19129 10309 10106 12630 45091 10108 12566 10111 12286 10108 27401 148 10111 30435 148 110862 10106 12630 12566 84204 10108 124 120632 181 110865 119839 44615 16004 87656 14010 10108 121 110863 119677 21069 10759 10366 110862 20212 10108 60594 16023 10108 119616 11166 110863 119619 11166 141 110862 10111 56888 40088 25303 31403 10108 10923 120726 10366 110864 10117 14616 59848 40582 10309 22625 36276 10155 19010 10106 10105 23447 121880 15031 110864 10117 22393 84204 29549 10107 10106 10105 122212 22620 10123 10309 37944 10841 10105 109 61400 110876 110878 110874 45455 10350 110880 110854 14893 10134 10106 10105 12220 10108 161 110865 11490 110869 119677 11396 10111 10105 109 45987 10929 110876 110878 110874 45455 10350 110880 110854 14893 10134 10106 10105 12220 10108 162 110865 11490 110869 119677 120011 27818 16004 87656 14010 10111 17981 20212 10108 60594 16023 26633 10106 169 17981 18344 10108 84204 15453 110864 20593 110862 10151 65763 92267 18214 12935 69190 10108 10105 122212 22620 10123 10124 27675 11764 10105 30676 10104 99634 10107 10309 10105 10992 38430 10841 10105 31214 22620 10123 17283 10134 10106 10105 12220 10108 149 110865 11490 110869 120766 10117 26503 10104 99634 10107 10160 10105 11561 84204 17315 18071 10114 10105 56888 40088 25303 31403 10309 19774 37944 10106 10105 15601 10108 149 110865 11490 110869 37462 110863 32792 11610 10135 10105 14979 10104 99634 40582 110864 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.457998 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.458149 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.459540 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000023\n",
      "I1125 11:12:38.459631 47903194205696 run_squad.py:400] unique_id: 1000000023\n",
      "INFO:tensorflow:example_index: 16\n",
      "I1125 11:12:38.459701 47903194205696 run_squad.py:401] example_index: 16\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.459753 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 자연 ##을 통한 과학 ##학습 ##이 ##란 무 ##엇 ##인 ##가 [SEP] 이와 같은 교육 ##적 필요 ##성에 따라 지식 위 ##주의 과학 ##학습 ##과 그 ##에 반 ##발 ##하여 나타난 정의 ##적 측면 ##의 자연 ##생 ##태 ##학습 ##의 합 ##일 ##점을 찾 ##아 ##야 한다. 이를 위해 과학교육 ##의 체 ##계 ##가 바 ##뀌 ##어 ##야 하며 그 ##에 맞 ##는 올 ##바 ##른 교육 ##방향 ##이 제시 ##되어야 한다. 이 연구를 통해 제시 ##하고자 하는 과학교육 ##의 올 ##바 ##른 방향 ##은 [UNK] 통한 [UNK] [UNK] 통한 [UNK] 있는 그대로 ##의 자연 안 ##에서 자연 ##의 대상 ##과 정 ##서 ##적으로 교 ##감 ##하고 이를 바탕으로 직접 관찰 ##을 통해 자연 ##의 총 ##체 ##적인 모습을 이해 ##하는 과학 ##학습 ##으로 정의 ##할 수 있다. [SEP]\n",
      "I1125 11:12:38.459836 47903194205696 run_squad.py:404] tokens: [CLS] 자연 ##을 통한 과학 ##학습 ##이 ##란 무 ##엇 ##인 ##가 [SEP] 이와 같은 교육 ##적 필요 ##성에 따라 지식 위 ##주의 과학 ##학습 ##과 그 ##에 반 ##발 ##하여 나타난 정의 ##적 측면 ##의 자연 ##생 ##태 ##학습 ##의 합 ##일 ##점을 찾 ##아 ##야 한다. 이를 위해 과학교육 ##의 체 ##계 ##가 바 ##뀌 ##어 ##야 하며 그 ##에 맞 ##는 올 ##바 ##른 교육 ##방향 ##이 제시 ##되어야 한다. 이 연구를 통해 제시 ##하고자 하는 과학교육 ##의 올 ##바 ##른 방향 ##은 [UNK] 통한 [UNK] [UNK] 통한 [UNK] 있는 그대로 ##의 자연 안 ##에서 자연 ##의 대상 ##과 정 ##서 ##적으로 교 ##감 ##하고 이를 바탕으로 직접 관찰 ##을 통해 자연 ##의 총 ##체 ##적인 모습을 이해 ##하는 과학 ##학습 ##으로 정의 ##할 수 있다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 13:0 14:1 15:2 16:2 17:3 18:3 19:4 20:5 21:6 22:6 23:7 24:7 25:7 26:8 27:8 28:9 29:9 30:9 31:10 32:11 33:11 34:12 35:12 36:13 37:13 38:13 39:13 40:13 41:14 42:14 43:14 44:15 45:15 46:15 47:16 48:17 49:18 50:19 51:19 52:20 53:20 54:20 55:21 56:21 57:21 58:21 59:22 60:23 61:23 62:24 63:24 64:25 65:25 66:25 67:26 68:26 69:26 70:27 71:27 72:28 73:29 74:30 75:31 76:32 77:32 78:33 79:34 80:34 81:35 82:35 83:35 84:36 85:36 86:37 87:38 88:39 89:40 90:41 91:42 92:43 93:44 94:44 95:45 96:46 97:46 98:47 99:47 100:48 101:48 102:49 103:49 104:49 105:50 106:50 107:50 108:51 109:52 110:53 111:54 112:54 113:55 114:56 115:56 116:57 117:57 118:57 119:58 120:59 121:59 122:60 123:60 124:60 125:61 126:61 127:62 128:63\n",
      "I1125 11:12:38.459932 47903194205696 run_squad.py:406] token_to_orig_map: 13:0 14:1 15:2 16:2 17:3 18:3 19:4 20:5 21:6 22:6 23:7 24:7 25:7 26:8 27:8 28:9 29:9 30:9 31:10 32:11 33:11 34:12 35:12 36:13 37:13 38:13 39:13 40:13 41:14 42:14 43:14 44:15 45:15 46:15 47:16 48:17 49:18 50:19 51:19 52:20 53:20 54:20 55:21 56:21 57:21 58:21 59:22 60:23 61:23 62:24 63:24 64:25 65:25 66:25 67:26 68:26 69:26 70:27 71:27 72:28 73:29 74:30 75:31 76:32 77:32 78:33 79:34 80:34 81:35 82:35 83:35 84:36 85:36 86:37 87:38 88:39 89:40 90:41 91:42 92:43 93:44 94:44 95:45 96:46 97:46 98:47 99:47 100:48 101:48 102:49 103:49 104:49 105:50 106:50 107:50 108:51 109:52 110:53 111:54 112:54 113:55 114:56 115:56 116:57 117:57 118:57 119:58 120:59 121:59 122:60 123:60 124:60 125:61 126:61 127:62 128:63\n",
      "INFO:tensorflow:token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True\n",
      "I1125 11:12:38.460027 47903194205696 run_squad.py:408] token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True\n",
      "INFO:tensorflow:input_ids: 101 120002 10622 119837 119971 120154 10739 49919 9294 119137 12030 11287 102 104342 18589 119583 14801 119629 119812 22799 119810 9619 37224 119971 120154 11882 8924 10530 9321 51431 13374 119988 119765 14801 119819 10459 120002 24017 83616 120154 10459 9957 18392 67477 9737 16985 21711 119575 35756 19905 120785 10459 9752 21611 11287 9318 118700 12965 21711 64866 8924 10530 9256 11018 9583 42144 37819 119583 119996 10739 119591 120050 119575 9638 119940 25605 119591 119713 23969 120785 10459 9583 42144 37819 119795 10892 100 119837 100 100 119837 100 13767 110589 10459 120002 9521 11489 120002 10459 119624 11882 9670 12424 17022 8907 105197 12453 35756 119983 67288 119855 10622 25605 120002 10459 9761 29683 15387 94684 119784 12178 119971 120154 11467 119765 14843 9460 119547 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.460192 47903194205696 run_squad.py:410] input_ids: 101 120002 10622 119837 119971 120154 10739 49919 9294 119137 12030 11287 102 104342 18589 119583 14801 119629 119812 22799 119810 9619 37224 119971 120154 11882 8924 10530 9321 51431 13374 119988 119765 14801 119819 10459 120002 24017 83616 120154 10459 9957 18392 67477 9737 16985 21711 119575 35756 19905 120785 10459 9752 21611 11287 9318 118700 12965 21711 64866 8924 10530 9256 11018 9583 42144 37819 119583 119996 10739 119591 120050 119575 9638 119940 25605 119591 119713 23969 120785 10459 9583 42144 37819 119795 10892 100 119837 100 100 119837 100 13767 110589 10459 120002 9521 11489 120002 10459 119624 11882 9670 12424 17022 8907 105197 12453 35756 119983 67288 119855 10622 25605 120002 10459 9761 29683 15387 94684 119784 12178 119971 120154 11467 119765 14843 9460 119547 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.460345 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.460487 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.461497 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000024\n",
      "I1125 11:12:38.461590 47903194205696 run_squad.py:400] unique_id: 1000000024\n",
      "INFO:tensorflow:example_index: 17\n",
      "I1125 11:12:38.461646 47903194205696 run_squad.py:401] example_index: 17\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.461700 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 오 ##늘 ##날 과학교육 ##의 목표 ##는 무 ##엇 ##인 ##가 [SEP] 오 ##늘 ##날 과학교육 ##은 단 ##지 과학 ##자 ##나 연구 ##자를 길 ##러 ##내는 것을 목표 ##로 하지 않 ##으며 모든 학생 ##들이 일 ##상 ##생활 ##에서 자신이 배 ##운 과학 ##을 활용 ##할 수 있는 능 ##력을 배 ##양 ##하고자 한다. ##35 Nature ##- ##St ##ud ##y ##도 이와 동일 ##하게 모든 학생 ##을 위한 교육 ##을 지 ##향 ##한다. [SEP]\n",
      "I1125 11:12:38.461775 47903194205696 run_squad.py:404] tokens: [CLS] 오 ##늘 ##날 과학교육 ##의 목표 ##는 무 ##엇 ##인 ##가 [SEP] 오 ##늘 ##날 과학교육 ##은 단 ##지 과학 ##자 ##나 연구 ##자를 길 ##러 ##내는 것을 목표 ##로 하지 않 ##으며 모든 학생 ##들이 일 ##상 ##생활 ##에서 자신이 배 ##운 과학 ##을 활용 ##할 수 있는 능 ##력을 배 ##양 ##하고자 한다. ##35 Nature ##- ##St ##ud ##y ##도 이와 동일 ##하게 모든 학생 ##을 위한 교육 ##을 지 ##향 ##한다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 13:0 14:0 15:0 16:1 17:1 18:2 19:2 20:3 21:3 22:3 23:4 24:4 25:5 26:5 27:5 28:6 29:7 30:7 31:8 32:9 33:9 34:10 35:11 36:11 37:12 38:12 39:12 40:12 41:13 42:14 43:14 44:15 45:15 46:16 47:16 48:17 49:18 50:19 51:19 52:20 53:20 54:20 55:21 56:21 57:22 58:22 59:22 60:22 61:22 62:22 63:23 64:24 65:24 66:25 67:26 68:26 69:27 70:28 71:28 72:29 73:29 74:29\n",
      "I1125 11:12:38.461859 47903194205696 run_squad.py:406] token_to_orig_map: 13:0 14:0 15:0 16:1 17:1 18:2 19:2 20:3 21:3 22:3 23:4 24:4 25:5 26:5 27:5 28:6 29:7 30:7 31:8 32:9 33:9 34:10 35:11 36:11 37:12 38:12 39:12 40:12 41:13 42:14 43:14 44:15 45:15 46:16 47:16 48:17 49:18 50:19 51:19 52:20 53:20 54:20 55:21 56:21 57:22 58:22 59:22 60:22 61:22 62:22 63:23 64:24 65:24 66:25 67:26 68:26 69:27 70:28 71:28 72:29 73:29 74:29\n",
      "INFO:tensorflow:token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True\n",
      "I1125 11:12:38.461929 47903194205696 run_squad.py:408] token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True\n",
      "INFO:tensorflow:input_ids: 101 9580 118762 41919 120785 10459 120006 11018 9294 119137 12030 11287 102 9580 118762 41919 120785 10892 9059 12508 119971 13764 16439 91785 48959 8934 30873 87444 21371 120006 11261 89093 9523 24098 25701 119637 20173 9641 14871 119961 11489 79370 9330 21614 119971 10622 119577 14843 9460 13767 9046 33975 9330 37114 119713 119575 76897 13937 110863 120336 11679 10157 12092 104342 120112 17594 25701 119637 10622 28195 119583 10622 9706 79544 119554 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.462074 47903194205696 run_squad.py:410] input_ids: 101 9580 118762 41919 120785 10459 120006 11018 9294 119137 12030 11287 102 9580 118762 41919 120785 10892 9059 12508 119971 13764 16439 91785 48959 8934 30873 87444 21371 120006 11261 89093 9523 24098 25701 119637 20173 9641 14871 119961 11489 79370 9330 21614 119971 10622 119577 14843 9460 13767 9046 33975 9330 37114 119713 119575 76897 13937 110863 120336 11679 10157 12092 104342 120112 17594 25701 119637 10622 28195 119583 10622 9706 79544 119554 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.462228 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.462368 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.468653 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000025\n",
      "I1125 11:12:38.468752 47903194205696 run_squad.py:400] unique_id: 1000000025\n",
      "INFO:tensorflow:example_index: 18\n",
      "I1125 11:12:38.468808 47903194205696 run_squad.py:401] example_index: 18\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.468863 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 암 ##호는 무 ##엇 ##인 ##가 ##? [SEP] 오 ##늘 ##날 널리 알려져 있는 정보 ##보 ##안 기술 중 하나 ##가 암 ##호 ##이며, 그리스 ##어 ##에서 기 ##원 ##한 암 ##호 ##(C ##ry ##pt ##ography ##) ##라는 용 ##어는 [UNK] [UNK] 의미 ##하지만 현재는 [UNK] 공 ##격 ##에 안전 ##하도록 메 ##시 ##지 변 ##형 ##을 하는 예 ##술 ##과 [UNK] 뜻 ##한다. 과 ##거 ##에는 암 ##호 ##가 단 ##지 비 ##밀 키 ##를 이용하여 메 ##시 ##지의 암 ##호 ##화 ##와 복 ##호 ##화를 하는 것으로 간 ##주 ##되었 ##지만, 오 ##늘 ##날 암 ##호는 세 개의 별 ##개의 메 ##커 ##니 ##즘 ##, 즉 공 ##개 ##키 암 ##호 ##화 ##, 비 ##밀 키 암 ##호 ##화 ##, 해 ##슁 ##( ##H ##ashi ##ng ##)으로 정의 ##된다. 암 ##호 ##화 ##는 컴 ##퓨 ##터 ##에 저장 ##되어 있 ##거나 네트워크 ##를 통해 전 ##달 ##되는 정보를 제 ##삼 ##자가 가 ##로 ##채 ##어 그 내용 ##을 노 ##출 ##시키 ##거나 의 ##도 ##적으로 내용 ##을 조 ##작 ##· ##변 ##경 ##하는 등의 보 ##안 ##공 ##격 ##으로 ##부터 정보를 보 ##호 ##하기 위한 수 ##단 ##으로 사용 ##되며 ##, 컴 ##퓨 ##터 ##와 인터 ##넷 ##을 중심으로 한 정보 ##화 사회 ##가 도 ##래 ##함 ##에 따라 그 중요 ##성이 점 ##점 증 ##대 ##되고 있는 핵 ##심 ##기술 ##이다 ##[ ##2, ##3 ##] ##. [SEP]\n",
      "I1125 11:12:38.468981 47903194205696 run_squad.py:404] tokens: [CLS] 암 ##호는 무 ##엇 ##인 ##가 ##? [SEP] 오 ##늘 ##날 널리 알려져 있는 정보 ##보 ##안 기술 중 하나 ##가 암 ##호 ##이며, 그리스 ##어 ##에서 기 ##원 ##한 암 ##호 ##(C ##ry ##pt ##ography ##) ##라는 용 ##어는 [UNK] [UNK] 의미 ##하지만 현재는 [UNK] 공 ##격 ##에 안전 ##하도록 메 ##시 ##지 변 ##형 ##을 하는 예 ##술 ##과 [UNK] 뜻 ##한다. 과 ##거 ##에는 암 ##호 ##가 단 ##지 비 ##밀 키 ##를 이용하여 메 ##시 ##지의 암 ##호 ##화 ##와 복 ##호 ##화를 하는 것으로 간 ##주 ##되었 ##지만, 오 ##늘 ##날 암 ##호는 세 개의 별 ##개의 메 ##커 ##니 ##즘 ##, 즉 공 ##개 ##키 암 ##호 ##화 ##, 비 ##밀 키 암 ##호 ##화 ##, 해 ##슁 ##( ##H ##ashi ##ng ##)으로 정의 ##된다. 암 ##호 ##화 ##는 컴 ##퓨 ##터 ##에 저장 ##되어 있 ##거나 네트워크 ##를 통해 전 ##달 ##되는 정보를 제 ##삼 ##자가 가 ##로 ##채 ##어 그 내용 ##을 노 ##출 ##시키 ##거나 의 ##도 ##적으로 내용 ##을 조 ##작 ##· ##변 ##경 ##하는 등의 보 ##안 ##공 ##격 ##으로 ##부터 정보를 보 ##호 ##하기 위한 수 ##단 ##으로 사용 ##되며 ##, 컴 ##퓨 ##터 ##와 인터 ##넷 ##을 중심으로 한 정보 ##화 사회 ##가 도 ##래 ##함 ##에 따라 그 중요 ##성이 점 ##점 증 ##대 ##되고 있는 핵 ##심 ##기술 ##이다 ##[ ##2, ##3 ##] ##. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 9:0 10:0 11:0 12:1 13:2 14:3 15:4 16:4 17:4 18:5 19:6 20:7 21:7 22:8 23:8 24:8 25:9 26:9 27:9 28:10 29:10 30:10 31:11 32:11 33:11 34:11 35:11 36:11 37:11 38:11 39:12 40:12 41:13 42:14 43:15 44:15 45:16 46:17 47:18 48:18 49:18 50:19 51:19 52:20 53:20 54:20 55:21 56:21 57:21 58:22 59:23 60:23 61:23 62:24 63:25 64:25 65:26 66:26 67:26 68:27 69:27 70:27 71:28 72:28 73:29 74:29 75:30 76:30 77:31 78:32 79:32 80:32 81:33 82:33 83:33 84:33 85:34 86:34 87:34 88:35 89:36 90:37 91:37 92:37 93:37 94:38 95:38 96:38 97:39 98:39 99:40 100:41 101:42 102:42 103:43 104:43 105:43 106:43 107:43 108:44 109:45 110:45 111:45 112:46 113:46 114:46 115:46 116:47 117:47 118:48 119:49 120:49 121:49 122:49 123:50 124:50 125:50 126:50 127:50 128:50 129:50 130:51 131:51 132:52 133:52 134:52 135:52 136:53 137:53 138:53 139:53 140:54 141:54 142:55 143:55 144:56 145:56 146:57 147:58 148:58 149:58 150:59 151:60 152:60 153:60 154:61 155:61 156:61 157:61 158:62 159:63 160:63 161:64 162:64 163:64 164:64 165:65 166:65 167:65 168:66 169:66 170:67 171:67 172:67 173:67 174:67 175:67 176:68 177:69 178:69 179:69 180:69 181:69 182:69 183:70 184:71 185:71 186:71 187:72 188:73 189:73 190:73 191:74 192:74 193:74 194:75 195:75 196:75 197:75 198:76 199:76 200:76 201:77 202:78 203:79 204:79 205:80 206:80 207:81 208:81 209:81 210:81 211:82 212:83 213:84 214:84 215:85 216:85 217:86 218:86 219:86 220:87 221:88 222:88 223:88 224:88 225:88 226:88 227:88 228:88 229:88\n",
      "I1125 11:12:38.469116 47903194205696 run_squad.py:406] token_to_orig_map: 9:0 10:0 11:0 12:1 13:2 14:3 15:4 16:4 17:4 18:5 19:6 20:7 21:7 22:8 23:8 24:8 25:9 26:9 27:9 28:10 29:10 30:10 31:11 32:11 33:11 34:11 35:11 36:11 37:11 38:11 39:12 40:12 41:13 42:14 43:15 44:15 45:16 46:17 47:18 48:18 49:18 50:19 51:19 52:20 53:20 54:20 55:21 56:21 57:21 58:22 59:23 60:23 61:23 62:24 63:25 64:25 65:26 66:26 67:26 68:27 69:27 70:27 71:28 72:28 73:29 74:29 75:30 76:30 77:31 78:32 79:32 80:32 81:33 82:33 83:33 84:33 85:34 86:34 87:34 88:35 89:36 90:37 91:37 92:37 93:37 94:38 95:38 96:38 97:39 98:39 99:40 100:41 101:42 102:42 103:43 104:43 105:43 106:43 107:43 108:44 109:45 110:45 111:45 112:46 113:46 114:46 115:46 116:47 117:47 118:48 119:49 120:49 121:49 122:49 123:50 124:50 125:50 126:50 127:50 128:50 129:50 130:51 131:51 132:52 133:52 134:52 135:52 136:53 137:53 138:53 139:53 140:54 141:54 142:55 143:55 144:56 145:56 146:57 147:58 148:58 149:58 150:59 151:60 152:60 153:60 154:61 155:61 156:61 157:61 158:62 159:63 160:63 161:64 162:64 163:64 164:64 165:65 166:65 167:65 168:66 169:66 170:67 171:67 172:67 173:67 174:67 175:67 176:68 177:69 178:69 179:69 180:69 181:69 182:69 183:70 184:71 185:71 186:71 187:72 188:73 189:73 190:73 191:74 192:74 193:74 194:75 195:75 196:75 197:75 198:76 199:76 200:76 201:77 202:78 203:79 204:79 205:80 206:80 207:81 208:81 209:81 210:81 211:82 212:83 213:84 214:84 215:85 216:85 217:86 218:86 219:86 220:87 221:88 222:88 223:88 224:88 225:88 226:88 227:88 228:88 229:88\n",
      "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True\n",
      "I1125 11:12:38.469238 47903194205696 run_squad.py:408] token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True\n",
      "INFO:tensorflow:input_ids: 101 9526 100543 9294 119137 12030 11287 110871 102 9580 118762 41919 107323 62350 13767 119596 30005 34951 119578 9694 119737 11287 9526 20309 119841 109043 12965 11489 8932 14279 11102 9526 20309 119936 10908 14971 34850 110859 60362 9603 106340 100 100 119614 120140 86539 100 8896 45465 10530 119741 119916 9272 14040 12508 9352 27506 10622 23969 9576 51945 11882 100 9153 119554 8898 41521 15303 9526 20309 11287 9059 12508 9379 118958 9838 11513 119593 9272 14040 73479 9526 20309 18227 12638 9357 20309 56999 23969 23925 8845 16323 119587 119920 9580 118762 41919 9526 100543 9435 68599 9353 32501 9272 106826 25503 119229 110862 9701 8896 21789 21039 9526 20309 18227 110862 9379 118958 9838 9526 20309 18227 110862 9960 123855 110858 12396 51151 10376 119991 119765 119574 9526 20309 18227 11018 9802 119410 21876 10530 119963 16855 9647 55534 119894 11513 25605 9665 89851 24683 119850 9672 119027 38939 8843 11261 119253 12965 8924 119669 10622 9022 52363 119761 55534 9637 12092 17022 119669 10622 9678 38709 110896 118985 31720 12178 28697 9356 34951 28000 45465 11467 17655 119850 9356 20309 22440 28195 9460 24989 11467 119550 99265 110862 9802 119410 21876 12638 119914 82881 10622 75109 9954 119596 18227 119701 11287 9087 37388 48533 10530 22799 8924 119692 53371 9668 34907 9705 14423 29208 13767 9961 71013 119769 11925 110873 119990 10884 110875 110864 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.469433 47903194205696 run_squad.py:410] input_ids: 101 9526 100543 9294 119137 12030 11287 110871 102 9580 118762 41919 107323 62350 13767 119596 30005 34951 119578 9694 119737 11287 9526 20309 119841 109043 12965 11489 8932 14279 11102 9526 20309 119936 10908 14971 34850 110859 60362 9603 106340 100 100 119614 120140 86539 100 8896 45465 10530 119741 119916 9272 14040 12508 9352 27506 10622 23969 9576 51945 11882 100 9153 119554 8898 41521 15303 9526 20309 11287 9059 12508 9379 118958 9838 11513 119593 9272 14040 73479 9526 20309 18227 12638 9357 20309 56999 23969 23925 8845 16323 119587 119920 9580 118762 41919 9526 100543 9435 68599 9353 32501 9272 106826 25503 119229 110862 9701 8896 21789 21039 9526 20309 18227 110862 9379 118958 9838 9526 20309 18227 110862 9960 123855 110858 12396 51151 10376 119991 119765 119574 9526 20309 18227 11018 9802 119410 21876 10530 119963 16855 9647 55534 119894 11513 25605 9665 89851 24683 119850 9672 119027 38939 8843 11261 119253 12965 8924 119669 10622 9022 52363 119761 55534 9637 12092 17022 119669 10622 9678 38709 110896 118985 31720 12178 28697 9356 34951 28000 45465 11467 17655 119850 9356 20309 22440 28195 9460 24989 11467 119550 99265 110862 9802 119410 21876 12638 119914 82881 10622 75109 9954 119596 18227 119701 11287 9087 37388 48533 10530 22799 8924 119692 53371 9668 34907 9705 14423 29208 13767 9961 71013 119769 11925 110873 119990 10884 110875 110864 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.469615 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.469794 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1125 11:12:38.471070 47903194205696 run_squad.py:399] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000026\n",
      "I1125 11:12:38.471166 47903194205696 run_squad.py:400] unique_id: 1000000026\n",
      "INFO:tensorflow:example_index: 19\n",
      "I1125 11:12:38.471222 47903194205696 run_squad.py:401] example_index: 19\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1125 11:12:38.471270 47903194205696 run_squad.py:402] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] 마 ##감 ##재 ##에 의한 바 ##닥 ##충 ##격 ##음 변화를 정확 ##히 판단 ##하고 반영 ##하기 위해 요구 ##되는 것은 ##? [SEP] 마 ##감 ##재 ##에 의한 바 ##닥 ##충 ##격 ##음 변화를 정확 ##히 판단 ##하고 이를 충 ##격 ##음 저 ##감 설계 ##와 제품 ##개발 ##에 반영 ##하기 위해서는 ##, 바 ##닥 ##충 ##격 ##음을 발생 ##시키는 직접 ##적인 원 ##인 ##인 바 ##닥 ##재 ##와 충 ##격 ##력 ##의 관계 ##에 대한 정 ##밀 ##한 분석 ##이 요구 ##된다. 바 ##닥 ##재 ##로 인한 충 ##격 ##력 변화 ##, 즉 충 ##격 ##력 스 ##펙 ##트 ##럼 ##을 평가 ##하고, 이 ##것이 바 ##닥 ##충 ##격 ##음 저 ##감 ##에 어 ##떠 ##한 영향 ##이 있는 ##지를 파악 ##하는 것이 매우 중요 ##하다. [SEP]\n",
      "I1125 11:12:38.471354 47903194205696 run_squad.py:404] tokens: [CLS] 마 ##감 ##재 ##에 의한 바 ##닥 ##충 ##격 ##음 변화를 정확 ##히 판단 ##하고 반영 ##하기 위해 요구 ##되는 것은 ##? [SEP] 마 ##감 ##재 ##에 의한 바 ##닥 ##충 ##격 ##음 변화를 정확 ##히 판단 ##하고 이를 충 ##격 ##음 저 ##감 설계 ##와 제품 ##개발 ##에 반영 ##하기 위해서는 ##, 바 ##닥 ##충 ##격 ##음을 발생 ##시키는 직접 ##적인 원 ##인 ##인 바 ##닥 ##재 ##와 충 ##격 ##력 ##의 관계 ##에 대한 정 ##밀 ##한 분석 ##이 요구 ##된다. 바 ##닥 ##재 ##로 인한 충 ##격 ##력 변화 ##, 즉 충 ##격 ##력 스 ##펙 ##트 ##럼 ##을 평가 ##하고, 이 ##것이 바 ##닥 ##충 ##격 ##음 저 ##감 ##에 어 ##떠 ##한 영향 ##이 있는 ##지를 파악 ##하는 것이 매우 중요 ##하다. [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 24:0 25:0 26:0 27:0 28:1 29:2 30:2 31:2 32:2 33:2 34:3 35:4 36:4 37:5 38:5 39:6 40:7 41:7 42:7 43:8 44:8 45:9 46:9 47:10 48:10 49:10 50:11 51:11 52:12 53:12 54:13 55:13 56:13 57:13 58:13 59:14 60:14 61:15 62:15 63:16 64:16 65:16 66:17 67:17 68:17 69:17 70:18 71:18 72:18 73:18 74:19 75:19 76:20 77:21 78:21 79:21 80:22 81:22 82:23 83:23 84:24 85:24 86:24 87:24 88:25 89:26 90:26 91:26 92:27 93:27 94:28 95:29 96:29 97:29 98:30 99:30 100:30 101:30 102:30 103:31 104:31 105:32 106:32 107:33 108:33 109:33 110:33 111:33 112:34 113:34 114:34 115:35 116:35 117:35 118:36 119:36 120:37 121:37 122:38 123:38 124:39 125:40 126:41 127:41\n",
      "I1125 11:12:38.471459 47903194205696 run_squad.py:406] token_to_orig_map: 24:0 25:0 26:0 27:0 28:1 29:2 30:2 31:2 32:2 33:2 34:3 35:4 36:4 37:5 38:5 39:6 40:7 41:7 42:7 43:8 44:8 45:9 46:9 47:10 48:10 49:10 50:11 51:11 52:12 53:12 54:13 55:13 56:13 57:13 58:13 59:14 60:14 61:15 62:15 63:16 64:16 65:16 66:17 67:17 68:17 69:17 70:18 71:18 72:18 73:18 74:19 75:19 76:20 77:21 78:21 79:21 80:22 81:22 82:23 83:23 84:24 85:24 86:24 87:24 88:25 89:26 90:26 91:26 92:27 93:27 94:28 95:29 96:29 97:29 98:30 99:30 100:30 101:30 102:30 103:31 104:31 105:32 106:32 107:33 108:33 109:33 110:33 111:33 112:34 113:34 114:34 115:35 116:35 117:35 118:36 119:36 120:37 121:37 122:38 123:38 124:39 125:40 126:41 127:41\n",
      "INFO:tensorflow:token_is_max_context: 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True\n",
      "I1125 11:12:38.471544 47903194205696 run_squad.py:408] token_is_max_context: 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True\n",
      "INFO:tensorflow:input_ids: 101 9246 105197 36210 10530 60804 9318 118770 119276 45465 32158 120010 119805 18108 119797 12453 119945 22440 19905 119703 24683 30050 110871 102 9246 105197 36210 10530 60804 9318 118770 119276 45465 32158 120010 119805 18108 119797 12453 35756 9770 45465 32158 9663 105197 119628 12638 119791 120043 10530 119945 22440 119770 110862 9318 118770 119276 45465 59724 119568 119950 67288 15387 9612 12030 12030 9318 118770 36210 12638 9770 45465 28143 10459 119657 10530 18154 9670 118958 11102 119552 10739 119703 119574 9318 118770 36210 11261 119984 9770 45465 28143 119586 110862 9701 9770 45465 28143 9477 119392 15184 118866 10622 119566 119604 9638 97403 9318 118770 119276 45465 32158 9663 105197 10530 9546 118833 11102 119642 10739 13767 36908 119720 12178 27487 42608 119692 119793 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.471711 47903194205696 run_squad.py:410] input_ids: 101 9246 105197 36210 10530 60804 9318 118770 119276 45465 32158 120010 119805 18108 119797 12453 119945 22440 19905 119703 24683 30050 110871 102 9246 105197 36210 10530 60804 9318 118770 119276 45465 32158 120010 119805 18108 119797 12453 35756 9770 45465 32158 9663 105197 119628 12638 119791 120043 10530 119945 22440 119770 110862 9318 118770 119276 45465 59724 119568 119950 67288 15387 9612 12030 12030 9318 118770 36210 12638 9770 45465 28143 10459 119657 10530 18154 9670 118958 11102 119552 10739 119703 119574 9318 118770 36210 11261 119984 9770 45465 28143 119586 110862 9701 9770 45465 28143 9477 119392 15184 118866 10622 119566 119604 9638 97403 9318 118770 119276 45465 32158 9663 105197 10530 9546 118833 11102 119642 10739 13767 36908 119720 12178 27487 42608 119692 119793 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.471870 47903194205696 run_squad.py:412] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1125 11:12:38.472016 47903194205696 run_squad.py:414] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:***** Running predictions *****\n",
      "I1125 11:12:38.643750 47903194205696 run_squad.py:1146] ***** Running predictions *****\n",
      "INFO:tensorflow:  Num orig examples = 99\n",
      "I1125 11:12:38.643887 47903194205696 run_squad.py:1147]   Num orig examples = 99\n",
      "INFO:tensorflow:  Num split examples = 114\n",
      "I1125 11:12:38.644065 47903194205696 run_squad.py:1148]   Num split examples = 114\n",
      "INFO:tensorflow:  Batch size = 8\n",
      "I1125 11:12:38.644131 47903194205696 run_squad.py:1149]   Batch size = 8\n",
      "WARNING:tensorflow:From make_bert_model/run_squad.py:656: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W1125 11:12:38.644269 47903194205696 module_wrapper.py:139] From make_bert_model/run_squad.py:656: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /scratch/kedu21/.conda/envs/notebook/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W1125 11:12:38.653108 47903194205696 deprecation.py:506] From /scratch/kedu21/.conda/envs/notebook/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From make_bert_model/run_squad.py:695: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "W1125 11:12:38.669481 47903194205696 deprecation.py:323] From make_bert_model/run_squad.py:695: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From /scratch/kedu21/.conda/envs/notebook/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "W1125 11:12:38.669787 47903194205696 deprecation.py:323] From /scratch/kedu21/.conda/envs/notebook/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /scratch/kedu21/.conda/envs/notebook/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "W1125 11:12:38.741257 47903194205696 module_wrapper.py:139] From /scratch/kedu21/.conda/envs/notebook/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From make_bert_model/run_squad.py:675: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1125 11:12:38.830084 47903194205696 deprecation.py:323] From make_bert_model/run_squad.py:675: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I1125 11:12:38.841781 47903194205696 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "I1125 11:12:38.841938 47903194205696 tpu_estimator.py:3124] Running infer on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "I1125 11:12:38.842186 47903194205696 run_squad.py:563] *** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 512)\n",
      "I1125 11:12:38.842292 47903194205696 run_squad.py:565]   name = input_ids, shape = (?, 512)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 512)\n",
      "I1125 11:12:38.842367 47903194205696 run_squad.py:565]   name = input_mask, shape = (?, 512)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 512)\n",
      "I1125 11:12:38.842436 47903194205696 run_squad.py:565]   name = segment_ids, shape = (?, 512)\n",
      "INFO:tensorflow:  name = unique_ids, shape = (?,)\n",
      "I1125 11:12:38.842506 47903194205696 run_squad.py:565]   name = unique_ids, shape = (?,)\n",
      "WARNING:tensorflow:From /scratch/kedu21/workspace/Final_Folder/make_bert_model/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W1125 11:12:38.845102 47903194205696 module_wrapper.py:139] From /scratch/kedu21/workspace/Final_Folder/make_bert_model/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /scratch/kedu21/workspace/Final_Folder/make_bert_model/modeling.py:411: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W1125 11:12:38.846337 47903194205696 module_wrapper.py:139] From /scratch/kedu21/workspace/Final_Folder/make_bert_model/modeling.py:411: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /scratch/kedu21/workspace/Final_Folder/make_bert_model/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "W1125 11:12:38.907331 47903194205696 deprecation.py:323] From /scratch/kedu21/workspace/Final_Folder/make_bert_model/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /scratch/kedu21/.conda/envs/notebook/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W1125 11:12:38.907960 47903194205696 deprecation.py:323] From /scratch/kedu21/.conda/envs/notebook/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /scratch/kedu21/workspace/Final_Folder/make_bert_model/modeling.py:277: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "W1125 11:12:38.986139 47903194205696 module_wrapper.py:139] From /scratch/kedu21/workspace/Final_Folder/make_bert_model/modeling.py:277: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:From make_bert_model/run_squad.py:582: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W1125 11:12:40.294785 47903194205696 module_wrapper.py:139] From make_bert_model/run_squad.py:582: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From make_bert_model/run_squad.py:597: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "W1125 11:12:40.299529 47903194205696 module_wrapper.py:139] From make_bert_model/run_squad.py:597: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "I1125 11:12:40.774984 47903194205696 run_squad.py:599] **** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (131747, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.775170 47903194205696 run_squad.py:605]   name = bert/embeddings/word_embeddings:0, shape = (131747, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.775267 47903194205696 run_squad.py:605]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.775353 47903194205696 run_squad.py:605]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.775427 47903194205696 run_squad.py:605]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.775491 47903194205696 run_squad.py:605]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.775552 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.775631 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.775707 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.775774 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.775848 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.775917 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.775979 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776044 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776117 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776181 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776241 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776306 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776381 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776450 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776512 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776573 47903194205696 run_squad.py:605]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776644 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776718 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776780 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776849 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776919 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.776984 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777045 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777114 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777183 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777245 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777306 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777379 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777448 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777513 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777578 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777643 47903194205696 run_squad.py:605]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777719 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777784 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777844 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777921 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.777986 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778050 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778111 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778186 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778250 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778311 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778370 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778446 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778509 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778572 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778632 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778710 47903194205696 run_squad.py:605]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778774 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778838 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778906 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.778978 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779040 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779103 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779169 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779241 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779302 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779361 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779426 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779499 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779562 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779625 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779703 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779767 47903194205696 run_squad.py:605]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779827 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779891 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.779962 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780030 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780090 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780153 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780228 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780296 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780356 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780416 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780486 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780554 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780614 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780689 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780757 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780818 47903194205696 run_squad.py:605]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780878 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.780947 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781015 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781081 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781141 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781209 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781277 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781342 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781403 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781467 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781538 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781604 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781670 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781746 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781810 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781870 47903194205696 run_squad.py:605]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.781929 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782005 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782068 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782131 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782191 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782266 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782330 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782397 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782457 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782529 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782592 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782660 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782727 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782798 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782860 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782919 47903194205696 run_squad.py:605]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.782984 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783057 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783118 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783180 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783246 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783318 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783380 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783443 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783508 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783576 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783637 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783708 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783779 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783846 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783907 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.783966 47903194205696 run_squad.py:605]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784038 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784105 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784165 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784231 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784302 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784369 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784429 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784492 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784565 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784627 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784693 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784763 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784831 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784896 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.784956 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785020 47903194205696 run_squad.py:605]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785089 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785154 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785216 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785284 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785352 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785418 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785477 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785545 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785614 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785685 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785748 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785824 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785888 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.785953 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786012 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786084 47903194205696 run_squad.py:605]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786148 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786212 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786273 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786349 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786413 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786478 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786537 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786612 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786680 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786741 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786805 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786877 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.786938 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787002 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787067 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787136 47903194205696 run_squad.py:605]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787197 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787261 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787327 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787398 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787461 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787525 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787590 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787666 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787728 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787788 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787860 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787927 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.787989 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.788053 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.788125 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.788188 47903194205696 run_squad.py:605]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.788248 47903194205696 run_squad.py:605]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.788311 47903194205696 run_squad.py:605]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/squad/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.788383 47903194205696 run_squad.py:605]   name = cls/squad/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/squad/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
      "I1125 11:12:40.788450 47903194205696 run_squad.py:605]   name = cls/squad/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I1125 11:12:40.788806 47903194205696 estimator.py:1150] Done calling model_fn.\n",
      "WARNING:tensorflow:From /scratch/kedu21/.conda/envs/notebook/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1125 11:12:40.907602 47903194205696 deprecation.py:323] From /scratch/kedu21/.conda/envs/notebook/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I1125 11:12:41.252381 47903194205696 monitored_session.py:240] Graph was finalized.\n",
      "2020-11-25 11:12:41.252873: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2020-11-25 11:12:41.265749: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz\n",
      "2020-11-25 11:12:41.267529: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f1bdbe1500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-25 11:12:41.267571: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-11-25 11:12:41.271559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-11-25 11:12:41.522417: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f1bdbe36f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-25 11:12:41.522521: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2020-11-25 11:12:41.524565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:af:00.0\n",
      "2020-11-25 11:12:41.526092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-11-25 11:12:41.529410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-11-25 11:12:41.532412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-11-25 11:12:41.533840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-11-25 11:12:41.537405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-11-25 11:12:41.540305: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-11-25 11:12:41.546869: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-11-25 11:12:41.550233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-11-25 11:12:41.550281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-11-25 11:12:41.552593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-11-25 11:12:41.552617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-11-25 11:12:41.552636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2020-11-25 11:12:41.556012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30583 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0)\n",
      "INFO:tensorflow:Restoring parameters from ./QA_models/model.ckpt-20628\n",
      "I1125 11:12:41.560259 47903194205696 saver.py:1284] Restoring parameters from ./QA_models/model.ckpt-20628\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I1125 11:12:43.979919 47903194205696 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I1125 11:12:44.103681 47903194205696 session_manager.py:502] Done running local_init_op.\n",
      "2020-11-25 11:12:44.860291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "INFO:tensorflow:Processing example: 0\n",
      "I1125 11:12:45.309681 47903194205696 run_squad.py:1165] Processing example: 0\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "I1125 11:12:46.788008 47903194205696 error_handling.py:101] prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "I1125 11:12:46.788859 47903194205696 error_handling.py:101] prediction_loop marked as finished\n",
      "INFO:tensorflow:Writing predictions to: ./QA_models/predictions.json\n",
      "I1125 11:12:46.789178 47903194205696 run_squad.py:710] Writing predictions to: ./QA_models/predictions.json\n",
      "INFO:tensorflow:Writing nbest to: ./QA_models/nbest_predictions.json\n",
      "I1125 11:12:46.789252 47903194205696 run_squad.py:711] Writing nbest to: ./QA_models/nbest_predictions.json\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 python make_bert_model/run_squad.py \\\n",
    "--vocab_file=./vocab/final_vocab.txt \\\n",
    "--bert_config_file=./conf/bert_config.json \\\n",
    "--init_checkpoint=./QA_models/model.ckpt-20628 \\\n",
    "--do_train=False \\\n",
    "--do_predict=True \\\n",
    "--predict_file=./QA_test.json \\\n",
    "--max_seq_length=512 \\\n",
    "--output_dir=./QA_models \\\n",
    "--do_lower_case=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model prediction evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "./QA_test.json (1번에서 나온 QA json파일 위치 지정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"exact_match\": 25.252525252525253, \"f1\": 56.6079192779617}\n"
     ]
    }
   ],
   "source": [
    "!python evaluate-v1.0.py \\\n",
    "./QA_test.json \\\n",
    "QA_models/predictions.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
